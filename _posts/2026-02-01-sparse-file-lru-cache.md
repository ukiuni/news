---
layout: post
title: "Sparse File LRU Cache - スパースファイルを使ったLRUキャッシュ"
date: 2026-02-01T06:14:49.604Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "http://ternarysearch.blogspot.com/2026/01/sparse-file-lru-cache.html"
source_title: "Ternary Search: Sparse File LRU Cache"
source_id: 46842586
excerpt: "スパースファイルでS3を部分キャッシュし、NVMeコストとIOPSを劇的に削減する実運用LRU設計"
---

# Sparse File LRU Cache - スパースファイルを使ったLRUキャッシュ
NVMeコストを大幅削減する「空きブロック」キャッシュ設計 — カラムナデータ向けの実運用テクニック

## 要約
ファイルシステムの「スパースファイル」を使い、S3などのコールドストレージからローカルNVMeへ部分的にデータをキャッシュする手法を紹介。カラムナデータのアクセス特性を活かして、ディスク容量とIOを節約しつつLRUで管理する設計。

## この記事を読むべき理由
カラムナ分析ワークロードではクエリごとに参照する列が極端に少ないため、ローカルSSDを効率よく使う設計がコストとパフォーマンスに直結する。日本でクラウド分析を運用するエンジニアにとって実践的価値が高い。

## 詳細解説
- スパースファイルとは  
  ファイルの論理サイズは大きいが、0で埋まる領域は実ディスク上に割り当てられないファイル機能。例えば論理512MBでも未書き込みなら物理は0。あるオフセットに非ゼロを書き込むと、そのブロックだけ物理割当が行われる（ファイルシステムがブロック単位でどこが実体化しているかを管理）。

- なぜカラムナ形式と相性が良いか  
  カラムはファイル内で連続領域になるため、必要な列だけに対応する論理ブロックを物理化すれば良い。クエリは通常5〜10列だけ参照するので、全ファイルを丸ごと置くより効率的。

- 他の設計との比較  
  1) ファイル丸ごとキャッシュ：実装は簡単だがSSDを無駄遣い。  
  2) 列ごとにファイル化：ディレクトリ／inodes増加と小さな列のブロック膨張問題（ファイルシステムのブロックで丸められる）。  
  → スパースファイルは中間解として、少ないメタデータで小列をブロックに詰められる利点を提供。

- 実装上の要点（元記事での実例）  
  - キャッシュ済みの「論理ブロック」メタデータをローカルのキー・バリューストア（例：RocksDB）で管理。エントリは「どのブロックがローカルにあるか」と「最終参照時刻」を保持し、これを使ってLRUに近い削除を行う。  
  - 論理ブロックは可変サイズを採用。ファイル先頭に小さめのブロックを置いてフォーマットのメタ（Parquet風のヘッダ）を読みやすくし、残りは大きめブロックで効率化。  
  - 読み手（クライアント）は事前にどの列を使うかをキャッシュレイヤに宣言し、該当論理ブロックを確保してから読み出す流れ。

- 効果  
  S3 GETの削減、ファイルシステムメタデータの削減、小さな列のブロック無駄の解消、IOPS削減といった複数の改善が同時に達成される。

## 実践ポイント
- まずアクセスパターンを計測し、ホットな列の割合を把握する。  
- スパースファイルをサポートするファイルシステム（例：XFS / ext4 の fallocate/sparse サポート）を検討する。  
- ブロック管理用に軽量なKV（RocksDB等）を用意し、(ブロックID → 存在フラグ + 最終参照時刻) を保持する設計にする。  
- ファイルフォーマットのヘッダを小さな先頭ブロックで確実に読み取れるよう、論理ブロックを可変長にする。  
- クライアントは事前に「使う列」を宣言してから読み始めるワークフローにすることで、不要なS3アクセスを防ぐ。

日本のクラウド環境でも、S3等コールドストレージと高性能ローカルNVMeの価格差があるため、同様の設計でコスト対効果が高くなる可能性が高い。導入前に列アクセス分布とファイルシステムのスパース挙動を必ず確認すること。
