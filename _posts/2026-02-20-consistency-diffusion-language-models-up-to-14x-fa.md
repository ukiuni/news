---
layout: post
title: "Consistency diffusion language models: Up to 14x faster, no quality loss - 一貫性拡散言語モデル：品質を落とさず最大14倍高速化"
date: 2026-02-20T05:52:25.690Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://www.together.ai/blog/consistency-diffusion-language-models"
source_title: "Consistency diffusion language models: Up to 14x faster inference without sacrificing quality"
source_id: 47083648
excerpt: "CDLMでDLMのKVキャッシュを復活させ、品質を落とさず最大14倍高速化"
---

# Consistency diffusion language models: Up to 14x faster, no quality loss - 一貫性拡散言語モデル：品質を落とさず最大14倍高速化
クリックせずにはいられないタイトル案：拡散モデルで「速さ」と「精度」を両取り——CDLMがLLM推論を一変させる理由

## 要約
Consistency Diffusion Language Models（CDLM）は、拡散型言語モデル（DLM）の反復改良を「ブロック単位のKVキャッシュ＋一貫性学習」で効率化し、数学・コーディング系ベンチで最大14.5倍のレイテンシ改善を達成します。

## この記事を読むべき理由
DLMは並列生成や文脈補完に強い一方で、「全方向注意によりKVキャッシュが効かない」「高いステップ数が必要」という実運用上の壁がありました。CDLMはその両方を解決する実用的な後処理（post-training）レシピで、低レイテンシ推論やコスト削減を狙う日本のプロダクト開発者／研究者に即効性のある道筋を示します。

## 詳細解説
- 背景（DLMの仕組み）
  - DLMは初めは全トークンをマスクし、複数のデノイジングステップで徐々に復元する方式。1トークンずつ出すAR（自己回帰）方式と違い、並列で複数トークンを確定できる可能性がある。
  - モデルが予測する分布は $p_{\theta}(\mathbf{X}_0 \mid \mathbf{X}_t, c)$ の形で表現される。

- 問題点
  1. 全方向（bidirectional）注意だと、各ステップで全コンテキストの注意を再計算する必要があり、従来のKVキャッシュが使えない。  
  2. 高品質には多くの改良ステップが必要で、単純にステップ数を減らすと精度が落ちる。

- CDLMのアイデア（要点）
  1. 軌跡収集（trajectory collection）  
     - 教師DLMでブロック単位（例：生成長 L_g=256、ブロックB=32、N=L_g ステップ）に沿ったデコーディング軌跡と「最終化時の最終層隠れ状態」を保存する。  
     - 軌跡 $\mathcal{T}_{\mathbf{x}}=(\mathbf{x}_{t_0},\mathbf{x}_{t_1},\dots,\mathbf{x}_{t_N})$ を学習の中心に使う。  
  2. ブロック因果（block-causal）学生モデルとマスク  
     - 訓練時はブロック単位で因果マスクを使い、プロンプトと過去の確定ブロック・現在ブロック内だけに注意を向けるようにする。これで「確定ブロックはKVキャッシュ可能」となる。  
  3. 3つの訓練目的（loss）  
     - 蒸留損失（新たにアンマスクされた位置）：教師の復元分布に合わせる。  
     - 一貫性損失（まだマスクされた位置）：途中状態と最終化状態の予測を整合させ、時系列安定性を促す（stop-gradientを活用）。  
     - 補助のマスク復元損失：一般的なマスク予測能力を維持し、特に数学的推論を保護する。  
  4. 推論時の流れ  
     - ブロック単位でKVキャッシュを再利用し、ブロック内は信頼度閾値に基づく並列最終化を行う。早期終了も採用。追加のタスク特化ヒューリスティックは極力避ける設計。

- 性能と解析
  - ステップ削減は約4.1x〜7.7x、レイテンシでは最大11.2x（GSM8K-CoT）〜14.5x（MBPP-Instruct）を報告。多くのケースでTokens/secが最大になる。  
  - ハードウェア視点ではARは小バッチでメモリバウンド、従来DLMは計算飽和。ブロックDLMは中間の算術強度（AI）に入り、小バッチ環境で効率が良い「スイートスポット」を取れる。

## 実践ポイント
- 既存のDLMに対して「教師→ブロック因果の学生」を学習させる後処理アプローチなので、フルモデル再設計は不要。  
- ブロックサイズの選定（例：B=16 or 32）は重要：小さすぎると並列利得が薄く、大きすぎると局所補完能力が落ちる。まずは16/32で試す。  
- トラジェクトリ収集は品質の鍵：保守的に1トークン/ステップ相当の軌跡を取ると良い蒸留データになる。  
- 日本語アプリへの効果：コード補完、数式処理、チャットボットの低レイテンシ化、オンプレGPUでのコスト対策などに即効性がある。  
- 将来的な拡張：より強力なDLMを教師に使うことで、さらに性能向上が期待できる。

この記事で得られる最短の実行プラン：まずは小規模な教師DLMでブロック単位の軌跡を集め、B=16/32で学生を微調整し、KVキャッシュを有効にした推論パイプラインでレイテンシと品質を比較してください。
