---
layout: post
title: High-performance C++ hash table using grouped SIMD metadata scanning - グループ化されたSIMDメタデータスキャンを使用した高性能C++ハッシュテーブル
date: 2025-12-29T21:26:44.054Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://github.com/Cranot/grouped-simd-hashtable"
source_title: "GitHub - Cranot/grouped-simd-hashtable: High-performance C++ hash table using grouped SIMD metadata scanning. Beats SOTA at scale."
source_id: 46371120
excerpt: "Grouped SIMDでSSE2活用、読み取り重視の百万規模検索を1.5倍高速化"
---

# High-performance C++ hash table using grouped SIMD metadata scanning - グループ化されたSIMDメタデータスキャンを使用した高性能C++ハッシュテーブル

## 要約
Grouped SIMD（グループ化されたSIMDメタデータ走査）を使ったC++ハッシュテーブルは、連続したスロットを一括でSSE2比較することで大規模テーブル（数十万〜百万以上）のルックアップ性能を劇的に向上させるアプローチだ。挿入コストはやや増えるが、読み取り中心のワークロードで有利になる。

## この記事を読むべき理由
- 日本のプロダクトで増える大規模キャッシュ／インデックス用途（サービスのスケールや検索頻度の高い内部DB）に直結する最適化が学べる。  
- GoogleのSwiss Tablesの洞察をベースに、現実的に実装可能なSSE2ベースの手法を解説するため、実運用での採用判断に役立つ。

## 詳細解説
問題点
- 伝統的な二次探査（quadratic probing）はプローブ先が離散的になり、任意位置の読み出し（gather）が多発するためSIMD化が効率を出しにくい。

解決策：Grouped Probing
- 16スロットを「グループ」として扱い、グループ単位でメタデータ（1バイト/スロット）をSIMDで一度にロードして比較する。これによりメモリ読み出しが連続化され、SSE2命令で高速にマッチ検出できる。
- SSE2での流れ（概念）：メタを128-bitでロード → バイトごとに比較 → マスクを抽出 → マスクに従って実際のキー比較を行う。

メタデータ形式（1バイト）
- ビット7：占有フラグ（1=occupied, 0=empty）  
- ビット0〜6：7ビットのハッシュフラグ（候補フィルタ）
→ これで実際のキー比較を行う前に127/128の非一致を落とせる。

プローブジャンプの設計
- グループ間は連続ジャンプではなく二次的なステップを採用することでクラスタリングと到達不能領域を防ぐ。式は例えば以下：
$$
\text{Group}_k: h + 16 \times k^2
$$
（$k=0,1,2,\dots$ をグループ番号とする）

性能傾向（要旨）
- 小〜中サイズ（< 500k）：従来実装に劣る場合がある。  
- 大規模（>= 500k、特に1M以上）かつ読み取り重視のワークロードではルックアップが有意に高速化される（例：ヒットで1.5倍以上の改善報告）。挿入はやや遅くなる点に注意。

制約とトレードオフ
- 固定容量（実装によってはリサイズ未対応）・削除未実装のものが多い。  
- SSE2(x86-64)依存。ARM向けにはNEON版が必要。  
- 挿入性能は工夫次第で改善できるが、読み取り優先設計であることを把握する。

短いコード例（利用イメージ）
```cpp
// C++
GroupedSIMDElastic<uint64_t, uint64_t> table(1200000); // 1.2Mキャパシティ
table.insert(key, value);
if (auto p = table.find(key)) {
  uint64_t v = *p;
}
```

## 実践ポイント
- 使うべき場面：テーブルサイズが数十万〜百万以上、読み取り（lookup）が圧倒的に多いサービス（キャッシュ、統計ルックアップ等）。  
- コンパイル時のヒント：最適化フラグ例 -O3 -march=native -msse2 を付ける（x86-64環境）。  
- 設計上の注意：事前に容量を見積もり、十分な余裕（max_load_factor）でプリサイズする。削除やリサイズが必須なら別実装か拡張を検討する。  
- ARM対応：ARM環境ではNEONを使った同等のグループ走査の実装が必要。  
- ベンチ方法：実運用のアクセス分布（ヒット率、キー分散、同時スレッド数）でベンチを行い、挿入/ルックアップ比でのクロスオーバー点（500k〜1M付近）を確認する。  
- 移植・採用の順序：①プロトタイプで読み取り中心ワークロードを再現して測定、②問題なければ本番でプリサイズ運用、③必要なら削除/リサイズ機能を追加。

以上を踏まえれば、Grouped SIMDアプローチは「大規模・読み取り重視」という明確な条件下で非常に有効な武器になる。導入前にワークロード特性とプラットフォーム（x86 vs ARM）を必ず確認してほしい。
