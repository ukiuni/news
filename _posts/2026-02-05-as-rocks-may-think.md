---
layout: post
title: "As Rocks May Think - 岩も考えるかもしれない"
date: 2026-02-05T00:34:59.296Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://evjang.com/2026/02/04/rocks.html"
source_title: "As Rocks May Think | Eric Jang"
source_id: 46893018
excerpt: "AIが自律的に実験設計・実行・改善し開発を劇的加速、だが安全と検証が不可欠"
---

# As Rocks May Think - 岩も考えるかもしれない
「AIが“思考する岩”になる時代：コードを書かないで済む明日のエンジニアリング」

## 要約
著者は「2022年以降、AIは単なる補助から自律的な研究者・エンジニアへ進化した」と論じ、コーディングエージェントが実験設計・実行・反省まで回せることで“自動化された科学者”時代が始まったと主張します。

## この記事を読むべき理由
日本のプロダクト開発・研究現場でも、コード生成・実験自動化・推論強化の波は既に到来しています。今知っておかないと設計手法や開発フローが一気に陳腐化する可能性があります。

## 詳細解説
- 状況の変化：ChatGPT以降、LLMはコード生成・論理的推論・ドメイン特化タスクで急速に能力を伸ばし、ロボットや映像生成まで影響を拡大。著者は「ゲームのサーバーが大型アップデートを受けた」と比喩します。
- コーディングエージェントの実例：著者はClaudeを使い、実験コマンド（/experiment）で実験フォルダ生成、単一ファイル実行、CSV保存、レポート生成まで自動化。コード自身を変え、反省→改変→再実行することで逐次最適化できる点を強調します。
- 推論の本質：推論は大別すると「演繹（deduction）」と「帰納（induction）」。演繹は論理的に確実だが計算量の問題で拡張困難。帰納は確率的で現実世界に強いが中間変数の取り扱いが難しい。ベイズ則は帰納の代表式で、$P(A|B)=\dfrac{P(B|A)P(A)}{P(B)}$ と示されます。
- AlphaGoの教訓：探索（演繹）とニューラル（帰納）を組み合わせることで難問を解いた。LLM時代の課題は言語や曖昧な現実に対する“推論回路”の学習であり、単なるプロンプト技巧では限界がある。
- プロンプト時代の教訓：Chain-of-thoughtや自己検証などのトリックは一時的効果を示したが、根本は「モデル自体により強い推論回路を学習させること」。過度なプロンプト依存は脆弱。
- 現状とインパクト：コードを自動生成し実験を設計・実行・評価するエージェントは「ソフトウェア工学」の枠を超え、研究・プロダクトのスピードを劇的に上げる。だが反面、安全性・検証・倫理のガバナンスが必須です。

## 実践ポイント
- 小さく自動化を試す：実験フォルダ→スクリプト→CSV→レポートのワークフローをエージェントに任せ、成果物の保存ルールを決める。
- 評価ループを整備：単に出力を信じず、検証用のテスト/チェッカーを用意して「反省→改変→再実行」を回す。
- 学ぶべき技術：モデル評価（プロンプト評価、process supervision）、実験管理（チェックポイント、FLOP予算管理）、安全ガード（アクセス制御、ログ）を優先して習得。
- ビジネス上の活用：MVP再実装、プロトタイプ大量生成、ハイパーパラ調整の自動化などで開発コストを下げられる一方、知財・セキュリティ面の社内ルール整備を急ぐ。
- 将来への備え：AIが「思考の土台」を担う前提で、監査可能な実験ログと人間による最終判断プロセスを設計しておく。

（原著は技術的示唆と危機意識を同居させた論考で、日本の開発現場にも直接応用できる示唆が多く含まれます。）
