---
layout: post
title: Clair Obscur: Expedition 33 director Guillaume Brioche admits Sandfall "tried - Clair Obscur: Expedition 33のディレクターGuillaume Brioche氏、Sandfallが「試みた」ことを認める
  AI during the J''RPG''s development, but "didn''t like it" and "everything in the
  game is human made"'
date: 2025-12-26 23:06:14.229000+00:00
categories:
- tech
- world-news
tags:
- tech-news
- japan
source_url: https://www.gamesradar.com/games/rpg/clair-obscur-expedition-33-director-admits-sandfall-tried-ai-during-the-jrpgs-development-but-didnt-like-it-and-everything-in-the-game-is-human-made/
source_title: 'Clair Obscur: Expedition 33 director admits Sandfall "tried" AI during
  the J''RPG''s development, but "didn''t like it" and "everything in the game is
  human made" | GamesRadar+'
source_id: 437453821
excerpt: Clair Obscur開発陣がAI試用を断念、最終成果は全て人の手で制作と明言し透明性議論に火
---
# Clair Obscur: Expedition 33 director Guillaume Brioche admits Sandfall "tried - Clair Obscur: Expedition 33のディレクターGuillaume Brioche氏、Sandfallが「試みた」ことを認める

## 要約
Clair Obscur: Expedition 33のディレクター、Guillaume Brioche氏は開発中に生成系AIを試したが最終的に不採用にし、「ゲーム内のすべては人の手による」と明言。インディー界隈での賞取り消しや議論と合わせ、AI活用の是非と透明性が改めて問題化している。

## この記事を読むべき理由
日本のゲーム/コンテンツ開発者やテック関係者にとって、生成AIは効率化の誘惑と法的・倫理的リスクを同時に抱える喫緊のテーマ。海外の一事例から、「いつ」「どのように」「何を」自動化すべきかの判断基準を学べる。

## 詳細解説
- 何が起きたか  
  元記事によれば、Clair Obscurチームは開発過程で生成系AI（テキスト生成、画像生成、音声合成など一般に使われる技術）を試用したが、品質や制作方針の観点から最終的に採用しなかったとされる。ディレクターは「好ましくなかった」「最終成果物は人間が作った」と強調している。

- 背景にある論点  
  近年インディー〜大手まで、アセット生成や脚本補助、テスト自動化など多様な領域で生成AIが導入され始めた。だが、以下の問題が浮上している。  
  - 品質と一貫性：生成物が制作物のトーンや演出方針にそぐわないケース。  
  - 出典と権利：学習データの出典不明瞭さが著作権侵害リスクや報酬帰属の不透明さを生む。  
  - 倫理と表現の制御：俳優の声や既存作品のスタイルを模倣してしまうリスク。  
  - コミュニティと賞の基準：AI使用が明示されないまま受賞した事例の取り消しなど、透明性に関する信頼問題。

- 技術的に問われる点  
  - 生成系AIの出力は確率的で「検出不能」な改変や類似性を生むことがあるため、徹底した検証（品質評価、差分検出、メタデータ検査）が必須。  
  - 証跡管理（プロンプトログ、モデルバージョン、学習データの参照情報）は、後追いでの説明責任や法的防御に重要。C2PAなどのコンテンツ認証規格の導入が注目されている。  
  - 人間による最終検閲（human-in-the-loop）をどう組み込むか：自動生成→人によるリライト／タッチアップのワークフロー設計が現実的。

## 実践ポイント
- ポリシーを明文化する  
  開発チーム内で「どの工程でAIを許可するか」「出力物の帰属はどう扱うか」を明文化し、ドキュメント化する。日本の法令や契約（著作権、肖像権等）も踏まえて社内ルールを作る。

- 証跡を残す  
  使用したモデル、プロンプト、出力日時、利用目的をログ化する。将来的な監査や外部問い合わせに備え、メタデータを体系的に保管する。

- 人間検証の工程を保持する  
  プロトタイプ用途は許容しても、最終アセットは人手による検査・編集を必須にする。演技や声の代替は出演者の同意や報酬配分を明確に。

- 小さく試し、評価指標を決める  
  生成AI採用はパイロットで試験。品質（アート/ライティング/音声の整合性）、コスト、リスク評価を定量化して意思決定する。

- 透明性とコミュニティ対応  
  外部へはAI利用の有無・範囲を明示する。コンテストや配信での公表は信頼維持に直結する。

