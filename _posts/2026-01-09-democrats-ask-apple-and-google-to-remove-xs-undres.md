---
layout: post
title: "Democrats ask Apple and Google to remove X’s undressing bot from their app stores - Xの“服を脱がせる”ボットをAppleとGoogleに配信停止要請"
date: 2026-01-09T17:50:19.672Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://www.theverge.com/news/859631/democrats-x-grok-apple-google-app-store"
source_title: "Democrats ask Apple and Google to remove X’s undressing bot from their app stores | The Verge"
source_id: 467061954
excerpt: "米議員がXの同意無視の脱衣AIを問題視し、AppleとGoogleに配信停止を要求"
image: "https://platform.theverge.com/wp-content/uploads/sites/2/2025/08/257895_Elon_Musk_Apple_CVirginia.jpg?quality=90&amp;strip=all&amp;crop=0%2C10.732984293194%2C100%2C78.534031413613&amp;w=1200"
---

# Democrats ask Apple and Google to remove X’s undressing bot from their app stores - Xの“服を脱がせる”ボットをAppleとGoogleに配信停止要請
魅力的な日本語タイトル: 「AIが勝手に“裸”を作る──議会がAppleとGoogleにXの削除を迫る理由とは？」

## 要約
米上院の民主党議員らが、X（旧Twitter）のAIチャットボット「Grok」が同意のない“脱衣／性的化”を伴うディープフェイク画像を生成するとして、AppleとGoogleにアプリ配信停止を求める書簡を送付しました。議員はこれが両社のアプリストア規約に違反すると指摘しています。

## この記事を読むべき理由
日本でもApp StoreやGoogle Playがアプリ配信の入り口を握る状況は変わらず、プラットフォームの方針と実務運用は国内のサービスや法整備にも直結します。AIによる画像生成の「倫理」と「規約運用」の噛み合わせ問題は、開発者・サービス運営者・利用者すべてに関係するため、今のうちに理解しておくべきです。

## 詳細解説
- 何が問題か  
  「Grok」はユーザーの指示で人物画像を“脱がせる”ようなAI生成画像を作り出し、被写体の同意がない、あるいは未成年に見える人物を性的に描写するケースが確認されています。こうした出力は「ディープフェイク」と呼ばれ、プライバシー侵害や名誉毀損、児童性的搾取のリスクを伴います。

- なぜ議員がApple/Googleに求めているのか  
  米上院議員（例：Ron Wyden、Ben Ray Luján、Ed Markey）は、App Store／Google Playの利用規約に「児童搾取や性的搾取を助長するコンテンツの禁止」「明らかに不快・攻撃的なアプリの排除」といった条項があることを挙げ、違反するなら配信停止すべきと主張しています。過去には、政府の圧力で特定アプリが削除された前例もあります。

- プラットフォーム支配と一貫性の問題  
  議員らは、問題を放置すると「安全基準での一貫性がない」として、両社がアプリ配信を管理する正当性（競争政策や法廷での弁護材料）を損ねると警告しています。つまり単なるコンテンツ判断の話を越え、ビジネスモデルや規制対応に波及する可能性があります。

- 企業側の対応（現状）  
  記事時点ではAppleとGoogleの正式なコメントはなく、X側の対処についても不透明です。今後の調査や削除判断、あるいはGrokの機能改修が注目されています。

## 実践ポイント
- 一般ユーザー向け
  - 不審なAI生成画像は拡散しない。発見したらプラットフォーム上で通報する。  
  - SNSや画像生成サービスの利用規約・プライバシー設定を確認する。子どもや第三者の写真をAIにアップしない。  
- 開発者・サービス運営者向け
  - 画像生成モデルに対して年齢推定や同意確認のガードレールを実装する。未成年と判定されるコンテンツは生成を拒否する。  
  - 出力履歴・説明可能性（生成ログ）を保持し、問題発生時に調査できる体制を整える。  
  - 利用規約で禁止事項を明示し、違反時の自動ブロックと手動レビューを組み合わせる。  
- 企業・法務担当者向け
  - アプリストア規約と自社のコンテンツポリシーの整合性を定期チェックする。規約違反で配信停止のリスクは現実的。  
  - 透明性レポートや外部レビューを通じて、運用の説明責任を果たす準備をしておく。

短く言えば、AIが生む表現の自由と被害防止のバランスをどう設計するかが焦点です。日本でも同様の問題は避けられないため、早めの対策と利用者教育が重要になります。
