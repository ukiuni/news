---
layout: post
title: "Letting Claude play text adventures - Claudeにテキストアドベンチャーを遊ばせる"
date: 2026-01-22T00:18:04.414Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://borretti.me/article/letting-claude-play-text-adventures"
source_title: "Letting Claude Play Text Adventures"
source_id: 46652173
excerpt: "Claudeで長期テキスト冒険を遊ばせ、記憶とコストの問題と改善策を実証"
image: "https://borretti.me/assets/card/letting-claude-play-text-adventures.webp"
---

# Letting Claude play text adventures - Claudeにテキストアドベンチャーを遊ばせる

AIに長期タスクを任せると何が起きる？——Claudeで「巨大テキストアドベンチャー」を攻略させて見えた設計課題

## 要約
著者はClaude（大規模言語モデル）をdfrotzで動くテキストアドベンチャーに接続し、エージェント設計（ハーネス）とトークンコストが長期的なプレイ性能にどう影響するかを検証した。単純な全履歴イン・コンテキストは動くが高コスト、メモリを分離すると低コストだが迷走する、という結論を示す。

## この記事を読むべき理由
ゲームは長期目標・探索・状態管理が必要な「制御された長期タスク」の代表例で、LLMを使ったエージェント設計やコスト最適化、記憶設計の実践的示唆が得られる。日本でも自動化エージェントや対話系AI運用の現場で直結する知見です。

## 詳細解説
- 実験対象と狙い：著者はハッカソンで、SOARやACT-Rのような認知アーキテクチャ的ハーネスをLLMエージェントに適用できるかを試したく、長期的・階層的世界を持つテキストアドベンチャー（例：Anchorhead）を評価タスクに選んだ。  
- 実装の概要：Z-machine実行環境（dfrotz）をPythonからstdin/stdoutでラップし、ゲーム出力→エージェント→コマンドというループを作成。エージェントは抽象的なPlayerインターフェースを実装する形。  
- トリビアル・ハーネス：ゲームの全履歴をそのままコンテキストに投げる方法。性能は出るが、長いプレイで入力トークンが膨れ上がりコストが破綻する。  
- メモリ・ハーネス：直近数ターン（作業記憶）＋追記可能なセマンティック・メモリを与える設計でトークン削減を図るが、結果は芳しくない。モデルはメモリを過剰蓄積して編集しない、赤いニセ手がかりに固執するなどの行動を示し、探索が非効率化してしまった。  
- 小規模世界の試行：短い脱出系や強盗系の小さなゲームではトリビアル・ハーネスで十分勝てるが、そうしたゲームは単純すぎて一般性に欠ける。一方でAnchorheadのような大規模世界は現実的だが試行コストが高い。  
- 観察された問題点：長い履歴は注意散漫とコスト、限定履歴＋単純メモリは局所最適化や冗長メモリ蓄積、メモリ編集の欠如、迷子・ループ行動など。  
- 提案される改良案：ドメイン特化メモリ（TODO/地理/オブジェクト辞書など）の分離、自動的／手動の地理情報構築（部屋グラフ化、link(room,direction,other)ツール）、試行終了時のエピソード要約による学習と再利用。

## 実践ポイント
- dfrotz等の既存インタプリタをstdin/stdoutでラップしてまずはプロトタイプを作る。  
- 小さいゲームでハーネスを試し、トークン消費と行動傾向を計測する。  
- 作業記憶（直近Nターン）＋永続メモリ（読み書き可能）という二層を試すが、必ず「削除・編集」機能を用意すること。  
- 部屋/接続のグラフを自動構築またはツール経由で明示的に与え、ジオグラフィー作業をモデルから切り離す。  
- セッション終了時に要約（エピソード記憶）を作り、次回起動時に要約を参照させることで起動コストを削減する。

著者のリポジトリは参考実装があるので、LLMエージェント設計を学ぶ良い出発点になります。
