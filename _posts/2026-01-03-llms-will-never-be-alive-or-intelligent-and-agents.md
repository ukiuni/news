---
  layout: post
  title: "LLMs will never be alive or intelligent, and \"agents\" will never know and cater to our every need - LLMは生き物でも知能でもないし、「エージェント」が全ての望みに応える日は来ない"
  date: 2026-01-03T19:53:50.634Z
  categories: [tech, world-news]
  tags: [tech-news, japan]
  source_url: "https://hatwd.com/p/llms-will-never-be-alive-or-intelligent"
  source_title: "LLMs will never be alive or intelligent - by Thane Thomson"
  source_id: 473195986
  excerpt: "LLMは高精度の補助に留まり、長手順自動化とOS級エージェントは誤差・セキュリティで危険だ"
  image: "https://substackcdn.com/image/fetch/$s_!s6jL!,w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4465af5-2033-4655-af7a-ca67c197b1f9_1920x1282.jpeg"
---

# LLMs will never be alive or intelligent, and "agents" will never know and cater to our every need - LLMは生き物でも知能でもないし、「エージェント」が全ての望みに応える日は来ない
AIブームの幻想を切る：トークン予測機と「万能エージェント」の限界

## 要約
LLMは優秀な確率的トークン予測器に過ぎず、自律的に「より良い」状態を感知して行動する能力はない。複数ステップの自動化では誤差が累積し、「OSレベルのエージェント」はセキュリティとプライバシーのリスクを高めるだけだという警告。

## この記事を読むべき理由
日本でも生成AIの導入が急速に進む中で、過度な自動化期待やエージェント統合への盲信はコストとリスクを招きます。エンジニアやプロダクト責任者が現実的な運用設計と安全対策を考えるための考点を得られます。

## 詳細解説
- 本質：LLMは「次に来るトークン」を確率的に予測するモデルであり、内部に主体的な「目的」や「価値基準」を持たない。出力が賢く見えても、それは大量の人間言語の統計的パターンに基づくもので、意識や自己目的性ではない。
- 新規問題への限界：ソフトウェア開発や未学習の問題では、既存データに対応する解が存在しないことが多い。人間は問題分割、要件設計、妥当性判断を行い、LLMの提案を統合／検証する必要が残る。
- 学習データの偏り：プロプライエタリなコードや高品質データが訓練に含まれない場合、LLMは特定クラスの解法を「総合的に予測」できない可能性がある。さらにハイパーパラメータやプロンプト／デコーディング設定で出力品質が変わる。
- エージェントの誤差累積：複数ステップを踏む自動化タスクでは、各ステップの成功確率が掛け合わされるため全体成功率は急速に低下する。例えば1ステップ成功率が $0.95$ の場合、$n$ ステップでの成功確率は
$$
0.95^n
$$
。30ステップでは約 $0.95^{30}\approx0.2146$ と低下する。仮に $0.99$ なら $0.99^{30}\approx0.7397$ に改善するが、長大なワークフローでは依然不安定だ。
- プライバシーとセキュリティ：エージェントに深いコンテキスト（OSレベルやユーザ行動）を与える設計は、監視リスクと攻撃対象の拡大を招く。特に銀行情報や業務データを扱う日本企業では、法規制（個人情報保護）や顧客信頼の観点から慎重な設計が必要。

## 実践ポイント
- 人間とAIの役割分担を明確に：LLMは「提案」や「ドラフト作成」向きと割り切り、意思決定・検証は人間が担当するワークフローを設計する。
- 小さなタスクに分割して検証を入れる：長いチェーンを避け、各ステップで自動判定の閾値と人間レビューを挟む。
- 失敗確率を定量化する：ステップ成功率 $p$ を見積もり、全体成功確率 $p^n$ を計算して許容できるか判断する。
- データガバナンスを徹底する：モデルに渡すデータを最小限にし、機密情報は匿名化／オンプレモデルで処理する。日本の法令や業界基準を順守すること。
- エージェント設計は段階的に：まずは限定ドメインのアシスタント（例：トランザクション分類の補助）で検証し、監査ログとロールバックを用意する。
- ツール選定：金融や医療など高リスク領域では、ブラックボックスAPIより説明可能性（explainability）の高いモデルやオンプレ実装を優先する。
- モニタリングと継続学習：誤出力の頻度を監視し、ヒューマンフィードバックでモデル運用ルールを定期的に更新する。

以上を踏まえれば、LLMやエージェントは強力な補助ツールになり得るが、「万能エージェント」神話に踊らされず、設計と運用でリスクを制御することが日本の現場での成功の鍵です。
