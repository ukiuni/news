---
layout: post
title: "Peer-reviewed study: AI-generated changes fail more often in unhealthy code (30%+ higher defect risk) - 査読済み研究：AI生成の変更は“不健康”なコードで失敗しやすく（欠陥リスク $30\%+$ 増）"
date: 2026-02-17T09:03:36.612Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://codescene.com/hubfs/whitepapers/AI-Ready-Code-How-Code-Health-Determines-AI-Performance.pdf"
source_title: "Peer-reviewed study: AI-generated changes fail more often in unhealthy code (30%+ higher defect risk)"
source_id: 440908048
excerpt: "査読研究：不健康なコードではAI修正の欠陥リスクが$30\%+$増加"
---

# Peer-reviewed study: AI-generated changes fail more often in unhealthy code (30%+ higher defect risk) - 査読済み研究：AI生成の変更は“不健康”なコードで失敗しやすく（欠陥リスク $30\%+$ 増）

AIが自動で直したつもりが、実は「壊して」しまう――導入前に知っておくべきリスクと現場対策

## 要約
査読済みの調査は、AI（生成系ツール）によるコード変更が、コードの「健康度」が低い箇所では欠陥を生みやすく、欠陥リスクが $30\%+$ 増加することを示しています。

## この記事を読むべき理由
日本の企業はレガシーや高い品質要件を抱えるケースが多く、AI導入を進める前に「どのコードでAIを使うか」「どう検証するか」を知っておかないと、コスト増・品質低下につながる可能性が高いためです。

## 詳細解説
- 研究の着眼点：AI生成の変更（自動補完やPR支援など）を実運用の変更と比較し、変更後の欠陥発生率をコードの健康度別に解析。コード健康度は複数のメトリクス（複雑さ、ホットスポット、過去のバグ密度や変更頻度など）で評価されます。  
- 主な発見：コードが「不健康（高複雑・頻繁に変更される・テスト不足）」な領域では、AIが生成した修正が既存の脆弱性や設計の脈絡を無視してしまい、欠陥発生確率が有意に上昇。定量的には $30\%+$ の上振れが確認されたと報告されています。  
- なぜ起きるか：AIは文脈（設計意図・暗黙の前提・周辺副作用）を完全には把握できず、表面的に「良さそう」な変更を提案してしまう。特にモノリシック、相互依存が強い日本の業務システムやテストが薄い領域で影響が大きい。  
- 検証条件：研究は査読済みであり、さまざまな言語・リポジトリを横断して解析している点が信頼性の根拠。ただしツールやモデルの種類、プロンプト設計、レビュー体制で結果は変わり得ます。

## 実践ポイント
- まず「コード健康度」を計測する（複雑度・ホットスポット・テストカバレッジを可視化）。  
- AIは「健康なモジュールから段階的に」導入する。低リスク領域で運用実績を作る。  
- 変更は小さなPRに限定し、必須でテストとCIを通す。自動生成でも必ず人間レビューを入れる。  
- ホットスポットやレガシー部分はリファクタ優先：AIは補助に留め、設計改善で根本対策を。  
- 効果測定を行う（導入前後で欠陥率やリワーク時間を定量化）。A/Bで安全性を検証する。

この研究は「AIを使えば楽になる」という期待を現場向けに現実化するための警告でもあります。導入は“どこで・どう使うか”を設計してから。
