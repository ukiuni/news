---
layout: post
title: "ANN v3: 200ms p99 query latency over 100B vectors - ANN v3：1000億ベクトルで p99 200ms"
date: 2026-01-25T14:39:58.403Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://turbopuffer.com/blog/ann-v3"
source_title: "ANN v3: 200ms p99 query latency over 100 billion vectors"
source_id: 46710747
excerpt: "階層クラスタ＋1bit量子化で1000億ベクトルをp99200msで検索"
image: "https://turbopuffer.com/api/og?title=ANN%20v3%3A%20200ms%20p99%20query%20latency%20over%20100%20billion%20vectors"
---

# ANN v3: 200ms p99 query latency over 100B vectors - ANN v3：1000億ベクトルで p99 200ms
1000億ベクトルを200msで返す秘訣──turbopuffer ANN v3 が示す「近似と圧縮」の最前線

## 要約
turbopuffer の ANN v3 は、1024次元・約1000億ベクトル（約200TiB）という巨大データセットに対して、p99 200ms を目標にした高速近似近傍検索を実現します。鍵は「階層クラスタリング」で探索空間を絞り、「二値化（RaBitQ）」でデータ帯域を激減させる設計です。

## この記事を読むべき理由
大規模埋め込み（推薦・検索・生成AIのベクトル検索）が日本のプロダクトでも急速に普及中。100億〜1000億規模を扱う際の現実的なボトルネックと、その回避方法（ソフトウェア設計とハードウェアの使い方）が学べます。

## 詳細解説
- スケールの課題  
  - 前提：$100\text{B}$ ベクトル × 1024 次元 × 2 bytes（f16）で約200TiBのデータ。目標は p99 ≤ 200ms、かつ高QPS（>1k）。  
  - 直感：ベクトル内積は要素ごとに1回しか使わないため算術強度が低く、処理は「メモリ帯域（bandwidth）制約」になりやすい。

- メモリ階層とボトルネック（概念）  
  - レジスタ → L1/L2/L3 キャッシュ → DRAM → NVMe → オブジェクトストレージ（S3等）という階層があり、上位ほど小さく高速、下位ほど大容量だが帯域が遅い。  
  - 目的は「上位キャッシュを活かしつつ、下位の帯域に依存しない」探索を作ること。

- ANN v3 の2大テクニック  
  1. 階層クラスタリング（SPFresh / SPTAG由来）  
     - セントロイドで木構造を作り、まず上位センターで「どのクラスタを探すか」を絞る。これによりオブジェクトストレージへの往復を木の高さに限定し、コールドアクセスの尾部遅延を抑える。  
     - 実装上は幅広・浅い木（例：各ノードの分岐 ≈100）を採用し、セントロイドはDRAMに乗せられるよう設計。空間的・時間的局所性が生まれる。  
     - 実験的に、1台あたり約500クラスタ（各クラスタ100ベクトル）を走査すれば十分なリコールが得られた。これが読み出し帯域の基準になる：  
       $$500\times100\times1024\times2\ \text{bytes}\approx100\ \text{MB（レベル当たり）}$$

  2. 二値化（RaBitQ）による圧縮  
     - 挿入時に元の高精度ベクトル（f16/f32）とは別に、1ビット/次元の量子化ベクトルを生成。高次元の性質（concentration of measure）を利用し、16〜32倍の圧縮を実現しつつ高リコールを維持する。  
     - ワークフローは「量子化されたベクトルでおおまかに候補を選び、候補に対して元の高精度で再評価（精密化）」という近似→精密化のパターン。これにより NVMe 等の下位ストレージから読み出すデータ量を劇的に削減。

- 帯域で見た効果（概算）  
  - 階層クラスタリングのみだと、NVMe帯域（例：~10GB/s）で約100 QPS 程度に制限されるが、量子化を組み合わせると実効帯域が下がり、数百〜千QPSクラスが現実的になる。

## 実践ポイント
- あなたの検索がメモリ帯域か演算（CPU/GPU）かをまず測る（算術強度の概念を適用）。ベクトル内積が主ならメモリ最適化優先。  
- クラスタリングで「幅広・浅い木」を試す（分岐 ≈100 が目安）。セントロイドはDRAMに収める設計を。  
- 量子化（1-bit 等）を導入して「候補選択→再評価」の2段階ワークフローにする。RaBitQ のような高次元向け手法が有効。  
- キャッシュ戦略を検討：ツリー構造をSSDに常駐させ、頻出セントロイドはDRAMに維持する。Cold path のオブジェクトストレージ往復を最小化する。  
- 日本市場への注意点：クラウドリージョンのストレージ帯域／出力コスト、オンプレでのNVMe配備、埋め込み生成（日本語固有のトークン化やモデル特性）の影響を考慮する。  
- 実験指標：p50/p95/p99 レイテンシ、QPS、リコール（R@k）、SSD/DRAM 帯域使用率を常時監視し、プローブ数（beam width）をチューニングする。

元記事は大規模ベクトル検索における「設計哲学（ハードとソフトのバランス）」を示しています。日本のサービスでも、データ量が増えるほど「近似＋圧縮＋階層化」が費用対効果とユーザー体験両面で鍵になります。
