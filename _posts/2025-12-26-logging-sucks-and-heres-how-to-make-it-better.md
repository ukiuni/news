---
layout: post
title: Logging Sucks - And here's how to make it better.
date: 2025-12-26 03:55:38.315000+00:00
categories:
- tech
- world-news
tags:
- tech-news
- japan
source_url: https://loggingsucks.com/
source_title: Logging Sucks - Your Logs Are Lying To You
source_id: 438361913
---
# ログは嘘をつく — その原因と「読み取れるログ」へ変える実践ガイド

## 要約
生ログはノイズと矛盾に満ちており、障害調査やパフォーマンス改善ではむしろ誤誘導することが多い。構造化、相関、サンプリング、そしてログよりメトリクス/トレースと組み合わせることで、初動と根因追跡の両方を格段に改善できる。

## この記事を読むべき理由
日本のプロダクトは規模や法規制（個人情報保護、金融系要件）でログ活用の難易度が高く、誤ったログ運用はコスト増・誤アラート・調査遅延につながる。今すぐ取り入れられる実践策を知ることで、現場の工数と運用コストを減らせる。

## 詳細解説
元記事のサンプルログを見ると、よくある「ログが嘘をつく」パターンが見て取れます。

問題点の整理
- フォーマットの不統一：INFO / info / warn / WARN といった表記ゆれ、キー名のばらつきで検索や解析が難しい。
- ノイズ過多：start/complete/heartbeat が大量にあると重要なイベントが埋もれる（シグナル対ノイズ比の低下）。
- 意味の無いレベル運用：重要なメトリクス（DBプール枯渇やメモリ圧迫）がINFO扱いだったり、逆に冗長なデバッグが高レベルだったりする。
- 文脈欠如：リクエスト単位の相関ID（trace_id/request_id）はあるが一貫して付与されていないとトレースが切れる。
- 機密情報混入：IPやtokenクレーム、ユーザIDなどが平文で出力されていると法令対応や漏洩リスクが増す。
- 重複と冗長：同じログが大量に繰り返される（サンプルに重複行あり）とストレージコストと解析時間が増加。
- ログだけで切り分けようとする：レイテンシや呼量はメトリクス、トレースで見るべきだがログに頼りすぎる。

改善の核となる考え方
1. 構造化ログ（JSONなど）を標準にし、キー命名・レベル体系を定義する。これでクエリやダッシュボード作成が簡単になる。
2. 相関ID（trace_id/request_id）を全レイヤで必ず渡す。失われたトレースは調査ロスの元。
3. ログは「イベントの記録」、メトリクスは「傾向と閾値の監視」、トレースは「遅延箇所特定」と役割分担する（Observability三本柱）。
4. 高頻度イベントはサンプリングまたは集約（カウント/ヒストグラム）し、フルログはエラーやサンプリングで保存する。
5. PIIは生成側でマスク・トークン化。ログの保存ポリシーとアクセス制御を厳格化する。
6. アラートは個々のログではなく集計指標や異常検知（例：DB待ちリクエスト数が閾値を超える）に紐付ける。

実際の適用例（サンプルログを踏まえて）
- 「Database connection pool exhausted」 → 単にエラーを吐くだけでなく pool_size、待ち行列長、平均クエリ時間をメトリクス化してアラート化。ログはサンプルとして保持。
- 「Slow database query detected」 → クエリ文字列をログに残す前にハッシュ化してクエリテンプレートで集計。高頻度のクエリはプロファイリングで最適化。
- JWTやIPといった敏感情報はログ内で不要なら省略、必要ならマスクして保存期間を短くする。
- 「Deprecated API version detected」 のような運用ログはカウントしてクライアント別に通知をトリガーする（通知先は開発/プロダクトチーム）。

## 実践ポイント
すぐに取り組めるチェックリスト（優先度順）
1. 構造化ログの標準作成（timestamp ISO8601, severity, service, env, version, trace_id/request_id, message, context JSON）
2. 全マイクロサービスで相関IDを強制伝搬するミドルウェアを実装
3. 高頻度イベントのサンプリング設定と集約メトリクス化（例：error_rate, p95_latency, db_waiting_count）
4. 機密情報の出力ルールを定義し実装（PIIマスキング、自動スキャン）
5. ログのライフサイクル管理：ホット（検索用）・ウォーム（アーカイブ）・コールド（長期保管）をS3/オブジェクトストレージで設計
6. アラートは「個別ログ」ではなく「集計メトリクス」に紐づける（ノイズ激減）
7. ログパイプラインには Fluentd / Vector / Logstash を用い、検証済みのパーサとスキーマバリデータを導入

日本市場への注目点
- Fluentd は日本発のログコレクタで、国内企業の導入実績が豊富。企業ポリシーやオンプレ混在環境での柔軟性が強み。
- 個人情報保護法や金融系の監査要件を満たすため、ログ設計時にマスキングと保持期間を明確化することが必須。
- JSTタイムゾーン表記やマルチバイト文字の取り扱い（エンコーディング）に注意すること。ログ解析ツールとインデクサが UTF-8 を前提にしているか確認。

