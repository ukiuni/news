---
layout: post
title: "AI generated tests as ceremony - AI生成テストは「儀式」か"
date: 2026-01-26T14:17:41.932Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://blog.ploeh.dk/2026/01/26/ai-generated-tests-as-ceremony/"
source_title: "AI-generated tests as ceremony"
source_id: 417153846
excerpt: "AI自動生成テストの儀式化を防ぎ、失敗確認で品質を担保する方法"
image: "https://blog.ploeh.dk/assets/themes/ploeh/images/favicons/favicon.png"
---

# AI generated tests as ceremony - AI生成テストは「儀式」か
「AIにテストを書かせれば安心？――見落としがちな“証明”の欠如と現場で使える対策」

## 要約
LLMにテストを自動生成させる流れは増えているが、テストを人が観察して失敗を確認するという科学的方法を省くと、テストが単なる形式的な“儀式（cargo‑cult）”になりかねない、という警鐘。

## この記事を読むべき理由
日本の開発現場でもLLM活用は進む一方で、テスト文化が成熟していないチームだと自動生成テストに依存して品質の落とし穴に嵌りやすい。特に安全性や規制が厳しい業界では、生成プロセスの「検証」をどう担保するかが重要です。

## 詳細解説
- 主張の核：自動テストは「テストを書く→失敗を確認→実装→再確認」という観察を伴う科学的プロセスで成立する。LLMが既存コード向けにテストを生成すると、その「テストが失敗するところを見た」経験を飛ばしてしまい、テストの信頼性が薄れる。
- 問題点
  - 人がコードを眺めて「大丈夫そう」と判断してもバグは残る（ギャップル・マンの忘却に類似）。
  - LLM生成テストは見た目だけ正しくても、トートロジーな断言（常に真になるアサーション）やシステムと無関係な“シミュレーション的”テストを生む危険がある。
  - テストが増えても、それが真の保証になっているかは別問題。形式的なチェックインで安心してしまうと「儀式的」になる。
- 技術的提案（元記事の提案を整理）
  - Characterization Testing：既存コードに対して一時的にSUTを壊してテストが赤になることを確かめる手法。これによりテストが本当に問題を検出するか検証できる。
  - LLMとTDDを組み合わせる運用：人が「テストを書かせる→レビュー→実行して赤を確認→実装を生成させる→レビュー」という工程を厳密に守るならエピステモロジカルに妥当。
  - 逆転アプローチ：人がテストを書き、LLMにSUT実装を生成させるブラックボックス的TDDも検討可能。
  - テスト批評の仕組み（テストの批判・レビュー）を制度化する必要性。

## 実践ポイント
- まず「失敗を見る」習慣を復活させる：生成テストでも必ず意図的に失敗を確認する（Characterization Testing）。
- LLMにTDDをやらせるなら、ステップごとに人のレビューを挟む（テスト作成→赤確認→実装→テスト再確認）。
- 自動生成テストのレビュー項目例：意味のあるアサーションか／外部依存を模擬しているか／偽陽性／偽陰性の可能性。
- 重要システムは「人が書いたテスト」か「人が検証したテスト」を優先。規制や安全要件のある領域では自動生成のみでOKにしない。
- ワークフロー改善：CIでの自動実行に加え、レビューチェックリストと失敗確認の手順をテンプレ化して運用する。

（短くまとめると）LLMは生産性向上に有益だが、テストの「観察と検証」を省くと安全保障にならない。自動化はツールであり、プロセス設計と人の関与が品質を決める。
