---
layout: post
title: "Google says attackers used 100,000+ prompts to try to clone AI chatbot Gemini - 攻撃者が10万超のプロンプトでAIチャットボットGeminiのクローン化を試みたとGoogleが発表"
date: 2026-02-12T16:28:50.882Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://www.nbcnews.com/tech/security/google-gemini-hit-100000-prompts-cloning-attempt-rcna258657"
source_title: "Google: Gemini hit with 100,000+ prompts in cloning attempt"
source_id: 443550140
excerpt: "Googleは10万超のプロンプトでGeminiの内部を抽出しようとする大規模攻撃を警告"
image: "https://media-cldnry.s-nbcnews.com/image/upload/t_nbcnews-fp-1200-630,f_auto,q_auto:best/rockcms/2026-02/260211-google-ww-1810-a0892a.jpg"
---

# Google says attackers used 100,000+ prompts to try to clone AI chatbot Gemini - 攻撃者が10万超のプロンプトでAIチャットボットGeminiのクローン化を試みたとGoogleが発表

10万回以上の「質問」でAIの“頭脳”を盗もうとした実態 — 日本の企業にも迫るリスクと防御の第一歩

## 要約
Googleは、攻撃者がGeminiに対して大量プロンプト（あるケースで10万回超）を投げて内部ロジックを抽出しようとする「ディスティレーション攻撃（モデル抽出）」が増えていると報告。商業目的で行われ、主に民間企業や研究者が関与していると見られる。

## この記事を読むべき理由
日本でも企業やスタートアップが独自の大規模言語モデル（LLM）やカスタムAIを導入・開発する流れが加速中。モデルの「中身」を他者に盗まれると知財や競争力を失う可能性があり、具体的な防御策を今から知っておく必要があるため。

## 詳細解説
- ディスティレーション攻撃（モデル抽出）とは：外部から大量に問い合わせ（プロンプト）を送り、応答パターンを解析してモデルの振る舞いやアルゴリズム的特徴を再現しようとする手法。ブラックボックスを多数の質問で叩いて内部設計を推測するイメージ。
- 規模と手口：Googleは1件のキャンペーンで10万回超のプロンプトを確認。攻撃は世界中で観測されており、単発ではなくシステマティックに行われる。特に「reasoning（推論）」や判断ロジックを引き出すよう工夫された質問が多い。
- 動機：自社モデルの強化や競争優位の獲得を目的とした商業的行為。大手がターゲットになると同様の手口が中小のカスタムLLMにも波及する恐れがある。
- 技術的脆弱性：公開APIやウェブ上で誰でも利用できるモデルは、アクセス性ゆえに抽出リスクが高い。検知や遮断の仕組みはあるが、根本的な脆弱性は残る。
- 前例と業界動向：OpenAIが類似の抽出攻撃を巡って競合を非難した事例など、業界全体で問題視されている。

## 実践ポイント
- ログと異常検知を整備：大量リクエストや類似プロンプトの連続を自動で検出するアラートを導入する。
- レート制限とクォータ管理：IPやAPIキー単位で呼び出し制限を設定。
- アクセス制御強化：認証、MFA、IPホワイトリスト、企業内限定のエンドポイントを活用。
- 出力のウォーターマーク/トレーサビリティ：生成物に識別子を埋めて盗用元を追跡可能にする（技術的・法的抑止）。
- プライバシー強化：差分プライバシーや出力フィルタで機密情報の露出を減らす。
- 法務・契約整備：利用規約やAPI利用契約で抽出行為を禁止し、違反時の対応を明確化。
- 定期的なレッドチーミング：社内で模擬的に抽出攻撃を行い防御の有効性を検証する。

短期的には「アクセス管理」と「異常検知」が最も効果が高く、長期的には出力ウォーターマークや差分プライバシーといった設計レベルでの対策が必要です。日本の企業も自社モデルの機密性評価と防御計画を急ぐべきです。
