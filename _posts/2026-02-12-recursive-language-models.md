---
layout: post
title: "Recursive Language Models - 再帰的言語モデル"
date: 2026-02-12T14:18:41.851Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://alexzhang13.github.io/blog/2025/rlm/"
source_title: "Recursive Language Models | Alex L. Zhang"
source_id: 949977752
excerpt: "REPLで文脈を再帰処理、10Mトークン超でも精度維持しコスト削減するRLMの実務衝撃"
image: "https://alexzhang13.github.io/assets/img/preview/rlm.png"
---

# Recursive Language Models - 再帰的言語モデル

会話が「忘れる」を克服する！膨大な文脈を分割して再帰的に処理するRLMの衝撃

## 要約
RLM（Recursive Language Models）は、モデルが入力文脈を変数としてREPL環境で読み書きし、自分自身（あるいは別のLM）を再帰的に呼び出して巨大な文脈を効率的に処理する推論戦略です。長文文脈での「context rot」を抑えつつ、精度とコストの両面で有利になることを示しています。

## この記事を読むべき理由
日本のプロダクトやリサーチでは、法務文書、ナレッジベース、長いチャット履歴など「長文を正確に扱う」ニーズが増えています。RLMはリトリーバー不要で10M+トークン規模の文脈でも性能劣化しにくく、コスト効率も良い可能性があるため実務的インパクトが大きいです。

## 詳細解説
- 背景（context rot）
  - 文脈トークンが増えるとモデルの記憶・参照精度が落ちる現象を「context rot」と呼び、従来の長文対策は限界がありました。

- RLMの骨子
  - RLMは薄いラッパーで、見た目は通常のモデル呼び出しと同じですが、内部でREPL（Pythonノートブック風）に文脈を変数としてロードし、モデルがその変数をプログラム的に「peek/partition/grep」できるようにします。
  - ルートLM（depth=0）はサブLM呼び出し（depth=1）を生成でき、サブ呼び出しの結果を組み合わせて最終応答を出します。形式的には $$RLM_M(q, C)$$ が環境 $\mathcal{E}$ の下で部分呼び出し $$RLM_M(\hat q, \hat C)$$ を立てるイメージです。

- 実装上のポイント
  - 環境としてのREPLは、モデルがコードブロックを書き、その実行結果を参照できる仕組み。最終出力は `FINAL(...)` 等のタグで返すフロー。
  - 実験では深さ1の再帰で十分な効果を確認（将来的に深さを伸ばす余地あり）。
  - サブクエリに小型モデルを使うことでコストを下げる戦略が有効。

- 結果ハイライト
  - OOLONG（長文推論ベンチ）で GPT-5-mini を使ったRLMは GPT-5 に比べ正答数を2倍にし、クエリ当たりの平均コストも低くなったという報告。
  - BrowseComp-Plus 系のDeep Researchタスクでも、ReAct＋BM25のような手法を上回り、10M+トークンでも性能劣化が見られなかった点が注目されます。

- 既存手法との関係
  - ReAct/CodeActのようなエージェント手法と似るが、RLMは「文脈を解釈するための手段」としてREPL＋再帰呼び出しをモデルに委ねる点が異なる。
  - 再帰的にどのように分割・検索・組み立てするかは学習可能で、強化学習で最適化する期待もあります。

## 実践ポイント
- 小さく試す：まずは rlm-minimal 相当の実装で、文脈を文字列変数に入れ、モデルに正規表現で絞らせてサブ問い合わせするワークフローを試す。
- サブ呼び出しモデルを使い分ける：ルートは高性能モデル、細部検索は小型モデルでコストを抑える。
- チャンク戦略をモデルに任せる：手動でチャンクするより、モデルに「どこを見るべきか」を決めさせるほうが強力な場合がある。
- 深さと出力管理：まずは深さ1で安定性確認、最終出力は明確なタグ（例: FINAL）で管理する。
- 日本語データで評価：法務/契約書やFAQの長文タスクでRLMを試し、context rotの改善とコスト比較を行う。

公式のソースコードや論文は公開されているため、実験ベースで自社データに当ててみる価値は高いです。
