---
layout: post
title: "Japan calls on X to take measures against AI-generated sexualized images - XにAI生成の性的化画像への対策を要請"
date: 2026-01-16T15:37:15.589Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://english.kyodonews.net/articles/-/68660"
source_title: "Japan calls on X to take measures against AI-generated sexualized images"
source_id: 426795499
excerpt: "拡散急増する実在人物の性的AI画像に対し、日本政府がXへ対策と法的指導を要求"
image: "https://english-kyodo.ismcdn.jp/mwimgs/b/2/1200x/img_b225faaf5c9810b9b0855d7e5f84d14d715512.jpg"
---

# Japan calls on X to take measures against AI-generated sexualized images - XにAI生成の性的化画像への対策を要請
XのAIが“実在人物”を性的に変換する問題——政府が踏み込んだ本当の理由と、開発者・ユーザーが今できること

## 要約
日本政府がX（旧Twitter）の生成AIツールによる「実在人物の性的化画像」急増を受け、Xに具体的な対策と対応計画の提出を求めました。改善が見られない場合、AI関連法に基づく指導も視野に入れています。

## この記事を読むべき理由
日本国内で何千万単位の利用者がいるプラットフォームで起きている問題であり、個人の権利侵害や国内のAI規制・開発方針に直結します。エンジニアやサービス運営者、一般ユーザーにとって「見て見ぬふりができない」実務的インパクトがあるためです。

## 詳細解説
- 発端と状況  
  Xは生成AI「Grok」などの機能で、ユーザーが入力したプロンプトで画像を操作・生成できます。この機能を悪用し、実在する人物の顔や姿を性的に加工した画像が短期間で大量に投稿される事例が報告されました。対象は著名人だけでなく一般人も含まれ、拡散のスピードと手軽さが問題を深刻化させています。

- 法的・倫理的懸念  
  この種のフェイク画像は肖像権や名誉毀損、プライバシー侵害の問題を引き起こします。未成年や非同意の裸の描写は児童性的虐待素材（CSAM）や非同意ヌードに該当し、国際的にも各国政府が調査や規制強化を進めています。日本の内閣府はAI法の下で事業者の対応を監督する立場からXに改善を求めています。

- 技術的課題  
  生成AIの本質は「高品質な合成画像を短時間で大量に作れること」。検出側の課題は、偽造の検出、作成者の特定、モデル出力の説明性、リアルタイムなモデレーションのスケーラビリティです。対策としては出力にプロンプト/メタデータを付与する「プロヴィナンス」、AI出力の透かし（watermarking）、学習データの管理、フィルタリングや人間による確認（human-in-the-loop）などが考えられます。

- プラットフォームの対応と国際事情  
  Xは「優先度の高い違反コンテンツは削除する」と表明していますが、具体的な防止策や報告計画の提示が求められています。英国、カナダ、マレーシアなど他国も同様の懸念を表明しており、プラットフォーム側には多国間での説明責任が生じています。日本では過去にOpenAIの動画生成ツール「Sora」に対しても改善要求が出された経緯があります。

## 実践ポイント
- 開発者／サービス運営者向け  
  - 出力プロビナンス（生成履歴・メタデータ）の保存と公開を検討する。  
  - 出力画像へのロバストな透かし（見た目に影響しないメタ透かし）を実装する。  
  - 顔認識を使った非同意の人物変換を自動検出するルールと人手介入フローを整備する。  
  - モデル学習データの同意管理と除外ポリシーを明確化する。  
  - 報告窓口と削除プロセスを迅速化し、透明性レポートを定期公開する。

- 一般ユーザー向け  
  - 扱う写真に対して顔や個人情報を不用意に公開しない。  
  - 問題のあるコンテンツはプラットフォームの通報機能で速やかに報告する。  
  - 自分の画像が生成物に使われた疑いがある場合はスクリーンショット保存・削除要求・法的相談を検討する。

- 政策・法務担当者向け  
  - プラットフォームに対する説明義務と改善期限の設定、透明性要件を明確にする。  
  - 国内の著作権・人格権とAI規制の調整を進め、被害救済の実効性を高める。

Xのような大規模プラットフォームが生成AIの機能を提供する中で、「技術的可能性」と「人権保護」のバランスをどう取るかが、今後の国内外での議論の焦点になります。日本のエコシステムとしても、技術者・事業者・ユーザーそれぞれが対策を急ぐ必要があります。
