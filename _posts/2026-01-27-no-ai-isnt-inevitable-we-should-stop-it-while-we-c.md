---
layout: post
title: "No, AI isn't inevitable. We should stop it while we can. - AIは避けられないわけではない。今のうちに食い止めるべきだ"
date: 2026-01-27T14:16:05.647Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://www.usatoday.com/story/opinion/2026/01/24/ai-chip-manufacturing-data-centers-humanity/88215945007/"
source_title: "ChatGPT won't end humanity, but AI superintelligence might | Opinion"
source_id: 416302511
excerpt: "超知能の脅威を理由に先端チップと巨大データセンターの拡大を国際協調で止めるべきだと警告"
---

# No, AI isn't inevitable. We should stop it while we can. - AIは避けられないわけではない。今のうちに食い止めるべきだ
今こそ「AIブレーキ」をかける時：超知能のリスクを現実的に議論する

## 要約
著者は、汎用的・超知能AI（AIが自らを高速に改良する「再帰的自己改善」）の追求が人類の存続や民主主義に深刻なリスクをもたらすと警告し、先端AI向けチップやデータセンターの生産を抑制する国際的合意を提案しています。

## この記事を読むべき理由
- 日本は半導体供給網やデータセンター需要で世界と結びつくため、AI拡大の影響を直接受ける可能性が高い。
- 技術的・政策的対応はまだ間に合うという主張は、エンジニアや政策決定者にとって重要な議論の始点になります。

## 詳細解説
- 危険の本質：単なるチャットボット（例：ChatGPT）を超え、AIが自己改良を繰り返して人間をはるかに上回る「超知能」を生む可能性が懸念されている。著者は人類の絶滅や政治的影響力の喪失を現実的リスクとして挙げる。  
- ハードウェアの集中：最先端AIをスケールさせるには高度な半導体と露光装置が必要で、TSMCやASMLのような企業に供給が集中している。これを「核兵器級」の技術に譬え、製造停止や輸出管理による抑止が現実的で検証可能だと主張する。  
- データセンター問題：大量の電力・冷却と土地を必要とするデータセンターの建設は地域レベルでの抵抗を生んでおり、米国でも自治体によるモラトリアム（建設差し止め）が増えている。著者は各国が協調してデータセンター拡大を制限する必要を説く。  
- 国際合意の提案：人間クローン禁止や核拡散防止の協調に倣い、先端AIハードウェアや超知能開発を制御する国際ルールを作るべきだという論旨。著者はCenter for AI Safetyの声明など、学術・市民レベルの危機感を背景にしている。  
- 著者情報：David Krueger（モントリオール大学助教、Evitable創設者）。AI安全分野で活動。

## 実践ポイント
- 技術者向け：AI安全（検証、堅牢性、透明性）に関する知識を学び、職場でリスク評価を提案する。  
- 企業／政策担当者：サプライチェーン依存の把握、影響評価、社内外の透明性と監査を強化する。  
- 市民／地域コミュニティ：データセンター計画や土地利用の公共議論に参加し、地方自治体への働きかけを行う。  
- フォローすべき動き：国際的な規制議論、主要半導体メーカーの政策、国内外のモラトリアムや条例の動向を注視する。

（出典：USA TODAY「No, AI isn't inevitable. We should stop it while we can.」を基に要約・再構成）
