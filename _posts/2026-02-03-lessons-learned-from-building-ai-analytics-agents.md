---
layout: post
title: "Lessons learned from building AI analytics agents: build for chaos - AIアナリティクスエージェント構築の教訓：カオスを前提に作る"
date: 2026-02-03T15:20:42.722Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://www.metabase.com/blog/lessons-learned-building-ai-analytics-agents"
source_title: "Lessons learned from building AI analytics agents: build for chaos"
source_id: 410269925
excerpt: "Metabot失敗から学ぶ、コンテキスト設計で現場のカオスに耐えるAI解析"
image: "https://www.metabase.com/images/posts/metabot-ai-talk-og.png"
---

# Lessons learned from building AI analytics agents: build for chaos - AIアナリティクスエージェント構築の教訓：カオスを前提に作る
破綻デモから学んだ「現場で動くAIエージェント」の設計法

## 要約
MetabaseチームのMetabot開発で起きた大失敗を起点に、「ハッピーパス」ではなく現実の混乱（カオス）を前提にした設計──特に“コンテキストエンジニアリング”の実践法を示す記事。

## この記事を読むべき理由
LLMを使ったデータ分析ツールを社内導入・開発しようとする日本のエンジニアやプロダクト担当は、デモでは動くが本番で壊れる失敗を避けるための具体的な設計パターンを学べるから。

## 詳細解説
- 何が壊れたか：複数チームが個別最適化したコンポーネントを統合した結果、LLMへ送るプロンプトが矛盾し「何をすべきか」分からなくなった。デモ用の綺麗なデータ前提では見えない問題。
- 本質的な課題：LLMはシステム全体を“理解”しない。与えられたコンテキスト窓（プロンプト）にフラットに情報が重ねられるため、矛盾や冗長が致命的。
- 有効だったアプローチ（コンテキストエンジニアリング）：
  1. LLM最適化されたデータ表現  
     - 生のAPIレスポンスをそのまま流さず、テーブル／フィールド／ダッシュボードなどを一貫したテンプレートでシリアライズ。階層化した定型フォーマットが誤解と幻覚を減らす。
  2. ジャストインタイムの指示（Just-in-time instructions）  
     - システムプロンプトに前倒しで詰め込むのではなく、ツールの結果やアクションが発生したタイミングで必要な説明を付与する。LLMは「今」出てくる文脈に注意を払う。
  3. 明示的なエラー回復ガイダンス  
     - 単なるエラーメッセージで終わらせず、代替操作や検索手順を返すとLLMが曖昧さを扱いやすくなる。
- ベンチマークの限界：エンジニアが作る「精密なプロンプト」では高スコアが出ても、実利用の曖昧な問い（例：「売上が下がったのはなぜ？」）には対応できない。ベンチは統合テスト的に扱い、プロダクションの実際の問い合わせとフィードバックで評価することが重要。
- コアメッセージ：ハッピーパスを磨くより、現場データの混乱・人の曖昧表現に耐えうる設計を優先する。

## 実践ポイント
- データ表現を標準化する：テーブル／フィールド／ダッシュボード用のLLM向けテンプレートを作る。
- 指示は発生時に渡す：ツール呼び出しの直後に「次に何をすべきか」を含める設計にする。
- エラーに復元手順を添える：エラー出力に検索候補やユーザー確認フローを含める。
- ベンチは統合テスト化：スコア低下＝何かが壊れた合図、合格は本番での動作保証ではないと認識する。
- 日本の現場向け留意点：レガシーDBや不統一な命名、ドメイン知識の欠如が多いので、セマンティック層（外部で定義する指標・外部キーなど）を先に整備すると効果が高い。
- 小さく試す：まずは限定されたダッシュボード領域でコンテキストエンジニアリングを適用し、実ユーザーの問い合わせで改善ループを回す。

以上。Metabotの実例は汎用的な教訓を与えるので、LLMを使った分析エージェントを作る際は「カオス前提」で設計を始めてください。
