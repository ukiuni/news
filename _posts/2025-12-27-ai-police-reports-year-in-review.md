---
layout: post
title: AI Police Reports: Year in Review - AI警察レポート：今年の振り返り
date: 2025-12-27 05:42:11.075000+00:00
categories:
- tech
- world-news
tags:
- tech-news
- japan
source_url: https://www.eff.org/deeplinks/2025/12/ai-police-reports-year-review
source_title: 'AI Police Reports: Year In Review | Electronic Frontier Foundation'
source_id: 46367195
excerpt: EFFとAxon事例で、生成AIが警察記録を不透明化し証拠破壊を招く危険と対策
---
# AI Police Reports: Year in Review - AI警察レポート：今年の振り返り

## 要約
米EFFが警鐘を鳴らす、警察向け生成AI（特にAxonのDraft One）が報告書の透明性・証拠性を損ねる実例と対策をまとめた年次レビュー。日本でも同様の問題が起こり得る。

## この記事を読むべき理由
警察記録は人の自由や裁判の根拠になるため、記録作成の自動化がもたらす誤記・改変・証拠隠滅リスクは社会インフラ上の重大な問題。日本で監視カメラや業務効率化ツールが広がる今こそ、技術仕様と運用ルールを先回りして検討すべきだから。

## 詳細解説
- 背景：Axonは米国で最有力のボディカメラサプライヤーであり、生成AIツールDraft Oneを警察向けに提供。音声を取り込み、AIが事件報告の草案を生成し、担当官が編集して提出するワークフローを想定している。
- 透明性の欠如：Draft Oneは「初稿」を保存せず、AIが提案した箇所と人間が編集した箇所を後で区別できない設計になっているとEFFが指摘。結果として、後日の矛盾が出た際に「AIが書いた」と主張して責任回避される恐れがある。
- 運用リスク：生成AIは事実を誤る（hallucination）ことがあり、偏りや差別的な表現を含む危険がある。捜査の根拠がAI出力に依存すると、冤罪や不当起訴のリスクが高まる。
- 証拠管理の破壊：RMS（Records Management System）へのコピーと同時にクラウドの草案が消える設計は、監査や公開記録請求での追跡を困難にする。EFFはこの点を「意図的な不透明化」と評している。
- 現実対応：ワシントン州King County検事局はAI作成レポートの受け取りを禁止する決定を出した。EFFはさらに市民が利用できる監査ガイドを公開し、透明性要求や公開請求の方法を提示している。

## 実践ポイント
- 調達段階で要求する仕様（最低限）：
  - 生成AIの提案差分（AI提示部分と人間編集の差分）を不可変（append-only）ログで保存
  - 出力の確率情報・モデルバージョン・入力音声のタイムスタンプをメタデータ化
  - 草案の保持期間とアクセス権を明確化
- 運用ルール：
  - 「人間最終確認（human-in-the-loop）」の義務化と署名（電子署名でも可）
  - 裁判や公開請求に対して追跡可能な監査トレイルを提供すること
  - 生成AIを用いた文章は明示的にタグ付けし、原典音声と突き合わせ可能にする
- 技術的対策：
  - 出力検証用の自動差分チェック（音声→文字起こしとの一致率算出）
  - モデルのバージョン管理とレーティング（信頼度、既知のバイアス情報）
  - 外部の独立監査（第三者がログとモデル挙動を検証できる環境）
- 市民・報道向けアクション：
  - 公的機関向けの公開請求で「AI利用の有無」「ログ保存方針」「モデル情報」を明示的に要求
  - 地方自治体の入札仕様に透明性条項（可搬なログ、監査可能性）を盛り込む

