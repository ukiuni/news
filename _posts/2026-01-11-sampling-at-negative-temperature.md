---
layout: post
title: "Sampling at negative temperature - 負の温度でのサンプリング"
date: 2026-01-11T20:44:19.890Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://cavendishlabs.org/blog/negative-temperature/"
source_title: "Sampling at negative temperature"
source_id: 46579374
excerpt: "負の温度でLLaMAを動かし、ありえない語の反復から埋め込みの盲点を可視化する実験"
---

# Sampling at negative temperature - 負の温度でのサンプリング
人はなぜ「もっともありえない語」を連発させてしまうのか — LLaMAを負の温度で動かして見えたモデルの裏側

## 要約
統計力学の温度とニューラルネットのsoftmax温度の対応から発想し、LLaMAを$T=-0.001$の「負の温度」でサンプリングすると、通常のランダム出力ともまた違う“最もらしくない”トークンの連続が生まれることがわかった。

## この記事を読むべき理由
- モデルの確率空間やトークン分布を直感的に理解できる。  
- LLMの出力がどう「意味」や「無意味」を作るかを探る新しい実験手法として有用。  
- 日本語トークン化やローカルでのモデル解析を行うエンジニアにとって実践的な示唆が得られる。

## 詳細解説
背景（温度の意味）
- 統計力学では、状態集合$\{E_i\}$に対する熱平衡分布はボルツマン分布で表される:
$$
p_i=\frac{e^{-E_i/k_B T}}{\sum_j e^{-E_j/k_B T}}.
$$
- ニューラルネットの最終層でのsoftmaxはこれと同形で、ロジット$\{z_i\}$に温度$T$を入れると
$$
p_i=\frac{e^{z_i/T}}{\sum_j e^{z_j/T}}.
$$
ここで$T$を下げれば確率は尖鋭になり（最尤トークンが選ばれやすく）、$T\to\infty$なら均一分布に近づく。

負の温度とは何か
- $ \beta = 1/(k_B T) $ を見ると、$T<0$は指数の符号が反転することを意味する。すなわち、もともと「最もありそうにない（高エネルギー）」状態が逆に「最もありそうになる」。  
- 真に負の温度は有限状態系でのみ意味を持つ（状態が無限に続く系では最も希な状態が無限に存在するため）。

実験の要点（元記事の方法）
- 公開APIでは$T$が$0\le T\le2$に制限されるため、ローカルで動くLLaMA（llama.cpp）を利用。サンプラーではロジットを温度で除算するだけなので、負の値を入れると理論上は可能。  
- 実装上の安全チェック（$T\le0$でgreedyにフォールバックする等）を外し、トップk/top-pや繰り返しペナルティを無効化して負の温度（例：$T=-0.001$）で生成すると、英語プロンプトに対して「Хронологија」「entferne」など普段はほとんど出ないトークンが繰り返される長い列が生成された。  
- これらのトークンは埋め込み空間でセントロイドに近く、モデルが意味をほとんど持たせていない（情報量が低い）トークンであることが観察される。負の温度は「最もらしくないトークン」を強制的に選ばせるため、そうしたトークンが連続して現れる。

なぜ「奇妙な反復」が出るのか
- 負の温度は確率順位を完全に反転させるため、通常は確率ゼロに近いトークン群が選択肢の上位に来る。  
- セントロイド付近のトークンはロジット分布で安定して低差で存在するため、一度選ばれると類似するトークン群が連鎖的に現れやすい。結果として「意味のないが統計的には極端にありえない」系列が続く。

## 実践ポイント
- 実験環境：ローカルのLLaMA（llama.cpp等）。実装の安全チェック（$T\le0$でgreedyにする箇所）を明示的に見直す必要がある。トップK/Pやrepeat-penaltyはオフにすることで純粋な温度効果を観察できる。  
- 安全上の注意：負の温度は無意味な出力や無限ループ・長時間生成を招く。実験はタイムアウトやトークン数上限を設定して行う。商用利用は避ける。  
- 解析用途の提案：
  - 埋め込み空間でセントロイドに近いトークンを列挙し、データ欠落やトークン化の問題点を洗い出す。  
  - 日本語での実験：日本語はトークン化（BPEやSentencePiece）で分割単位が異なるため、負の温度で出る「異常トークン」がかなり違った振る舞いをする可能性が高い。表記ゆれや未学習語（方言、スラング）が浮かび上がることが期待できる。  
  - デバッグ用途：モデルが「意味を持たない」部分（低情報トークン群）を識別する手段として有用。学習データの偏りやトークナイザの盲点を発見できる。

まとめ（日本の読者へ）
- 負の温度サンプリングは「愉快な遊び」以上に、LLMの内部確率構造や埋め込み空間の盲点を探る実験的手法になる。日本語モデルで試すと、トークナイザ固有の挙動や学習データの欠落が可視化されやすく、モデル改善や品質評価のヒントが得られる。ただし生成制御や安全対策は必須。
