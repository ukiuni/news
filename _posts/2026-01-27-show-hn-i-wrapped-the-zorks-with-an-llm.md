---
layout: post
title: "Show HN: I wrapped the Zorks with an LLM - ZorksをLLMでラップしてみた"
date: 2026-01-27T22:52:41.192Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://infocom.tambo.co/"
source_title: "Infocom Chat"
source_id: 46786618
excerpt: "古典テキスト冒険ZorkをLLMで会話化し、実装ノウハウと応用例を示す実演"
---

# Show HN: I wrapped the Zorks with an LLM - ZorksをLLMでラップしてみた
魅惑のテキストアドベンチャーを現代の会話AIで再生 — 「Infocom Chat」が古典ゲームを会話型に変える理由

## 要約
作者は古典的テキストアドベンチャー（ZorkなどInfocom作品）を、LLMをフロントエンドにして会話的に遊べる仕組み「Infocom Chat」として公開した。ゲーム出力をLLMが読み取り、自然言語でコマンド生成やヒント提供を行う。

## この記事を読むべき理由
レトロゲームの再解釈は単なるノスタルジーに留まらず、対話型AIの「環境理解」「状態管理」「命令生成」といった重要課題を実用的に示す。日本のゲーム開発者、教育者、インタラクション設計者にとって参考になる実装例だ。

## 詳細解説
- 取り組みの本質  
  Infocomのテキストアドベンチャーは「テキスト入出力」「内部状態」「パズルロジック」が明確で、LLMと相性が良い。作者はゲームの出力（部屋説明・アイテム・状態変化）をLLMに入力し、LLMから返る自然言語応答をコマンドに変換してゲームに送り返すループを作ったと考えられる。UIは「Infocom Chat」として会話ウィンドウで表現されている。

- 技術的ハイライト（想定される要素）  
  - 状態の明示化：ゲーム側の観測（room, inventory, last action result）を構造化してプロンプトに含める。  
  - プロンプト設計：少数ショットやルール（許可されるコマンド形式、避けるべき推論）を明示することでLLMの出力を安定化。  
  - コマンド正規化：LLMの自由な文章を解析して「go north」「take lamp」のようなゲームコマンドに変換するパーサーを挟む。  
  - ループ制御と誤動作対策：同じコマンドの繰り返しや非実行的な提案を検出して修正するロジック。  
  - ユーザー体験：単純なQ&Aではなく「プレイ感」を保つため、ヒントの出し方や会話トーンを調整している可能性が高い。

- 技術的課題と対処法  
  - ハリボテ知識（LLMの幻覚）：ゲーム内の事実は必ずゲーム出力で検証する。  
  - 長期状態管理：トークン制限に対しては要約や状態要素のみ保持する戦略を使う。  
  - パズル解法の暴露とネタバレ管理：ヒントの段階化（小さな助言→具体ヒント）を実装する。

## 実践ポイント
- 小さく始める：まず1エリア、単純なオブジェクトでLLMをラップして入出力ループを作る。  
- 状態を構造化する：room/inventory/last_actionの3つだけでも劇的に安定する。  
- プロンプトを制約する：「出力は英語の1行コマンドで」といった強い指示を与えてパースを簡潔に。  
- ログを取る：LLMの提案とゲーム反応を全て記録し、誤動作の再現とプロンプト改善に使う。  
- 活用アイデア：日本語化、教育用途（自然言語理解の教材）、音声インターフェースやアクセシビリティ向上への応用。

原典（Infocom Chat）を実際に触って、自分のプロジェクトにどう応用できるか試してみてください。
