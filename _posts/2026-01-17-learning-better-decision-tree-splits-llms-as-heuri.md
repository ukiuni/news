---
layout: post
title: "Learning better decision tree splits - LLMs as Heuristics for Program Synthesis - より良い決定木分割の学習 — プログラム合成のヒューリスティックとしてのLLM"
date: 2026-01-17T06:42:51.852Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://mchav.github.io/learning-better-decision-tree-splits/"
source_title: "Learning better decision tree splits - LLMs as Heuristics for Program Synthesis – Michael Chavinda – A collection of my thoughts on the various topics I find myself interested in."
source_id: 425989463
excerpt: "LLMで意味ある候補特徴を選別し決定木の可読性と精度を同時に向上させる手法"
---

# Learning better decision tree splits - LLMs as Heuristics for Program Synthesis - より良い決定木分割の学習 — プログラム合成のヒューリスティックとしてのLLM
決定木が「説明できる特徴」だけを使うようにする――LLMで候補特徴をふるいにかけるシンプルな発想

## 要約
列同士の単純な算術式（例：$price / area$ や $revenue - cost$）を候補特徴として列挙し、判断に「意味があるか」をLLMに点数付けさせて低スコアの候補を捨てる。これだけで決定木が人間らしい・解釈しやすい分割を学ぶようになった、という実験報告です。

## この記事を読むべき理由
- 日本でも金融や医療、法律など解釈性が求められる領域は多く、単に精度を上げるだけでなく「説明できる特徴」を自動生成したい場面が増えています。  
- 小さな追加コスト（LLMによるフィルタ）で、モデルの“見た目”と保守性を大きく改善できる実例を学べます。

## 詳細解説
- 着想：多くの良い特徴は人が名前を付けられる「単位や意味の通る量（例：1人あたり、1時間あたり、利益）」になる。列挙探索だけだと統計的に相関するが意味の薄い組合せ（例：収入 ÷ 郵便番号のような怪しい式）まで出てきてしまう。  
- パイプライン概要：  
  1. 数値列から深さ2程度（$a+b$, $a-b$, $a*b$, $a/b$ と元列）の候補式を列挙（深さ2は「比率・差・単純相互作用」を得やすい）。  
  2. 各式を小さいパーセンタイル網で閾値化してルール化し、決定木学習に供給。  
  3. ここで問題になるのは「意味のない式」が大量に混ざること。そこでLLMを使って式ごとに0–10の解釈可能性スコアを出させ、閾値未満は除外する（著者は5未満を除外）。  
- LLMの役割は限定的：式の妥当性（単位やカテゴリ列扱いの疑い、有用性の見積り）を判定する“セマンティック正則化子”であり、特徴生成やしきい値選定自体は従来の学習器が行う。  
- デモ（Titanic）：一般的な前処理後に上記を適用。LLMフィルタ無しだと「客室クラス ÷ 兄弟数」等の説明しづらい式がツリーに入り、訓練精度は約0.82。LLMフィルタを入れるとツリーが小さく明瞭になり（家族人数、性別×クラス等）精度は約0.83に改善した。  
- 実装上の工夫：列名を英語的に読みやすくする、maxExprDepth=2、complexityPenaltyを0にしてLLMの影響を観察、スコアはキャッシュして決定性を確保するなど。

## 実践ポイント
- まずは小さな候補空間から：深さ2（比率・差・乗算）で始めると「名付け可能」な特徴が出やすい。  
- LLMは「フィルタ」に限定する：特徴生成や評価は従来の評価指標（例：Giniや情報利得）に任せ、LLMは意味的に怪しい候補を弾くだけにする。  
- スコアリングルブリックを明示する：単位の不一致、カテゴリコードの混入、実用性の観点などをプロンプトで定義し、閾値（著者は5）を決める。  
- 再現性を確保する：式→スコアのキャッシュ、LLMの決定的デコード設定、プロンプト固定を必ず行う。  
- スキーマ情報を与える：列名が X1, A のようだと判定が弱い。可能なら「この列は円（yen）」「この列は年齢（years）」のようなメタデータをLLMに渡すと精度向上。  
- 日本市場での応用例：不動産の $price / m^2$（㎡当たり価格）や人事での $sales / employee$（一人当たり売上）など「説明できるKPI」を自動探索したい場面で有効。規制業界では解釈性を優先したモデル構築の一助になる。  
- 評価は両面で：単純な精度（検証スコア）だけでなく「ツリーの人間可読性」「作成した特徴が意味を持つか」を定性的にチェックする。

この手法は「LLMに全部任せない」点が肝で、小さな役割（セマンティックなボディガード）を与えるだけで候補空間の質が大きく改善します。まずは既存の決定木ワークフローにLLMフィルタを差し込んで、ツリーの可読性と精度の両方を観察してみてください。
