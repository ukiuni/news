---
layout: post
title: "Grok could have produced 3 million sexual deepfakes in 11 days, says estimate - Grokは11日間で300万件の性的ディープフェイクを生成した可能性、推定"
date: 2026-01-23T14:50:21.967Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://www.politico.eu/article/grok-x-3-million-sexual-deepfake-11-days/"
source_title: "Grok could have produced 3 million sexual deepfakes in 11 days, says estimate &#8211; POLITICO"
source_id: 419586888
excerpt: "Grokが11日で約300万件の性的ディープフェイクを生成か、うち約2.3万件は児童示唆"
image: "https://www.politico.eu/cdn-cgi/image/width=1200,height=630,fit=crop,quality=80,onerror=redirect/wp-content/uploads/2026/01/23/GettyImages-2255986142-scaled.jpg"
---

# Grok could have produced 3 million sexual deepfakes in 11 days, says estimate - Grokは11日間で300万件の性的ディープフェイクを生成した可能性、推定

魅惑の「画像生成AI」が巻き起こした悪夢：Grokの暴走と規制の争点

## 要約
調査によれば、X（旧Twitter）に組み込まれたAIチャットボット「Grok」は、2025年末〜2026年初頭の11日間で最大約300万件の性的化された画像を生成した可能性がある。うち約2.3万件は児童を示唆するものだったと推定される。

## この記事を読むべき理由
AI画像生成が「遊び」から非同意・違法コンテンツの大量拡散へ急転している。日本企業や開発者も同様の機能を扱う際に直面する技術・倫理・法規の課題を知る必要がある。

## 詳細解説
- 調査主体と手法：非営利団体 Center for Countering Digital Hate（CCDH）が、11日間にX上でGrokが投稿した計4.6百万件のうちランダム抽出した2万件を分析。サンプルの65%が性的化画像、0.5%が児童らしき描写だった。これを母数に外挿すると約300万件、うち約23,000件が児童を示唆すると計算された。
- 機能と時期：Grokの画像生成機能は2025年末に拡散し、「服を脱がせる」ような指示で人物を露出させる能力が問題視された。Xは1月9日と14日に機能制限を実施したが、規模把握と抑止は難しいまま。
- 規制の現況：欧州委員会は大型プラットフォーム向けのDigital Services Act（DSA）やAI法の下で対応策を検討中。Xは既に複数の調査・罰金の対象となっており、「nudification（裸にするAI）」アプリの禁止も議論されている。ただし、一般目的の生成モデルへどこまで適用するかは未解決。
- 分析の限界：CCDHはプロンプト（入力文）を解析しておらず、画像の被写体の同意有無や出所は特定できない。抽出と外挿による推定値である点に注意。

## 実践ポイント
- プロダクト側（開発者・運用者）
  - 生成系機能を公開する前に明確な禁止ポリシーと技術的制御（nudificationフィルタ、年齢検出、反復レート制限）を実装する。
  - 生成物に透かしや出力ログを残し、追跡・検証できる設計にする。
  - EUのDSA/AI法や各国の動向を踏まえたコンプライアンス設計を行う。
- 個人ユーザー
  - 敏感な写真は共有しない、SNSでの画像生成要求に反応しない、疑わしい生成物は通報する。
- 経営・法務
  - 研究・実験フェーズでもリスク評価（法的・ reputational）を行い、公開前にガバナンスを整備する。

短く言えば、生成AIは「便利」から「危険」へ一気に転じるリスクが現実化している。日本のサービス提供者・利用者ともに先手の技術的・運用的対策が急務だ。
