---
layout: post
title: "Cory Doctorow nails the problems with AI - コーリー・ドクトロウが指摘するAIの問題点"
date: 2026-01-19T01:35:14.947Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://www.theguardian.com/us-news/ng-interactive/2026/jan/18/tech-ai-bubble-burst-reverse-centaur"
source_title: "AI companies will fail. We can salvage something from the wreckage | AI (artificial intelligence) | The Guardian"
source_id: 423276165
excerpt: "AIは効率化の名で人を使い捨てる危険性と現場守る“ケンタウロス設計”の重要性を暴く"
image: "https://i.guim.co.uk/img/media/3cab6e38d4ff57c0631ad4532131aa15878f8386/284_824_2216_1773/master/2216.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=35399f4f1d76c88a6b1cc65f4fc711f5"
---

# Cory Doctorow nails the problems with AI - コーリー・ドクトロウが指摘するAIの問題点
AIは人を助ける「ケンタウロス」か、それとも人を使い捨てる「逆ケンタウロス」か？──投資と監視が生むAIバブルの本質

## 要約
コーリー・ドクトロウは、現在のAIブームは成長株維持のための「バブル」であり、実際には人間を補助する「ケンタウロス」ではなく、人間を機械の付属物にする「逆ケンタウロス」を量産していると批判する。

## この記事を読むべき理由
日本でも企業の自動化や医療・物流のAI導入が進む中、投資や経営の論理が現場と利用者にどんな弊害をもたらすかを理解することは重要です。労働、医療の質、消費者の利益がどう変わるかを見抜く視点が得られます。

## 詳細解説
- 成長株とバブルの力学：支配的な大手企業は「成長株」として高評価を受け続ける必要があり、新たな成長物語（動画、メタバース、そしてAI）を次々と作り出して投資家を維持している。AI熱はその最新の乗り物だ。
- ケンタウロス vs 逆ケンタウロス：  
  - ケンタウロス＝人が機械で支援され、能力が拡張される状態（望ましい）。  
  - 逆ケンタウロス＝機械が主導し、人は機械の監視・補助に回され、責任だけ負わされる状態（問題）。  
- 代表例（医療ラジオロジー）：AIが「診断補助」で有用でも、経営者は人件費削減のために人員を切り、残った医師に「最終確認と責任」を押し付ける。結果、サービスの質が落ちるリスクと「責任のすり替え（accountability sink）」が生じる。
- 狙いは効率化ではなく価値捕捉：多くのAI導入は「サービスを安くすることで企業が差益を得る」ために売り込まれる。AIが本当に人を置き換えるほど信頼できるかは別問題だが、経営層は消費者や投資家の支持を得るためにその物語を広める。
- 政策と連合の作り方：被害を受ける労働者（配達員、医師、エンジニアなど）と品質を求める消費者は共通の利害を持ちうる。AIの成果物が「安くて質が低い」ものになる点を示せば幅広い支持を得られる。

## 実践ポイント
- 導入時に「ケンタウロス設計」を求める：AIは人を補う設計（監視・決定の完全移譲を避ける）で導入するよう主張する。  
- 責任と監査を明確化する：AIの判定履歴、データソース、エラー事例をログ化・公開して説明責任を確保する。  
- 労働者の立場を守る：自動化による職の置き換えではなく再教育や労働条件の維持を求める連携を作る。  
- 技術者としてできること：モデルやデータの偏りをチェックする、失敗ケースを文書化する、人間が最終判断をしやすいUI/ワークフローを設計する。  
- 市民・消費者として：AI導入のメリットだけでなく被害やトレードオフを問い、透明性や規制（医療・労働・監視に関するルール）を求める。

短く言えば、AI自体が善でも悪でもない。重要なのは「誰のためのAIか」を見極め、企業の成長神話に踊らされないことです。日本でも医療・物流・開発現場で似た圧力が出てくるため、今のうちに設計基準と社会的合意を作ることが大切です。
