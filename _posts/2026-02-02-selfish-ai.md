---
layout: post
title: "Selfish AI - 利己的なAI"
date: 2026-02-02T07:23:27.229Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://www.garfieldtech.com/blog/selfish-ai"
source_title: "Selfish AI | GarfieldTech"
source_id: 920819688
excerpt: "著作権侵害や低賃金、電力・水問題…AIで社会が壊れる前に技術者が取るべき行動は？"
---

# Selfish AI - 利己的なAI
魅力的なタイトル案：AIが「俺だけ得する」世界を作る前に、エンジニアが知っておくべきこと

## 要約
海外記事「Selfish AI」は、AIコーディングブームが開発者個人の利便性以上に著作権侵害、低賃金労働、電力・水資源の消費増、大規模な倫理問題を招いていると警鐘を鳴らします。

## この記事を読むべき理由
AIツールの導入は「自分ごと」で済ませられません。日本の開発現場やスタートアップ、インフラにも直接影響するため、技術選択が社会・環境・法制度に及ぼす波及を理解する必要があります。

## 詳細解説
- データ収集と著作権  
  多くの大規模言語モデル(LLM)はウェブの大量クロールで学習しており、著作権やオープンソースのライセンスを侵害する事例が問題視されています。これにより法的・倫理的な論点が生じ、今後の裁判や規制で事業運営が制約される可能性があります。

- 労働とラベリング作業  
  表面的に「人手がいらない」とされるAIでも、ラベル付けや品質チェックは低賃金のクラウドワーカーに依存することが多く、労働搾取の構造を内包します。これはグローバルなサプライチェーン問題です。

- 電力・水資源への影響  
  AI向けハードウェアを備えたデータセンターは消費電力を急増させ、地域の電力需給や再生可能エネルギー導入計画に影響します。研究例では短いテキスト生成でも冷却・発電を含めて数百ミリリットルの水を消費する試算があります。日本では電力集中地域や水資源の制約を考えると無視できません。

- 経済・市場の脆弱性  
  AI投資ブームはバブル的側面を持ち、短期的に雇用や事業構造を破壊するリスクがあります。さらに、安価なAIサービスが普及すると価格競争で倫理的な配慮が犠牲になりがちです。

- 集合的意思決定の問題  
  個々の「仕方ない／it is what it is」という選択が累積して社会的帰結を生むため、開発者・企業・ユーザーの集合的行動が重要になります。

## 実践ポイント
- ツール選びで倫理を問う：トレーニングデータの出自やライセンス対応、運用ポリシーを確認する。  
- オープンソースとライセンスを尊重：自社で使うモデルがソースコードやデータの権利を侵害していないかチェックする。  
- 省エネ・ローカル運用の検討：オンプレや小型モデルで必要な処理を済ませる、推論頻度を最適化する。  
- 労働とサプライチェーンに配慮：外注先の労働条件を見直す・透明性を要求する。  
- 組織的なルール作り：利用方針を定め、開発チームで倫理的な使用の判断基準を共有する。  
- 社会的対話に参加：業界団体や自治体の議論に関わり、規制やガバナンス設計に声を上げる。

短く言えば、AIは便利ですが「便利だから全部受け入れる」では済まなくなっています。技術者として、個人と社会の双方を守る選択を意図的に行いましょう。
