---
layout: post
title: "An introduction to XET, Hugging Face's storage system (part 1) - XET入門：Hugging Faceのストレージシステム（パート1）"
date: 2026-01-21T11:13:13.808Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://00f.net/2026/01/19/xet-intro-1/"
source_title: "An introduction to XET, Hugging Face's storage system (part 1) - Frank DENIS random thoughts."
source_id: 421292970
excerpt: "Hugging FaceのXETで大規模モデルの保存・転送コストを劇的に削減する仕組みを解説"
image: "https://00f.net/favicon.ico"
---

# An introduction to XET, Hugging Face's storage system (part 1) - XET入門：Hugging Faceのストレージシステム（パート1）
大きなモデルやデータで増えるコストを一気に削る？Hugging Face流の「チャンク＋コンテントアドレッシング」設計、XETの全体像

## 要約
XETはHugging Faceが開発したコンテントアドレストストレージで、ファイルを可変長チャンクに分割して重複をチャンク単位で排除（デデュープ）し、効率的に配布・検証する仕組みです。Git LFS互換性を維持しつつサーバ側の無駄な保存・転送を大幅に減らします。

## この記事を読むべき理由
- 日本でもモデルや大規模データの共有が増え、クラウド保存・転送コストが問題になっているため。  
- XETは既存のGit/Git LFSワークフローと親和性が高く、導入でコスト削減や配信効率改善が期待できるため。  
- 技術的には「チャンク設計」「コンテントアドレッシング」「HTTP Rangeを使った並列ダウンロード」といった実務で使えるアイデアが詰まっているため。

## 詳細解説
- 背景問題：Gitは差分管理が得意でも大きなバイナリでは小さな変更でも新しい大ファイルを保存しがち。Git LFSはポインタでクライアント側の扱いを改善するが、サーバ側での冗長保存は残る。  
- 解決方針（チャンク化）：ファイルを可変長チャンクに分割して、同一チャンクを1つだけ保存する方式。差分が局所的でも多くのバイトは共有できるため効率が高い。  
- チャンクの特徴：XETはコンテント定義チャンク（content-defined chunking）を採用し、可変長ブロックで挿入・削除耐性を持たせる。典型チャンクサイズは約64KiB（最小8KiB、最大128KiB）。  
- Xorbs（コンテナ）：多数のチャンクをまとめた大きなオブジェクト（xorb）を使い、HTTPリクエスト数・クラウドのオブジェクト数・CDNエントリを削減する。xorbはシリアライズで最大約64MiB、通常は数千チャンクを含める。  
- ダウンロードと再構築：サーバは「xorbハッシュ＋チャンクインデックス範囲」の計画をクライアントに渡す。クライアントはHTTP Rangeで必要バイト範囲を並列取得し、チャンクヘッダを解析してデコード・連結して元ファイルを再構成する。  
- 検証と互換性：チャンク、xorbs、ファイルはハッシュでコンテントアドレス化され、Merkle風のハッシュで整合性を確認可能。Git LFS互換を保つため既存のワークフローに統合しやすい。  
- 適用範囲：モデル・データセット以外に、OCIイメージや大容量アーティファクトを扱うシステムでもメリットがある。公開プロトコルとOSS実装がある点も採用を後押しする。

## 実践ポイント
- まずはドキュメントと公式のプロトコル草案、簡単なPython実装を読んで設計思想を把握する。  
- 自社で大きなバイナリを多く扱うなら、XETを使った小さなPoCでサーバ側保存容量と転送量を比較検証する。  
- CDNやオブジェクトストレージはHTTP Rangeと部分ダウンロードの挙動を確認しておく（Range対応が必須）。  
- チャンクサイズはトレードオフ：小さすぎると管理コスト大、大きすぎるとデデュープ性能低下。まずは64KiB前後で試す。  
- セキュリティ／アクセス制御設計も忘れずに。コンテントアドレス化は整合性に有利だが、認可設計は別途必要。  
- XETは標準化の余地があるため、コミュニティ実装や次パート（コンテント定義チャンクと圧縮）も追うと良い。

短時間で把握できる全体像と、すぐ試せる実践案を提示しました。日本の企業や研究機関で大規模モデル・データ流通を扱う現場では、導入検討の価値が高い技術です。
