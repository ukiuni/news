---
layout: post
title: "Building for an audience of one: starting and finishing side projects with AI - 「一人に向けて作る」：AIでサイドプロジェクトを始めて完成させる方法"
date: 2026-02-17T05:56:24.182Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://codemade.net/blog/building-for-one/"
source_title: "Building for an audience of one: starting and finishing side projects with AI - CodeMade"
source_id: 47041973
excerpt: "AI対話で仕様を固め、コンテナとgitで短期間に自作ツールを安全に完成させる手順"
---

# Building for an audience of one: starting and finishing side projects with AI - 「一人に向けて作る」：AIでサイドプロジェクトを始めて完成させる方法
魅力的なタイトル: AIと一緒に「自分だけ」のツールを短期間で仕上げる技術 — FastTabに学ぶ実践ワークフロー

## 要約
AI（LLM）を会話で使って仕様を固め、コンテナ＋gitで安全にコード生成を回し、手元でリファクタと最適化を行えば「自分用」のサイドプロジェクトを短期間で完成できる、という実体験レポート。

## この記事を読むべき理由
日本のエンジニアやハッカーは職場での制約や時間不足からサイドプロジェクトで学び・試作するケースが多い。AIを要所で使う実践的な手順を知れば、効率的に完成まで持っていける。

## 詳細解説
- 発端と狙い：著者はKDE（Plasma）上のX11でのタスク切替「Gallery」表示の遅延を嫌い、自分専用の高速スイッチャー（FastTab）を作成。重要なのは「観客は一人」で、ニッチな問題もAIによって着手可能になる点。
- ワークフローの核
  - 会話で問題を探索し、LLMと仕様（high-level spec）を詰める。コード断片より擬似コードやMermaid図でアーキテクチャを固めるのが効率的。
  - 仕様をマイルストーンに分割し、まずはプロトタイプ→改善の繰り返し。
- 安全に自動生成を回す工夫
  - gitで小刻みにコミットし差分を確認。LLMが壊しても戻せる運用。
  - コンテナ（Dockerラッパー）でLLMの実行を隔離し、ホストを守る。LLMにはコンテナ環境の制約を教えておく。
- モデルとトークン問題
  - 言語や低レベル処理（例：Zig、X11、OpenGL）はトークン消費が多く、複数モデルやCLIを切り替える必要が出る場合あり。
- 人間側の役割は依然重要
  - LLMは大半（約80%）を自動化できるが、最後の20%は設計知識や最適化（例：SIMDやX11のテクスチャ共有の発見）を要する。テストやリファクタで保守性を回復する必要あり。
- 総括的見解：業務コードほど厳密でないサイドプロジェクトはAI活用の恩恵が大きく、完成率向上につながる。

## 実践ポイント
- まずはAIと「会話」してアイデア棚卸→高レベル仕様化（擬似コードと図を多用）。
- 仕様を小さなマイルストーンに分け、最初は動くプロトタイプ優先。
- gitで頻繁にコミット、差分レビューをルーチン化。
- LLMにフルアクセスを与えず、開発はコンテナ内で実行（ホストは保護）。
- テストとリファクタを必須工程にする（LLM生成コードは読みやすくないことが多い）。
- パフォーマンス改善は「何が効くか」を知っていることが重要（SIMDやプラットフォーム固有の最適化を学ぶ）。
- トークン制限に備え、モデル切替や作業の分割を計画する。

以上を取り入れれば、日本の限られた時間・環境でもAIを活かして「自分だけ」の実用ツールを作り切る確率が上がります。
