---
  layout: post
  title: "4 Ways to Improve A Perfect Join Algorithm - 完璧な結合アルゴリズムを速くする4つの方法"
  date: 2026-01-04T17:45:11.227Z
  categories: [tech, world-news]
  tags: [tech-news, japan]
  source_url: "https://remy.wang/blog/ya-fast.html"
  source_title: "4 Ways to Improve A Perfect Join Algorithm"
  source_id: 1234660369
  excerpt: "Yannakakis結合を実運用で劇的に高速化する4策：Bloom、集約、遅延展開、半結合"
  ---

# 4 Ways to Improve A Perfect Join Algorithm - 完璧な結合アルゴリズムを速くする4つの方法
次世代DBで「理論的最適」を実務で速くする——実践的に効く4つの改良手法

## 要約
Yannakakis の「アキシカル結合に対する最適アルゴリズム」は理論上強力だが、実装するとハッシュ結合より遅くなることがある。この記事はそのギャップを埋めるための4つの実践的改良（Bloomフィルタ、集約のプッシュダウン、遅延展開によるネスト表現、ループに乗せたオンザフライ半結合）を分かりやすく解説する。

## この記事を読むべき理由
日本でもデータ基盤／OLAP／トランザクション系DBの性能差は事業競争力に直結する。理論的に優れたアルゴリズムを「実用的に速くする」手法は、クラウド上のコスト削減やレイテンシ低減に直結するため、DB実装者や性能を気にするエンジニアは知っておくべき。

## 詳細解説
背景（問題点）
- Yannakakis のアルゴリズムはアキシカル（木状）結合に対してインスタンス最適性を持つが、セミジョイン（前処理の削減）を複数回行うため、実データではハッシュ結合より 2–3× 遅くなることがある。典型例として直列に4つの二項リレーションをつなぐと、無駄なセミジョインが多く発生する。

コストの粗い比較（例）
- 元の実行ではセミジョイン6回＋最終結合3回で合計 probe/insert が概ね $9n$ のプローブと $6n$ の挿入。
- 一方で標準のハッシュジョインはハッシュ表3つの構築と3回のプローブで $3n$ の挿入と $3n$ のプローブに相当する。

改良1：Bloomフィルタでセミジョインを軽くする
- セミジョイン結果をフルハッシュ表で保持する代わりに Bloom フィルタで「存在否」をテストする。フィルタが CPU キャッシュに収まれば，プローブ／挿入が大幅に高速化される。
- 効果：無駄なメモリアクセスを減らし、平均ケースで不要タプルを早期に削る（上の例では $6n$ のプローブがキャッシュフレンドリーに）。
- 実運用の注意点：偽陽性率に依存。フィルタサイズは L1/L2/L3 キャッシュに合わせて調整。

改良2：集約のプッシュダウン（Aggregate pushdown）
- 多くの実アプリは SELECT * ではなく GROUP BY＋集約を求める。集約を下流（リレーション側）で先に実行すると、キーごとに1行に圧縮できるためセミジョイン自体を置き換えられる。
- 仕組み：各リレーションで GROUP BY を行い「鍵→集約値（例：max）」だけを伝搬させる。これにより各ステップは結合＋集約で済み、全体が線形時間に近づく。
- 適用条件：クエリが relation-dominated（GROUP BY の属性が一関係に帰属する等）である必要がある。

改良3：結合時に展開を遅らせる（ネスト表現）
- 右深プランで部分結合が爆発的に大きくなるケースでは、マッチするタプルを展開せずポインタ（参照）だけを保持することで中間結果の二乗爆発を防ぐ。
- 戦略：T3[x3] に実データのコピーを入れるのではなく、T4[x4] への参照を入れる。トップダウンで必要になったときにアンネスト（展開）する。
- トレードオフ：アンネストの際に追跡が必要だが、アンネストプロセスはハッシュ表アクセスを伴わないため高速。

改良4：ループに乗せたオンザフライ半結合（TreeTracker / On-the-fly semijoin）
- 実運用の多くはループネスト（左深プラン）でパイプライン処理される。ループ内で将来のプローブ失敗が見えたら、即座に現在のタプルを削除（tombstone）して再訪問コストを払わせない。
- 例：外側ループで R1 のタプルを巡回中に R2/R3/R4 のハッシュ表へプローブし、失敗する箇所を発見したらその場で削除する。以後同じタプルは二度と評価されないため合計で $O(|IN|+|OUT|)$ の振る舞いに近づく。
- 実装の利点：パイプライン／メモリの局所性を活かし、削除は tombstone として低コスト。

補足（実装上の細部）
- SIMD を使った Bloom フィルタ構築／プローブ、ベクトル化されたネスト表現、ループジャンプ最適化（変数導入位置検出）など、論文化された技術がある。SQLite や SQLServer に似たアイデアの実例も存在。

数式メモ（重要度の見積）
- 伝統的ハッシュ結合：概算でプローブと挿入は $O(n)$（例では $3n$）。
- 元の Yannakakis 実行：セミジョイン過多で $O(n)$ だが係数が悪く、$9n$ プローブ・$6n$ 挿入のような定数係数増。
- 改良後はキャッシュフレンドリー化や圧縮で係数を大きく下げられる。

## 実践ポイント
- まずは観測：クエリプランでセミジョインが多い・中間結果が巨大になっている箇所を特定する。
- Bloomフィルタ導入：セミジョインを多用するワークロードでは、フィルタを L2/L3 に収めるサイズに調整して効果を測る。偽陽性率$<1\%$あたりを目安にチューニング。
- 集約のプッシュダウンはアプリ側で実装可：DBエンジンを変えずにビューや部分集計で効果を試せる（特に GROUP BY 件数が少ないケース）。
- ネスト表現はエンジン改修向け：中間展開コストが問題な場面では、参照ベースの表現と遅延アンネストを検討。ベクトル化実装と相性が良い。
- オンザフライ半結合（TreeTracker系）は左深/パイプライン実行環境に有用。DBベンダーやエンジンの実装者はこの最適化を検討するべき。
- 日本の現場での関係：クラウド上の VM（メモリ/キャッシュ制約）や日本語サポートのある商用DB（例：SQL Server, PostgreSQL系拡張）での適用効果を評価することでコスト削減に直結する。

参考アクション（すぐできる）
- 部分集計を使ってクエリを書き換え、レスポンス／I/O が減るかを A/B テストする。
- プロファイラでハッシュ表のキャッシュミス率とセミジョイン回数を確認し、Bloom フィルタの導入を検討する。
- DBのオープンソース実装者であれば、ネスト表現・tombstone 削除ロジックのプロトタイプを作ってベンチを回す。

興味があれば、元の研究（Yannakakis のアルゴリズムと最近の拡張論文群）を参考に、まずは Bloom フィルタと集約プッシュダウンから試すのが最短で効果が出る。  

（簡単な疑似コード例）

```python
# Bloomフィルタを使ったセミジョイン（疑似）
for (x3, x4) in R3:
    if bloom_R4.might_contain(x4):
        bloom_R3.add(x3)
```

```python
# 集約プッシュダウン（max を下流で計算）
for (x4, x5) in R4:
    if T4.get(x4) is None or T4[x4] < x5:
        T4[x4] = x5
# 以降 T4 を使って上位リレーションの集約を連鎖させる
```

以上。元記事の手法は「理論的最適を実運用で生かす」実践集で、日本のデータ基盤改善にも直接応用できるアイデアが多い。
