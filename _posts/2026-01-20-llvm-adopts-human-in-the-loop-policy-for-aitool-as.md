---
layout: post
title: "LLVM adopts \"human in the loop\" policy for AI/tool-assisted contributions - LLVM、AI支援の貢献に「Human in the Loop」ポリシーを採用"
date: 2026-01-20T19:05:26.195Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://www.phoronix.com/news/LLVM-Human-In-The-Loop"
source_title: "LLVM Adopts &quot;Human In The Loop&quot; Policy For AI/Tool-Assisted Contributions - Phoronix"
source_id: 423110591
excerpt: "LLVMがAI生成コードを容認しつつ必ず人間の全文レビューと責任表明を義務化しました"
image: "https://www.phoronix.net/image.php?id=2026&image=llvm_vs_ai"
---

# LLVM adopts "human in the loop" policy for AI/tool-assisted contributions - LLVM、AI支援の貢献に「Human in the Loop」ポリシーを採用
LLVMが示した「AI任せはダメ、最後は人が責任を取る」—オープンソース開発の新常識になるか

## 要約
LLVMはLLMやコード支援ツールで生成したコードの利用を完全否定せず、しかし「人間による事前レビューと責任表明」を必須とするHuman in the loopポリシーを採用しました。無査読のAI生成プルリクは受け付けません。

## この記事を読むべき理由
日本のOSS貢献者、企業のエンジニア、コードレビュー担当者にとって、AI支援ツールが一般化する中で「品質」「責任」「レビュー負荷」をどう担保するかは現場の喫緊課題です。LLVMの方針は今後の社内ルールやオープンソース参加方針の参考になります。

## 詳細解説
- 背景: 2025年に入ってLLM支援の「雑な」貢献が増加。レビュー工数の無駄や品質低下を招いたため、LLVMは明確なガイドラインを制定しました。Linuxカーネルなど他プロジェクトでも同様の議論が進行中です。
- 中核ルール:
  - ツールは自由に使ってよいが、必ず「人間が全文を読み、レビュー前に自分で確認」すること。
  - 貢献者がその変更の作者かつ最終責任者であり、レビュー中に自分の変更について答えられること。
  - 大規模なツール生成コンテンツがある場合は明示してラベリング（例: プルリク説明やコミットメッセージに記載）。推奨トレーラー: Assisted-by: [ツール名]
  - 新規寄稿者にはまず小さな変更から始めて自信を付けることを勧める。
- 意図: レビュー担当者の時間を守り、学習機会を確保し、ツール依存の成長阻害を避けること。
- 技術的含意: 自動生成コードはテスト不足・セキュリティ脆弱性・ライセンス混入のリスクがあるため、人間チェックで動作確認、スタイル・API適合、テストカバレッジを担保する必要があります。

## 実践ポイント
- プルリク作成時の最低要件（テンプレート化を推奨）
  - どのツールを使ったかを明記（例: Assisted-by: Copilot）
  - 手で確認したポイント（動作確認手順、追加テスト、既存コードとの互換性）
  - 変更箇所について自分が答えられる短い要約
  - 小さな単位でPRを出す（まずは1機能・1バグ修正単位）
- レビューワー向けチェックリスト
  - 自動生成文やコードにセキュリティ上の問題はないか
  - テストが十分か（ユニット/統合テストの有無と結果）
  - ライセンスや外部コードの混入がないか
- 企業内ルール案（日本のチーム向け）
  - CONtributing.mdや社内開発ルールに「ツール使用の明記」と「最終確認者の署名」を追加
  - CIで自動静的解析＋追加テスト必須にして人のレビューに先立つ品質ゲートを設定
- コミュニティ参加の心得
  - 初めての貢献者は小さく始める。ツール出力をそのまま流すのは厳禁。
  - レビューで得たフィードバックを元にLLMのプロンプト改善に使うのは可だが、レビュアーの時間をそのために消費しない工夫を。

LLVMの方針は「AIを敵に回さないが、責任と品質の担保を人間が取る」という現実的な落としどころです。日本の現場でも、同様のガイドラインを早めに整備することでトラブルを減らし、AIを生産的に活用できるでしょう。
