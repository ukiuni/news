---
  layout: post
  title: "All AI Videos Are Harmful (2025) - すべてのAI動画は有害である（2025）"
  date: 2026-01-05T17:07:16.785Z
  categories: [tech, world-news]
  tags: [tech-news, japan]
  source_url: "https://idiallo.com/blog/all-ai-videos-are-harmful"
  source_title: "All AI Videos Are Harmful"
  source_id: 46498651
  excerpt: "AI生成動画の違和感が偽情報拡散と信頼崩壊を加速、対策の急務を警告"
  image: "https://cdn.idiallo.com/images/assets/594/thumb.jpg"
---

# All AI Videos Are Harmful (2025) - すべてのAI動画は有害である（2025）
見分けられるか？AI動画が生む「新しい不気味の谷」と日本の危機

## 要約
OpenAIのSoraやRunwayなど最新のAI動画生成ツールは映像の「量産」と「説得力」を容易にしたが、出力には独特の不自然さ（新しい不気味の谷）があり、詐欺・偽情報の拡散や信頼の崩壊を加速している──著者イブラヒム・ディアロの警鐘。

## この記事を読むべき理由
AI映像は単なる技術トピックではなく、ニュース、選挙、地域コミュニティ（日本ならLINEの高齢者グループなど）に直接影響します。エンジニア、プロダクト担当、メディア従事者が現状の技術的限界と悪用の実態を理解し、対策を設計する必要があります。

## 詳細解説
- 何が起きているか：Sora（初代・Sora 2）、Runway ML、Veoなどを試した著者は、ツールが「格好良く見える」映像は作るが、物語に沿った精密な演技や意図的な表現はほとんど再現できないと指摘。結果として「AI動画」特有の美的指紋＝微妙な違和感（顔の平滑化、過剰なシャープネス、奇妙なリップシンク、ありふれたシーン構成）が生まれる。
- 新しい不気味の谷：人間の脳は「なんとなく違う」と察知するが、具体的説明は困難。これが不信感を生み、逆に悪意ある発信者はそれを隠れ蓑に偽情報を大量配信している。
- 悪用の実態：著者は高齢者がAI生成の偽著名人発言や災害フェイクをLINEやWhatsAppで回している実例を挙げ、拡散の速さと検証の遅さのギャップを問題視。プラットフォーム側が実際にリアル映像をAIで補正（例：顔の平滑化）することで真偽の境界がさらに曖昧に。
- 技術的原因：生成モデルは確率的に「ありそうな」映像や台詞を作るため、特異点（詳細な意図や文脈）を欠きやすい。時間軸の一貫性や語用論的整合性はまだ脆弱で、これが微妙な違和感につながる。
- 対応策の技術要素：コンテンツの出所を示すプロビナンス（例：C2PAのような認証フレームワーク）、生成物への透かし・メタデータ付与、フォレンジックによる生成痕跡検出、スケールに耐えるモデレーションパイプラインが鍵。

## 日本市場との関連
- プラットフォーム普及度：日本ではLINEやTwitter（X）、YouTubeが情報流通の中心。とくに高齢層はLINEでの「動画貼り付け→転送」が主要ルートであり、英語圏と同様の被害が起きやすい。
- 社会的影響：地方自治体や選挙、医療情報の誤伝播は被害が局所化して拡大しやすい。メディアとプラットフォーム、企業の連携による早期検証・周知が不可欠。
- 事業側の視点：映像制作や広告に関わる企業は「表現の補助」としての有用性を探りつつ、ブランド毀損や法的リスク（偽装や肖像権侵害）に備える必要がある。

## 実践ポイント
- 一般ユーザー向け（特に高齢者に教えること）
  - 転送する前に「出典を確認」：公式発表やNHKなど一次ソースを先に探す。
  - 視覚的な手がかりを点検：不自然な口の動き、過度の肌の平滑化、透かし（小さなクラウドやアイコン）を確認。
  - 怪しい動画は共有しない。疑わしければ既存のファクトチェック（公式サイト・新聞）を参照。
- エンジニア／プロダクト担当向け
  - プロビナンス実装を検討：C2PAなどで生成や編集の履歴を付与し、UI上で表示する。
  - フォレンジック検出パイプラインを整備：フレーム間の不整合や音声-映像同期のズレを自動検出するモデルを導入。
  - UXで信頼性を示す：公式認証バッジ、編集履歴、発行元の検証を見せることで誤解を減らす。
  - モデレーションの自動化と人間の介在を両立：高速拡散を止めるために初動での自動検出→優先レビューのフローを作る。
- 組織・教育
  - 社内外でのメディアリテラシー研修を強化し、高齢者向けに分かりやすいチェックリストを配布する。

著者イブラヒム・ディアロの結論は辛辣です：現時点では「出会うAI動画の多くが有害か、少なくとも信頼を損なう」。技術的には有益な応用もあり得る一方、社会的被害を抑える仕組みを急いで実装しなければ、日本でも同じ危機が顕在化します。
