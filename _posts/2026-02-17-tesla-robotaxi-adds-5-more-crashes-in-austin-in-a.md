---
layout: post
title: "Tesla 'Robotaxi' adds 5 more crashes in Austin in a month – 4x worse than humans - テスラ「ロボタクシー」、オースティンで1か月にさらに5件の衝突 — 人間より4倍多い"
date: 2026-02-17T22:05:11.225Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://electrek.co/2026/02/17/tesla-robotaxi-adds-5-more-crashes-austin-month-4x-worse-than-humans/"
source_title: "Tesla &#039;Robotaxi&#039; adds 5 more crashes in Austin in a month — 4x worse than humans | Electrek"
source_id: 47051546
excerpt: "オースティンでテスラのロボタクシーが1か月に5件追加入院修正も、事故率は人間の約4倍"
image: "https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2021/08/Tesla-Full-Self-Driving-Beta-Hero.jpg?resize=1200%2C628&quality=82&strip=all&ssl=1"
---

# Tesla 'Robotaxi' adds 5 more crashes in Austin in a month – 4x worse than humans - テスラ「ロボタクシー」、オースティンで1か月にさらに5件の衝突 — 人間より4倍多い

魅力的なタイトル: テスラの「無人」タクシー、運用1年で散見される事故増加――透明性の欠如が招く信頼危機

## 要約
テスラのロボタクシー（Austin運用）で12月〜1月に5件の追加入力がNHTSAのデータベースに登録され、合計14件に。うち1件は報告後に入院ありへと修正され、事故率は人間運転者の同社指標より約4倍悪いと指摘されています。

## この記事を読むべき理由
自動運転の安全性と透明性は、国内外で技術採用と規制に直結する話題です。日本でもロボタクシーや自動運転の実用化が進む中、事故データの扱いと評価指標の読み解き方を知っておくことは重要です。

## 詳細解説
- 情報源：米国運輸省NHTSAのSGO（Standing General Order）事故報告データベースに登録されたテスラ提出の報告からの集計。
- 新規報告：2025年12月〜2026年1月に発生した5件はすべてModel Yで「自動運転システムが作動（verified engaged）」の状態。速度は低速〜停車時が中心（0–17 mph）、ぶつかった対象は固定物、トラック、バス、後退での接触など。
- 透明性の問題：各事故の「事故説明」はテスラが機密として全面的に黒塗り（redacted）しており、他社（Waymo等）が行う事故の詳細開示と対照的。
- 入院ありへの修正：2025年7月の事故が当初「物損のみ」申告だったのを数カ月後に「軽傷（入院あり）」へ修正。事故後の報告修正は原因究明や説明責任の観点で問題視される。
- 事故率の比較：データと推計で約800,000マイル走行で14件→約1件/57,000マイル。テスラの自社指標では「人間運転者の軽微な衝突は約229,000マイルに1回」なので、比率は概ね $229{,}000 \div 57{,}000 \approx 4$ 倍悪いと算出されます。NHTSAの警察報告ベース（約1/500,000マイル）と比べればさらに差が開きます。
- 他社との対比：Waymoは数千万〜1億超マイルの無監督運行実績があり、独立研究で負傷事故を大幅に低減しているとの報告があるため、同条件での比較が公平かは議論がありますが、運用実績と透明性の差は明確です。

## 実践ポイント
- 利用者：ロボタクシーを選ぶ際は「事故報告の透明性」「第三者検証の有無」「走行実績」を確認する習慣を持つ。
- 開発者／事業者：事故ログ・ナラティブの開示、遅延修正の理由公開、第三者による独立検証を優先すべき。
- 政策担当者：データ開示基準と監査の厳格化、運行開始前後の独立モニタリング体制を検討する必要あり。
- 技術者向け学習トピック：センサーフュージョンの失敗モード、フェイルセーフ設計、ヒューマンインザループ（安全監視員）と自動化の境界設計について学ぶと実務に直結します。
