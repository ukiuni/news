---
layout: post
title: "Scaffolding to Superhuman: How Curriculum Learning Solved 2048 and Tetris - 足場から超人的へ：カリキュラム学習が2048とテトリスを解いた方法"
date: 2025-12-31T16:38:03.461Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://kywch.github.io/blog/2025/12/curriculum-learning-2048-tetris/"
source_title: "Scaffolding to Superhuman: How Curriculum Learning Solved 2048 and Tetris"
source_id: 46445195
excerpt: "高速シミュレーションと段階学習で2048とテトリスを超人級に解く具体手法と実践指針"
---

# Scaffolding to Superhuman: How Curriculum Learning Solved 2048 and Tetris - 足場から超人的へ：カリキュラム学習が2048とテトリスを解いた方法
超速シミュレーション×カリキュラム学習で、数TB級の探索表をわずか数十MBのポリシーが超えた話

## 要約
PufferLibの超高速環境と徹底したハイパーパラメータ探索、そして「カリキュラム（段階的学習）」の設計で、2048では数TB級の終盤テーブルを使う探索法を小さなNNポリシーが上回り、テトリスでは“バグ”が堅牢性を生んだ。

## この記事を読むべき理由
日本の個人研究者や中小チームでも、巨大クラスタを使わずに「超人的」なゲームAIを作れる手法と具体的な設計指針（観測設計・報酬設計・カリキュラム）を学べるため。限定されたリソースで最大限の成果を出す実践ノウハウが詰まっている。

## 詳細解説
- 高速シミュレーションが鍵  
  PufferLibのCベース環境はCPUコア当たり1M+ステップ/秒を実現。これにより「1Bステップは分単位」で回せ、数百のハイパーパラメータスイープが数時間で可能に。結果として少数GPU（RTX 4090×2）でも短時間で多様な探索ができる。

- 探索方針（Recipe）  
  まず観測（obs）と報酬（reward）を完璧にし、最後にネットワークを拡大する。ネットワークだけ大きくしても、観測や報酬が不十分なら伸びない。著者は200のスイープを回し、Proteinというコスト-成果のパレート前線サンプリングで効率的に最適条件を絞った。

- 2048での具体的工夫（なぜ勝てたか）  
  ・ポリシーは15MB（学習75分などの短時間設定で実用）で、65,536タイル到達率14.75%、32,768タイル71.22%を達成。  
  ・観測設計：4×4セルごとに18次元の特徴（タイル値の正規化（値^1.5をLUTで実装）、空セルフラグ、タイル値ワンホット16次元、スネーク状態フラグ）を固定。  
  ・報酬設計：マージ報酬（タイル値比例、重み0.0625）、無効手(-0.05)、ゲームオーバー(-1.0)、モノトニシティや特定配置（スネーク）へのボーナス（非常に小さな係数〜大きな係数まで複合）。  
  ・カリキュラム（決定打）：終盤状態を意図的に生成する「スキャフォルディング」--- 高タイルを事前に配置するエピソード-levelの段階的導入、さらに終盤専用環境（終盤のみを反復練習）で数万手の正確な連続手順を学習させる。  
  ・アーキテクチャ：3.7Mパラメータ、エンコーダ（FC 1024→512→512, GELU）、LSTM（512×512）。LSTMは数万手先を見越す長期計画に必須。

- テトリスでの発見（バグがカリキュラムに）  
  一時的なバグで「次の2ピースのワンホットがステップ間で残存し、観測が徐々にノイズ化」していた。修正後は初期性能は良くなるが終盤の混乱に弱くなった。逆にバグが有していた「早期からのカオスな状態露出」がロバスト性を育てた。著者は外部（初期からランダムゴミ行挿入）と内部（観測ノイズを徐々に減らす）という2つのカリキュラム手法を採用。

- 学びの総括  
  スピード（シミュレーション性能）→体系的スイープ→観測・報酬の丹念な設計→カリキュラムの投入→必要ならばネットワーク拡張。ハイパーパラメータ調整の効果はしばしばネットワーク構造変更より大きい。

## 実践ポイント
- PufferLibのような高速環境を使う：大量の短期実験で最適解を見つけるのが近道。  
- 最初に観測と報酬を磨く：良い特徴設計と報酬があれば小さなモデルで高性能を出せる。  
- カリキュラムを設計する：到達困難な高価値状態は事前配置や専用環境で反復させる（2048の終盤訓練が好例）。  
- ハイパーパラメータの系統的スイープを自動化する（コスト-成果のPareto探索が有効）。  
- 長期計画問題にはメモリ機構（LSTM等）を検討する。  
- 意図せぬ挙動（バグ）から学ぶ：早期のノイズやランダム化はロバスト性向上に使える（ただし慎重に評価を）。  
- 日本の小〜中規模チームでも、ゲーミングPC一台＋工夫で世界水準に挑める設計思想を採る。

## 引用元
- タイトル: Scaffolding to Superhuman: How Curriculum Learning Solved 2048 and Tetris  
- URL: https://kywch.github.io/blog/2025/12/curriculum-learning-2048-tetris/
