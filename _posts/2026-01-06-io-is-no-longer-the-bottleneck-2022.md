---
  layout: post
  title: "I/O is no longer the bottleneck? - I/Oはもはやボトルネックではないか?"
  date: 2026-01-06T02:01:57.582Z
  categories: [tech, world-news]
  tags: [tech-news, japan]
  source_url: "https://stoppels.ch/2022/11/27/io-is-no-longer-the-bottleneck.html"
  source_title: "I/O is no longer the bottleneck?"
  source_id: 46506994
  excerpt: "手作業SIMDで読み取り速度に迫るが、CPU最適化が現代ストレージの制約となる"
  ---

# I/O is no longer the bottleneck? - I/Oはもはやボトルネックではないか?
「ディスクが速くなった今、プログラムのボトルネックはCPUとアルゴリズムだ」——手作業でSIMDを入れたら何が変わったか

## 要約
Harmen Stoppelsが、典型的な「ストリームから単語数を数える」問題でI/Oが本当にボトルネックかを再検証。コンパイラ最適化だけでは限界があり、AVX2を駆使した手作りのSIMD実装でようやく読み出し速度に近づいたが、それでも単一スレッドではストレージの理論性能に遠く及ばない、という結論。

## この記事を読むべき理由
日本のエンジニアが遭遇する「面接問題／ログ集計／テキスト処理」の現場で、単純にI/Oを疑う前に何を疑うべきか、そして実務的にどの対策（SIMD、分岐削減、キャッシュ配慮など）が効果的かが実測データとともに示されているから。SSDやNVMe採用が進む日本企業の現場で役立つ視点です。

## 詳細解説
- 背景観測
  - 最近のストレージ順次読み出し速度は大きく向上。一例では「冷キャッシュで1.6 GB/s、温キャッシュで12.8 GB/s」という測定も報告される一方、従来のソースコード（最適化済みC）での単語頻度カウントは数百MB/sにとどまる。
- 問題の本質
  - 元のC実装は「ループ内の分岐（早期脱出、大小判定、ケース変換）」が多く、コンパイラの自動ベクトル化を阻害していた。
  - 単純化（小文字化をループ外へ出す）だけで性能が改善する例もあり、分岐削減の効果は大きい。
- ベースラインの再検証
  - 単に単語数を数える「wc -w」も想定より遅く（約245 MB/s）、実装がロケールや複数種の空白を扱うため分岐が増えることが原因。
- SIMD（ベクトル化）でのアプローチ
  - VPCMPEQB のような比較命令で一括に空白位置マスクを作り、PMOVMSKBでビットマスクを取り出し、ビットトリック（__builtin_ffs 等）で立ち上がりを見つける手法を採用。
  - AVX2を用いて明示的に256ビットレジスタでデータを処理、ループ展開・32バイト境界でのアラインメントなどの低レベル最適化を施し、手作業で実装した結果、単一スレッドで約1.45 GB/s（温キャッシュ）を達成。
- しかし
  - これでも「温キャッシュの順次読み出し最大 ~12.8 GB/s」に対しては約11%程度しか到達できず、I/Oだけが問題ではないことが示唆される。つまりディスク速度が上がった現代、CPU側（アルゴリズム＋低レベル実装）が新たな課題になる。

小さな補足（スループットの式）:
$$
\text{throughput} = \frac{\text{入力サイズ}}{\text{処理時間}}
$$

簡単なビットトリック例（__builtin_ffs の使い方、抜粋）:
```c
#include <stdio.h>

int main() {
    int mask = 0b0100000100001000;
    int prev = 0;
    while (mask) {
        int curr = __builtin_ffs(mask);
        if (curr > prev + 1) printf("Word start at %d\n", curr);
        prev = curr;
        if (curr == 32) break;
        mask = (mask >> curr) << curr;
    }
}
```

## 実践ポイント
- まずは計測：I/O（cold/warm）の実測値と処理時間を必ず取る。sysctlでキャッシュを落とすなど冷・温での比較を行う。
- 分岐を減らす：ループ内の条件分岐や早期脱出は自動ベクトル化を阻害する。可能なら事前処理で分岐を外へ出す。
- SIMDを検討する：VPCMPEQB、PMOVMSKB、ビットトリック、__builtin_ffs などの組合せで大量データをまとめて処理できる。コンパイラ任せにしない実装は効果が大きいが工数もかかる。
- コンパイラとフラグ：clang は自動ベクトル化で強い場合がある。ビルドは -O3 -march=native で比較検証を。
- 高レベルライブラリを検討：手作業の immintrin.h は辛い。SIMDラッパーやJuliaのVectorizationBase.jlのような高レベルAPIを試すと生産性が上がる。
- 実運用では：単一スレッドでの最高化だけでなく、アルゴリズム改善（キャッシュ局所性、ワード頻度分布を利用した最適化）やマルチスレッド化も合わせて検討する。

参考：記事の著者は実装をGitHubで公開しているため、実測・実験から学ぶには良い出発点。
