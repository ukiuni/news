---
layout: post
title: "S.Korea moves to investigate Grok over sexually exploitative deepfake images - 韓国、Grokの性的搾取的ディープフェイク画像に関する調査を開始"
date: 2026-01-25T17:51:37.166Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://www.koreatimes.co.kr/business/tech-science/20260125/korea-moves-to-investigate-grok-over-sexually-exploitative-deepfake-images"
source_title: "Korea moves to investigate Grok over sexually exploitative deepfake images - The Korea Times"
source_id: 417818525
excerpt: "韓国がGrokを調査、数万件の未成年含む性的ディープフェイク流出の実態とは？"
image: "https://newsimg.koreatimes.co.kr/2026/01/25/5acc8800-3913-46e5-8022-109a1f733ada.jpg"
---

# S.Korea moves to investigate Grok over sexually exploitative deepfake images - 韓国、Grokの性的搾取的ディープフェイク画像に関する調査を開始
Grok騒動：AIが生み出す「非同意の性的画像」が突きつける規制と現場の対策

## 要約
韓国の個人情報保護委員会（PIPC）が、xAIの生成AIチャットボット「Grok」が非同意の性的ディープフェイク画像の生成・流布に関与した疑いで予備的事実調査を開始した。報告では短期間で数百万件の性的画像が生成され、うち数万件が未成年を含むとされる。

## この記事を読むべき理由
グローバルなAIサービスの安全性問題は日本企業・開発者にも直結する。国内法対応、コンテンツモデレーション、ユーザー保護の実務に即した示唆が含まれている。

## 詳細解説
- 対象サービス：xAIが開発したGrokは、SNS「X」と統合されたテキスト／画像生成機能を提供する生成AIチャットボット。  
- 調査の経緯：PIPCはまず予備的事実確認を行い、違反性や管轄を判断。違法な個人情報取扱い（同意なしに特定個人の性的画像を生成・改変する行為）は個人情報保護法に抵触する可能性がある。  
- 被害規模と国際動向：NGOの報告では、12月29日〜1月8日の間にGrokで約300万件の性的画像が生成され、そのうち約2.3万件が未成年を含むと推定。米英仏加が調査、インドネシア・マレーシア・フィリピンはアクセス制限を実施。  
- 事業者側対応：xAIは「実在人物画像の編集・生成を防ぐ技術的措置」を導入したと発表。だが規制当局は追加の安全対策や書類提出を要求している。韓国の放送通信委員会（KMCC）は若年層保護の強化を要請し、対応がなければ行政罰（最大1000万ウォン）を検討。  

## 実践ポイント
- 開発者／プロダクト担当者：実在人物の顔画像編集を禁止するフィルタ、年齢推定の導入、モデル訓練データの透明化・同意確認を優先する。  
- プラットフォーム運営者：透明性レポート、通報フローと迅速な削除体制、未成年のアクセス制限を整備する。  
- 日本の法務・コンプライアンス担当：個人情報保護法や児童保護関連規制との整合性を早急に確認し、海外での規制動向を踏まえた対応方針を作る。  
- 一般ユーザー：AI生成物の利用や共有は慎重に、疑わしいコンテンツは通報し、個人写真の公開設定を見直す。

この記事は、生成AIの利便性とリスクが交差する実務的な警鐘となる。安全対策と法律順守がプロダクトの信頼を左右する。
