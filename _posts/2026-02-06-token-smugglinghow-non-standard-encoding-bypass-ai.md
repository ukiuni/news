---
layout: post
title: "Token Smuggling: How Non-Standard Encoding Bypass AI Security - トークンスマグリング：非標準エンコーディングがAI防御をすり抜ける仕組み"
date: 2026-02-06T12:57:50.405Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://instatunnel.my/blog/token-smuggling-bypassing-filters-with-non-standard-encodings"
source_title: "Token Smuggling:How Non-Standard Encoding Bypass AI Security | InstaTunnel Blog"
source_id: 407872510
excerpt: "非標準エンコーディングがLLMの単純フィルタを巧妙に回避し実運用リスクを高める対策必須の記事"
image: "https://i.ibb.co/MkqQShZS/Token-Smuggling-Bypassing-Filters-with-Non-Standard-Encodings.png"
---

# Token Smuggling: How Non-Standard Encoding Bypass AI Security - トークンスマグリング：非標準エンコーディングがAI防御をすり抜ける仕組み
クリックせずにはいられない：あなたのチャットボットを「見抜けない」攻撃が既に進化している理由

## 要約
文字列の“見た目”とモデルが内部で扱う“トークン”の違いを突く手法（トークンスマグリング）が、単純なキーワードフィルタを容易にすり抜ける。防御は正規表現だけでは不十分で、トークン化や出力監視を含む多層防御が必須になる。

## この記事を読むべき理由
日本でもLLMを組み込むサービスやチャットボット導入が進む中、表面的な入力検査だけでは法令順守や企業のブランドリスクを守れない。攻撃は既に視覚的トリックやエンコーディングを使って実運用のフィルタを回避しているため、現場のエンジニアやセキュリティ担当は対策を知っておく必要がある。

## 詳細解説
- 問題の本質：多くの防御は文字列マッチ（正規表現）で危険語を探す。一方でLLMはトークン（サブワード）を使って入力を内部表現に変換するため、この二者の「読み方の差」が攻撃の隙となる。  
- 主な回避パターン（高レベル）  
  - 異字体・混在スクリプト：見た目は同じでも別コードポイントの文字を混ぜることで、文字列マッチを回避する。  
  - エンコーディングラップ（例：データエンコーディングで実質の意図を隠す）：入力自体を別形式で包んで、フィルタが中身を検査しない隙を突く。  
  - 未学習トークンや異常トークンの利用：モデル語彙中の希少トークンが挙動を乱し、安全性制約が弱まる可能性。  
  - レトロな手法の拡張（リーㇲトや母音除去など）：人間の直感を外す表記でフィルタとモデルの解釈差を利用する。  
- なぜLLMは「復元」してしまうか：巨大モデルは多言語・コード・パターンから意味を推定する能力が高く、ノイズや変形を内部で正規化してしまうことがある。これが“見えない命令”を再構築してしまう原因の一つ。  
- リスクの実務面：誤情報拡散、規制対象コンテンツの提供、内部機密漏洩指示の実行など、企業運用での重大インシデントにつながり得る。

## 実践ポイント
- 入力正規化を徹底する：Unicodeの正規化形式や不可視文字の除去を事前処理で実行する（詳細設計で検討）。  
- トークン化を意識した検査：モデルと同じトークナイザで入力をトークン化し、トークン列レベルでのブラックリスト照合を行う。  
- 出力フィルタ（セカンドモデル）を導入する：生成後のテキストを別モデルやシグネチャで検査してブロックする方針を必須にする。  
- 統計的検出：過度にランダムな文字列や高い予測困難性（perplexity）を検知してフラグ付けする。  
- レッドチーミングと継続的評価：実運用前後に模擬的な回避試験を実施し、新たな手法に対する耐性を定期的に確認する。  
- ガバナンス整備：ログの保持、異常検知時のエスカレーションルール、法務・CSとの連携を明確化する。

（注意）ここで述べたのは防御とリスク認識のための高レベル解説です。具体的な回避手法を実行するための手順やペイロードは提供しない。安全運用と倫理を最優先に対応を進めてください。
