---
layout: post
title: "Microsoft Copilot Reprompt exploit allowed attackers to steal your AI data - Microsoft Copilotの「Reprompt」脆弱性でAIデータが流出する恐れ"
date: 2026-01-14T18:18:11.134Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://www.windowscentral.com/artificial-intelligence/microsoft-copilot/copilot-ai-reprompt-exploit-detailed-2026"
source_title: "Patched Microsoft Copilot Reprompt exploit stole user data | Windows Central"
source_id: 426931991
excerpt: "ワンクリックでCopilotが機密を外部送信、今すぐ対策必須の脆弱性とは？"
image: "https://cdn.mos.cms.futurecdn.net/69VpweEQV86WafY924hdpP-2048-80.jpg"
---

# Microsoft Copilot Reprompt exploit allowed attackers to steal your AI data - Microsoft Copilotの「Reprompt」脆弱性でAIデータが流出する恐れ
ワンクリックでAIが情報を流す？Copilot「Reprompt」攻撃の全貌と日本で今すぐやるべき対策

## 要約
セキュリティ企業Varonisが発見した「Reprompt」脆弱性は、URLのパラメータを悪用してMicrosoft Copilotに不正な命令を実行させ、ユーザーの機密情報を外部サーバへ送信させる攻撃で、2026年1月13日に修正されました。

## この記事を読むべき理由
日本企業や個人がCopilotやクラウドAIを業務で使う機会が増える中、ワンクリックで情報漏洩につながる攻撃手法が実在したことは他人事ではありません。社内教育、運用設定、パッチ適用の優先度を見直す必要があります。

## 詳細解説
- 攻撃の仕組み：攻撃者は特殊なqパラメータ（URLに埋め込むクエリ）を用いて、ページ読み込み時にCopilotの入力欄に質問/命令を自動で注入させます。これによりユーザーの明示的な入力なしにAIが即時に処理を始めます。  
- 逸脱ポイント：通常の設計ではCopilotは外部URLへ勝手にアクセスしたりデータ送信を拒否するようになっていましたが、Varonisはプロンプトの工夫でその防御を回避し、生成結果やユーザー情報を攻撃者側のサーバへ送信させる手口を作り出しました。  
- 被害シナリオ：攻撃者は「今日見たファイル一覧」や「ユーザーの位置情報」などをAIに問い合わせ、得られた回答を外部へ送ることでデータ窃取を行えます。重要なのは「ワンクリックで完了」し、Copilotが閉じている状態でも実行可能だった点です。  
- 影響範囲と対応：Varonisは2025年8月に報告し、Microsoftは2026年1月13日に修正をリリースしました。今回の手法はEchoLeakなど既知のAI関連攻撃とは異なり、より低いユーザー交互性（クリックのみ）で成立します。

## 実践ポイント
- すぐにやること：利用中のWindows/Microsoft 365/Copilot関連の更新を適用する（2026年1月13日以降のパッチを確認）。  
- 運用対策：メールや外部リンクでCopilotを呼び出すURLを安易に開かないポリシーを徹底する。社内でのフィッシング演習を強化する。  
- 設定と監視：Copilotや関連サービスの外部連携設定を点検し、qパラメータ的な自動実行を抑止するオプションがあれば有効化する。アクセスログや異常な外部通信の監視ルールを追加する。  
- 教育／規程：非公開情報をAIに入力しないルールの明文化と従業員教育（特に営業・総務などのファイルや位置情報を扱う職種）。  
- セキュリティ設計：ゼロトラスト原則の適用、外部へのデータ送信を防ぐ出口対策（DLP：Data Loss Prevention）を導入・強化する。

短い対策で被害は大きく減らせます。まずはパッチ確認と「リンクを安易に開かない」運用から始めてください。
