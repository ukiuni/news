---
layout: post
title: "Building a Multi-Tenant Metrics Pipeline for Thousands of Clients - 数千クライアント向けマルチテナントメトリクスパイプラインの構築"
date: 2026-01-21T11:14:09.941Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://jamesrobb.ca/projects/metrics_pipeline/"
source_title: "James Robb &#183; Building a Multi-Tenant Metrics Pipeline for Thousands of Clients"
source_id: 421300219
excerpt: "HeimdallとThanosで数千顧客の監視を安全かつロス無く集約する実践設計"
---

# Building a Multi-Tenant Metrics Pipeline for Thousands of Clients - 数千クライアント向けマルチテナントメトリクスパイプラインの構築
Thanosと独自プロキシ「Heimdall」で実現する、リアルタイムかつライセンス保護された監視基盤

## 要約
Prometheusの単純なRemote Writeでは満たせない要件（データ損失回避、動的な収集設定、テナント分離）を解決するために、Authorは「Heimdall」というIngress/Egressプロキシを開発し、Thanosと組み合わせて大規模で安全なマルチテナントメトリクスパイプラインを構築した。

## この記事を読むべき理由
- マルチテナントSaaSやクラウドサービスで、数千台・数千顧客のメトリクスを安全に集約したいエンジニア向けの実践設計。
- Prometheus＋Thanosの落とし穴（メモリキューの寿命や静的設定）を回避する実装パターンが学べる。
- 日本の事業者が顧客データ分離やコンプライアンスを保ちつつ可観測性を高める際の参考になる。

## 詳細解説
背景と問題点
- Prometheusは広く使われるが、Remote Write（RWP）だけだと「リモート障害時にメモリ内キューが溢れてデータを捨てる」「Prometheusの設定が静的で運用リスクがある」といった問題が発生する。大量の顧客を相手にするとこれが致命的になる。

Heimdallの役割（概観）
- Heimdallは2つのバイナリで構成：Egress（顧客クラスタ側）とIngress（中央側）。EgressはPrometheusからのRWPを受け取り、フィルタリング、ディスクベースのFIFOに永続化、並列キューで送信する。Ingressはライセンス検証とテナントごとのフィルタ設定を提供し、Thanosへ転送する。

Egressの工夫
- フィルタリング：ホワイト／ブラックリスト（正規表現）で不要／機密性の高いメトリクスを除外。例：「yb_.* を取りつつ yb_bad_metric は除外する」といった細かな制御が可能。
- 永続化：ディスクベースのFIFOを使い、mothership側（中央）やネットワークが落ちてもローカルに貯めておけるためデータ損失を防止。
- 並列化：メトリクス名をハッシュしてN個のフォワーディングキューに決定的に振り分ける。これにより同一メトリクスのタイムスタンプ順序が保たれる一方、スループットをスケールできる。
- 再送制御：Ingressからの応答に応じて、受領（破棄）、再試行待ち、または破棄（不正なペイロード）を選別。

Ingressの役割
- ライセンス（JWT）検証：公開鍵ストアで署名と有効期限をチェック。無効ならEgressに再試行を促す（ライセンス更新後に受け取り可能にするため）。
- テナント管理：ライセンスに基づきテナントIDを決定し、そのテナントごとのホワイト／ブラックリストを提供。ThanosへはテナントIDをHTTPヘッダで渡す（テナント分離の実現）。

Thanos側の配慮
- Thanos Receiveをルータとイングestorに分けて配置。ルータはハッシュ（ketama推奨）でどのイングestorに送るか決定し、イングestorはローカルTSDBに保存後、定期的にオブジェクトストレージへブロックをアップロードする。
- テナントごとに別TSDBを使うことでデータ混在を防ぎ、クエリの効率とガバナンスを確保している。

なぜ二重アンパックを許容したか
- Egressは受信時にまずフィルタリングして不要なデータをディスクに残さない。FIFOから送信準備する段階でもう一度アンパックしてキュー振り分けを行う。二度アンパックするコストはネットワーク待ちが主体のため許容でき、ディスク容量効率と順序保証を優先した設計となっている。

## 実践ポイント
- PrometheusのRemote Writeだけに依存しない：ローカルにディスク永続化できるプロキシ（またはバッファ）を置くことでデータ損失リスクを劇的に下げられる。
- メトリクスのフィルタは正規表現ベースで：ホワイトリスト＋ブラックリストの組み合わせが運用を楽にする。
- メトリクスの順序性を守るための決定論的ハッシュ振り分け：同一メトリクスは常に同じ送信キューへ入るようにする。
- ライセンス／テナント識別はJWT等で明示し、受け側で検証してからストレージに入れる：コンプライアンスや課金要件に有効。
- Thanos運用ではketama等の安定ハッシュを使い、ルータとイングestorを分けてスケール戦略を明確にする。
- 日本の現場での応用例：オンプレ＋クラウド混在、特定顧客のデータ分離、地域別リージョン運用、SaaS事業者の監査対応などにそのまま適用可能。
- まずはプロトタイプで負荷試験を：並列キュー数やディスクサイズ、再送ポリシーを負荷下で調整することが重要。

このパターンは「可観測性の品質」と「顧客データの安全性」を両立させたい日本のSaaS／クラウド事業者にとって有効な設計です。実装の原則（ローカル永続化・フィルタリング・テナント認証・安定ハッシュによる配分）を押さえれば、スケーラブルで運用しやすいパイプラインを構築できます。
