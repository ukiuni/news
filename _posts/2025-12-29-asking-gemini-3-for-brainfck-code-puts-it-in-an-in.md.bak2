---
layout: post
title: "Asking Gemini 3 for Brainf*ck code puts it in an infinite loop"
date: 2025-12-29T11:26:43.078Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://teodordyakov.github.io/brainfuck-agi/"
source_title: "Brainf*ck: The Ultimate AGI Test"
source_id: 46418966
excerpt: "Gemini 3にBrainf*ck生成を頼むと無限ループ化し、停止性と推論力の脆弱性を暴く実例解説"
---

# Asking Gemini 3 for Brainf*ck code puts it in an infinite loop
Brainf*ckでLLMを「壊す」――単純さが暴く本当の知能


## 要約
一見無意味な極小言語「Brainf*ck」は、巨大言語モデル（LLM）にとって記号的推論と停止性の両方を問う強力なストレステストになる。実際に最新モデルに複雑なBrainf*ck生成を頼むと無限ループ（出力の自己増幅）が発生することが観測されている。

## この記事を読むべき理由
Brainf*ckはデータ量や可読性に頼る現代のLLMの弱点を明確に露呈する。日本のAI開発者やプロダクト担当は、モデル評価、セーフガード設計、少量データ領域での性能改善に直接使える知見を得られる。

## 詳細解説
- データ希少性の問題  
  LLMは膨大なコードやテキストのパターンを学習することで振る舞いを獲得する。だがBrainf*ckの公開コードは極端に少なく、一般的な言語に比べて約 $10^6$ 倍近く訓練データが少ないと考えられる。このためモデルは「丸暗記」ではなく言語の意味論を推論する必要がある。

- 反リテラル性（Anti-Literate Programming）  
  Brainf*ckはコメントや意味のある識別子を持たない。指示子の集合が非常に限定され、コードは記号列に過ぎない。既存コードを参照して模倣するアプローチがほとんど通用せず、高レベルな抽象推論と正確な意味モデルを要求する。

- 出力の自己強化と無限ループ問題  
  ミニマルなトークン集合と高い反復性は、モデルが自分の直前の出力を強く参照してしまう状況を生む。あるトークン列が「最尤」になりがちになると、そのトークンが自らを呼び込み、結果的に同じ文字列を延々と吐き続ける自己増幅（無限ループ）が発生する。これはトークンベースの確率モデルの構造的な脆弱性を突く現象であり、停止性（halting）をチェックできないと危険を含む。

- 日本市場との関連性  
  日本企業は組み込みソフトや省リソース環境での特殊言語、また情報セキュリティや難読化コードの評価が重要になる領域が多い。Brainf*ck的な「データが少ない・可読性が低い・高反復性」の課題は国内のレガシー解析、ファームウェア解析、教育（アルゴリズムの本質理解）などにも直結する。

## 実践ポイント
- 診断用途としての活用  
  Brainf*ckの生成タスクをLLMのベンチマークに組み込み、停止性（実行して止まるか）や正答率を測ることで「真の推論力」を評価する。

- プロンプト設計とガードレール  
  出力トークン数の上限、停止条件（stop sequences）、温度の低下、反復検知（同一トークン列の検出）を組み合わせて無限出力を防ぐ。

- 実行時サンドボックスとステップ制限  
  生成したBrainf*ckコードは必ず安全なサンドボックス上で実行し、ステップ数上限（最大ステップ）と実行時間を設定する。無限ループ判定により早期中断する。

- 少数ショット／説明付き生成  
  単にコードを要求するのではなく、アルゴリズムの高レベル説明→擬似コード→Brainf*ckへ段階的に誘導する（分割と検証）ことで成功率が上がる。

- データ拡張と教育的活用  
  Brainf*ckの正解・失敗例を収集して専用の小規模データセットを構築すると、少量データ領域での指導学習や微調整に役立つ。社内教育では「なぜこのコードが止まらないか」を通じてモデルの挙動理解を深める。

短くまとめると、Brainf*ckは「見かけの単純さ」がLLMの本質的な弱点（データ依存、記号的推論、自己参照による出力崩壊）を暴く格好の試金石であり、評価・安全対策・少量データでの強化に実践的な示唆を与える。
