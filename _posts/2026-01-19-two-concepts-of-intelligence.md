---
layout: post
title: "Two Concepts of Intelligence - 知能の二つの概念"
date: 2026-01-19T12:57:42.303Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://cacm.acm.org/blogcacm/two-concepts-of-intelligence/"
source_title: "Two Concepts of Intelligence"
source_id: 46607969
excerpt: "理解と振る舞いの二視点でAI評価を整理し、導入基準と誤解回避策を提示"
---

# Two Concepts of Intelligence - 知能の二つの概念
魅力的なタイトル: 「AIは本当に“理解”しているのか？──知能をめぐる2つの見方を日本の現場向けに整理する」

## 要約
Bertrand Meyerの論考は、「知能」をめぐる議論が主に二つの相反する概念（“理解する”知能と“うまく振る舞う”知能）に基づいていると指摘し、それぞれの長所・限界を対比して現在のAI論争を整理する。

## この記事を読むべき理由
日本でもAI導入は急速に進み、技術評価や政策決定、現場の信頼構築が必要です。議論の出発点である「知能とは何か」を明確にしておくことで、誤解や不毛な論争を避け、実務的な判断（導入基準、評価指標、説明責任）を的確に下せます。

## 詳細解説
- 二つの概念
  - 理解（概念的/演繹的）としての知能：物事を説明し、因果や本質を把握する能力。伝統的に「理解＝intelligo」の語源に基づく欧州的な見方。理論的で「なぜそれが起きるか」を重視するため、反証可能性（falsifiability）が重要。
  - 適応・予測（帰納的/経験的）としての知能：環境にうまく対応し、経験から学んで正しい行動や予測を出せる能力。米国のAI研究で重視される実用志向の定義で、機械学習・深層学習はここに該当する。
- 議論の源泉
  - Turingテストや中国語の部屋の議論が示す通り、観測可能な振る舞い（出力）だけで評価するとAIは高評価を得やすい。一方で「本当に理解しているか」を定義・実験的に証明するのは難しい。
  - 古いルールベース（エキスパートシステム）は演繹的アプローチ、現代のMLは帰納的アプローチに相当し、失敗や成功の性質が異なる。
- 実例的問答
  - 翻訳や画像診断などでAIが人間を上回るケースが増えると、「理解の有無」を理由にAIの成果を否定する説明は説得力を欠く。逆に、誤答（幻覚）を根拠に「理解していない」と主張するのも反証不能な主張に留まりやすい。
- 結論的観点
  - どちらの定義を採るかで「AIは知能か？」という問いの答えが変わる。議論を建設的にするためには、前提（どの知能観を採るか）を明示することが不可欠。

## 実践ポイント
- 議論の前に前提を明示する：政策提言や社内説明では「ここでは知能を○○（理解／適応）と定義する」と宣言する。
- 評価は観測可能な指標で行う：精度、再現率、F1、キャリブレーション、誤検出率、ヒューマン・イン・ザ・ループでの比較など、帰納的な成果を数値化する。
- 反証可能な実験を設計する：特定タスクでの一般化能力やロバストネス（未知データ・敵対的入力）をテストして、性能の限界を明確にする。
- ハイブリッド設計を検討する：説明可能性（XAI）やルールと学習の組合せで「理解っぽさ」と「高性能」を両立する試みを行う。
- 日本市場向けの実務対応
  - 医療、翻訳、製造ラインにおける導入判断は「人間の理解力」と「機械の再現性」のどちらを優先するかで基準が変わる。用途別に定義を分けると運用が進めやすい。
  - 規制・説明責任の観点では「なぜその結果になったか」を示す手順（ログ、説明生成、検証フロー）を整備する。

この記事を読めば、AIに対する感情論や非科学的な反応を避け、技術評価・導入判断を論理的かつ実務的に進めるための視点が手に入ります。
