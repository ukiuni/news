---
layout: post
title: "ICE’s Facial Recognition App Misidentified a Woman. Twice | ICE has said the app's results are a “definitive” determination of someone's immigration status - ICEの顔認識アプリが女性を誤認。しかも2度／ICEはアプリの結果を「決定的」と主張"
date: 2026-01-19T20:59:37.835Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://www.404media.co/ices-facial-recognition-app-misidentified-a-woman-twice/"
source_title: "ICE’s Facial Recognition App Misidentified a Woman. Twice"
source_id: 422679797
excerpt: "ICEの顔認識が拘束女性を二度誤認、「決定的」判定の危険性露呈"
image: "https://www.404media.co/content/images/size/w1200/2026/01/54977911914_4995b93005_k.jpg"
---

# ICE’s Facial Recognition App Misidentified a Woman. Twice | ICE has said the app's results are a “definitive” determination of someone's immigration status - ICEの顔認識アプリが女性を誤認。しかも2度／ICEはアプリの結果を「決定的」と主張

政府が「決定的」と信じるAIが二度も失敗した――移民取締現場で起きた顔認識の実例

## 要約
米国移民税関執行局（ICE）が運用する顔認識アプリ「Mobile Fortify」が、拘束中の女性をスキャンして2回とも別人の誤った氏名を返した。ICEは同アプリの結果を出生証明書よりも信頼できる「決定的」判定だと説明してきたが、実際の運用で重大な誤りが露呈した。

## この記事を読むべき理由
顔認識技術は捜査・入国管理・公共サービスに広く使われつつあり、判定誤りは人の自由や法的地位に直結する。日本でも顔認証の導入が進む中、技術限界と運用上のリスクを理解しておかないと制度設計や権利保護で重大な見落としが生じる。

## 詳細解説
- 何が起きたか：米国のある移民摘発現場で、拘束された女性の顔をMobile Fortifyでスキャンしたところ、システムは2回にわたって異なる氏名を提示。両方とも誤認識であり、同アプリの「決定的」判定という説明と矛盾する実例になった。
- 技術的な流れ：一般的な顔認識は（1）顔検出（2）アライメント（3）特徴抽出（埋め込みベクトル）（4）照合（距離計算と閾値判定）というパイプラインで動作する。誤認はデータ品質、照合用データベース（氏名付き画像）の不一致、閾値設定、照明や角度、マスクや高齢化などの外的要因、そしてモデルのバイアス（人種・性別・年齢による誤差差異）で生じる。
- 運用上の問題：ICEは結果を「決定的」として扱うと報じられているが、顔認識は確率的であり偽陽性（別人を一致と判定）や偽陰性が常に存在する。監査ログやヒューマンインザループ（人が最終判断を下す段階）が不十分だと、誤判定が拘束や送還につながる恐れがある。
- エコシステムの問題：元記事では、Palantirや「ELITE」「Tangles」「Webloc」といった他の監視ツールとの連携も指摘される。顔認識が他データ（行動履歴、位置情報、過去の記録）と結びつくと、誤りの影響は個人の生活全般に波及する。
- 法的・倫理的観点：技術的誤認が法的判断に使われる場合、透明性（どのデータベースと照合したか、閾値やモデルの性能）、説明責任、独立監査、異議申し立て手続きが不可欠。

## 実践ポイント
- 市民向け
  - 行政機関が顔認証で判定を下す場合は「機械判定だけで即時処分しない」こと、説明責任と異議申立てルートを求める。
  - 個人情報の扱い（保存期間、共有先、目的）を確認する。公開請求や市民団体への相談が有効。
- エンジニア/開発者向け
  - 評価指標は単一の精度だけでなく、FAR（偽陽性率）、FRR（偽陰性率）、ROC曲線、デモグラフィックごとの混同行列を必ず公開する。
  - データセットの偏り（人種・性別・年齢差）を検出・是正し、閾値は運用目的に合わせて調整、ヒューマンレビューを組み込む。
  - ロギングと説明可能性（どの照合結果が根拠か）を設計に組み込み、監査可能にする。
- 政策立案者向け
  - 重大な権利に影響する用途（拘束・送還・逮捕など）での自動判定は禁止または厳格な監査を義務付ける。
  - 第三者の独立監査と透明な性能報告、影響評価（AIA：Algorithmic Impact Assessment）を必須化する。

顔認識技術は便利だが「万能」ではない。現場での誤認は人命・権利に直結するため、技術の限界を前提にした制度設計と運用監視が不可欠だ。日本でも同様の議論と具体的なガードレール構築が急務といえる。
