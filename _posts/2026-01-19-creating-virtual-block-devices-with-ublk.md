---
layout: post
title: "Creating virtual block devices with ublk - ublkで仮想ブロックデバイスを作る"
date: 2026-01-19T18:57:00.246Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://jpospisil.com/posts/2026-01-13-creating-virtual-block-devices-with-ublk"
source_title: "Creating virtual block devices with ublk - Jiri Pospisil"
source_id: 1305532368
excerpt: "io_uringでユーザ空間に高速仮想ブロックデバイスを実装し、メモリ最適化手法を解説"
---

# Creating virtual block devices with ublk - ublkで仮想ブロックデバイスを作る
魅力を引く日本語タイトル案：io_uringでユーザ空間に“ストレージの頭脳”を置く — ublk入門と実務で使うための要点

## 要約
ublkはLinuxカーネル（v6.0以降）で提供される実験的フレームワークで、io_uringを使ってユーザ空間で仮想ブロックデバイスを実装できる。パフォーマンスを損なわずにカーネル責務の一部をユーザ空間へ移せるのが特徴。

## この記事を読むべき理由
- 日本のクラウド／ストレージ開発や組込み・エッジ領域で、高速I/Oや柔軟なデバイス実装の需要が高まっているから。
- カーネルモジュールを書かずに好きな言語とライブラリで「ブロックデバイスの振る舞い」を作れる点は、製品開発やプロトタイピングで大きな利点になる。

## 詳細解説
- 全体像  
  ublkは2部構成：カーネル側ドライバ（ublk_drv）と、ユーザ空間の「ublkサーバ」。サーバは/dev/ublkbN（ブロック側）と/dev/ublkcN（制御側）を介してカーネルとやり取りし、実際のI/O処理をユーザ空間で行う。ファイルシステムやdmなど既存のブロック層はこの仮想デバイスを通常のブロックデバイスとして扱える。

- なぜ性能が出るのか（io_uringの使い方）  
  従来、ユーザ空間⇄カーネルの往復はコンテキストスイッチのオーバーヘッドが重かった。ublkはio_uringを用いて「複数の作業をまとめて受け取り、まとめて処理する」ことでスイッチ回数当たりの処理量を増やし、オーバーヘッドを相対的に小さくする。サーバは複数のタグ（tag）を持ち、(q_id, tag) ペアで作業を識別してio_uringに一括で投げる。

- ワーカー構成とメモリ  
  典型的なサーバはメインスレッドでドライバ接続を作り、I/Oキュー数に応じてワーカスレッドを立てる。各スレッドはキュー深さ（タグ数）分のbuffer/descriptorを持つため、バッファサイズ×深さ×スレッド数でメモリ消費が増える（例：1MiB×128＝128MiB/スレッド）。対策として深さやバッファを小さくする、MADV_DONTNEEDで遊休ページを戻す、あるいは後述のユーザコピー方式を使う。

- データ転送モード（主要3種）  
  1) デフォルト（事前割当）: 各(tag)にページアライメントされたバッファをあらかじめ割り当て、addrで位置を伝える。シンプルだがメモリ消費が大きい。  
  2) ユーザコピー（UBLK_F_USER_COPY）: リクエスト到着時に必要な長さのバッファを都度確保して渡す。メモリ効率良好で外部ライブラリのバッファをそのまま使えるなど柔軟性が高い。制御側デバイス（/dev/ublkcN）を介してデータ受け渡しを行う。  
  3) ゼロコピー（UBLK_F_SUPPORT_ZERO_COPY）: io_uringの固定バッファテーブルを使い、カーネル側バッファと直接紐付ける方式。コピーを排して高スループットを狙えるが、buf_indexによる間接参照になるため実装制約がある。自動登録オプション（UBLK_F_AUTO_BUF_REG）を有効にすると登録/解除の手間を減らせるが失敗に備えたフォールバック処理が必要（UBLK_IO_F_NEED_REG_BUF をチェック）。

- 実装のコツと注意点  
  - サブミッションの user_data フィールドで「ドライバ作業」か「サーバが起こしたio_uring操作」かを区別する。  
  - io_uringは IORING_SETUP_SQE128 と IORING_SETUP_CQE32 のサポートが必要（サポートしない言語バインディングだと破壊的な不具合になる）。  
  - 自動バッファ登録は便利だが、失敗ケースを必ず処理すること。  
  - キュー深さ・タグ数とバッファサイズはスループットとメモリのトレードオフ。負荷の高い環境では深さを上げてバッチ化で効率化する一方、メモリ限定ならユーザコピーやMADV_DONTNEEDを検討する。

- 安定性・互換性  
  ublkは実験マーク付きでAPI変更の可能性あり。カーネルバージョンの制約（v6.0以上だが例外あり）を確認のこと。

## 実践ポイント
- 環境確認：Linuxカーネルがubulkをサポートしているか（v6.0+）、io_uringの128/32バイト設定を使えるかをまず確認する。  
- まずは公式ツールを使う：ublkのコマンドラインユーティリティでデバイス一覧や状態を確認してから実験する。  
- 言語選択：Rust/Cはライブラリが揃っている。自分の言語でやるならio_uringと低レベルメモリ操作が可能か確認する。  
- メモリ計画：ターゲットワークロードに合わせてバッファサイズとキュー深さを決める。開発段階は小さめにしてプロファイリングしつつ調整する。  
- モード判断：  
  - プロトタイプや実装簡便さ重視 → デフォルトモード。  
  - メモリ効率や外部バッファ再利用を重視 → ユーザコピー。  
  - 最高スループットかつ実装の複雑さを許容できる → ゼロコピー（自動登録＋フォールバック実装推奨）。  
- 実地検証：ローカルNVMeやネットワークストレージ負荷下でlatency/throughputとメモリ使用量を測定し、IOパスごとの遅延要因（ユーザ⇄カーネル往復、バッファ登録など）を可視化する。  
- 日本向け応用例：クラウドのブロックサービスプロトタイプ、組込み/ネットワーク機器でのカスタムキャッシュ層、エッジでのオンデマンド生成ストレージ（計算でデータ生成して返す用途）など。

最後に一言：ublkは「カーネルを書かずにブロックデバイスを作れる」点で実験的ながら魅力的です。まずは小さなプロトタイプでio_uring周りの振る舞いを学び、使いどころ（高スループット vs メモリ制約）に応じてモードを選ぶことをお勧めします。
