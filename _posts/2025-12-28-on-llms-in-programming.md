---
layout: post
title: "On LLMs in programming"
date: 2025-12-28T02:17:20.331Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://blog.danieljanus.pl/2025/12/27/llms/"
source_title: "On LLMs in programming"
source_id: 1513545431
excerpt: "LLMで生産性を高めつつ注意力喪失を防ぐ実践ガイド・検証法やRAG導入の実践手順付き"
---

# 注意力を奪うAI？プログラミングでLLMを賢く使うための最短ガイド

## 要約
著者は「意識的なLLM懐疑派」として、日常の開発でLLMを実際に使いつつも不安を抱えている。LLMは生産性を変える一方で、注意（＝開発者の最も貴重な資源）をどう配分するかを再考させる。

## この記事を読むべき理由
LLMは既に開発現場の風景を変えつつあり、日本のプロダクト開発や組織運用にも直接影響する。便利さの裏にある注意力のコストや具体的な技術的制約を理解しておくことで、実務での導入判断がブレなくなる。

## 詳細解説
- LLMがプログラミングで果たす役割  
  - 自動補完・コード生成、リファクタリング提案、ドキュメント作成、テストケース生成、バグ原因の探索など、反復的・言語的タスクの効率化に強みがある。  
  - 実装ではVS Codeの拡張（例: Copilot、ChatGPT拡張）やAPI経由でIDEに組み込むのが一般的。

- 技術的制約と落とし穴  
  - 幻覚（hallucination）：根拠のないコードやAPIを生成するリスクがあるため、そのまま採用せず検証が必須。  
  - 文脈ウィンドウと状態：モデルは長いリポジトリ全体を一度に把握できない。RAG（Retrieval-Augmented Generation）やリポジトリ埋め込みでローカル知識を補強する運用が必要。  
  - 非決定性：同一プロンプトでも出力が変わることがある。CIでの自動合流は注意が必要。  
  - プライバシー／コンプライアンス：ソースコードや顧客データを外部APIに投げる際の規約・社内ポリシー整備が重要。オンプレやプライベートモデルを検討する価値あり。

- 使い方の技術パターン  
  - Few-shot / prompt engineering：短い例を与えて期待するスタイルを誘導する。  
  - RAG + ベクターストア：リポジトリや設計資料を埋め込み検索して根拠に基づいた回答を得る。  
  - 自動テストで検証：生成コードは必ずテストで挙動を担保する。Lint／静的解析も組み合わせる。  
  - ヒューマン・イン・ザ・ループ：最終判断は人間が行う運用フローを組む。

- 注意力（Attention）の視点  
  - 著者はSherlock Holmesの「頭の屋根裏」比喩を引き、注意は有限であり、何に興奮（集中）するかを選ぶべきだと主張する。LLMは情報取得のコストを下げる一方で、注意の分散や浅い思考を誘発する危険がある。特に設計やアーキテクチャの深い思考は外注すべきではない。

## 実践ポイント
- 短期的（今日からできる）  
  - VS Codeに公式/信頼できるLLM拡張を入れ、生成結果は必ずローカルでテストする。  
  - プロンプトテンプレートをチームで共有（入力→期待出力の例を整備）。  
  - 生成コードはコードレビュー必須にする。自動CIでユニットテストを必須化。

- 中期的（チームで運用）  
  - RAGとベクターデータベースで社内ナレッジを“根拠”として与える。  
  - 外部API利用のガイドライン、データ出力ログを整備し監査可能にする。  
  - モデルの振る舞い（誤答率・型の逸脱など）をKPI化して運用改善する。

- 長期的（戦略）  
  - どの作業をLLMに任せ、どの作業で深く思考するかをチームの「注意ガイドライン」として定める。  
  - 必要ならプライベート/オンプレモデルを評価してデータ漏洩リスクを下げる。  
  - 教育：LLMを補助ツールとして使いこなすスキル（プロンプト設計、出力検証、RAG設計）を育てる。

## 引用元
- タイトル: On LLMs in programming  
- URL: https://blog.danieljanus.pl/2025/12/27/llms/
