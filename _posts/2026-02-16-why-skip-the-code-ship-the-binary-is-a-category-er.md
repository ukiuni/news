---
layout: post
title: "Why “Skip the Code, Ship the Binary” Is a Category Error - 「コードを飛ばしてバイナリを出荷する」はカテゴリーエラーだ"
date: 2026-02-16T09:51:50.742Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://open.substack.com/pub/engrlog/p/why-skip-the-code-ship-the-binary?r=779hy&amp;utm_campaign=post&amp;utm_medium=web&amp;showWelcomeOnShare=true"
source_title: "Why “Skip the Code, Ship the Binary” Is a Category Error"
source_id: 441687376
excerpt: "LLMでバイナリ直生成はなぜ現実的でないか—コンパイラの本質から明快に解説"
image: "https://substackcdn.com/image/fetch/$s_!tqX3!,w_1200,h_675,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2082951-d747-469d-b8f3-9f979805eafc_1800x1000.png"
---

# Why “Skip the Code, Ship the Binary” Is a Category Error - 「コードを飛ばしてバイナリを出荷する」はカテゴリーエラーだ
バイナリ直生成AI？それ、なぜ技術的にも実務的にも成り立たないのか — コンパイラの仕事を知れば納得する理由

## 要約
Elon Muskらが提唱する「ソースコードを飛ばしてAIが直接バイナリを生成する」という発想は、コンパイラの役割とLLMの性質を混同した誤解であり、コスト・正確性・運用性の面で現実的ではない。

## この記事を読むべき理由
コンパイラやLLMの違いは、単なる研究ネタではなくソフトウェア開発の信頼性、セキュリティ、コストに直結します。日本の製造業や組込み、クラウド開発で「AIに任せる」判断をする前に押さえておくべき論点です。

## 詳細解説
- コンパイラの仕事：字句解析→構文解析でAST作成→意味解析で型や参照を検査→中間表現(IR)に落とし最適化パス（定数畳み込み、デッドコード除去、ループ展開、ベクトル化、レジスタ割当など）を経てターゲット用バイナリへ。これらは形式的仕様に基づく決定的な変換で、同じ入力は同じ出力を返す。
- LLMの性質：トークンの確率的生成により「もっともらしい」出力を作るが、正確性の保証がない（＝幻覚）。バイナリの一バイト誤りが致命的な不具合や脆弱性を生むため、完璧な出力が必須。
- コストとエネルギー：最適化済みコンパイルはミリ秒〜数分・低消費電力で済むのに対し、大規模LLMで大量トークン生成するのは高コスト・高電力。現実的な経済性が見合わない。
- 運用と品質管理：ソースコードは人間の検査・差分管理（Git）、コードレビュー、デバッグ、移植性、サプライチェーン監査を可能にする。バイナリだけではこれらがほぼ不可能になり、組織的な開発ワークフローが破綻する。
- しかし有効な役割も明確：LLMはボイラープレート生成、API発見、言語間変換、テスト作成、最適化しやすいコードのリファクタリングなどで強力。実際の研究やツールは「LLMがコンパイラを置き換える」のではなく、「コンパイルチェーンを補強する」方向で成果を上げている（例：LLMを使ったベクトル化支援や、生成コードを形式検証ツールで保証するアプローチ）。

## 実践ポイント
- AI活用は「ソースコードありき」で：LLMはソース生成・補助に使い、従来のコンパイルと組み合わせる運用を推奨する。
- 品質担保の仕組みを残す：CIでの再現ビルド、コードレビュー、署名済みアーティファクト、テスト、形式検証（可能な箇所で）を必須にする。
- コスト・環境配慮：大規模モデルで大量トークンを生成する運用は現実的コストと電力を再計算してから採用する。
- 日本企業向け：組込み・車載・工場制御などでのバイナリ信頼性要求は特に高い。ソースレス運用は規制適合や安全性で致命的リスクを招く。
- ツール活用例：Matt GodboltのCompiler Explorerで最適化の挙動を見る、LLMでリファクタ→コンパイラで検証のワークフローを試す。

短く言えば、LLMは“創造と補助”を担い、コンパイラは“正確で検証可能な変換”を担う。両者を役割分担させるのが現実的な道です。
