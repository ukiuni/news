---
layout: post
title: "AI Lazyslop and Personal Responsibility - AIの「手抜き生成」と個人の責任"
date: 2026-01-26T20:31:22.024Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://danielsada.tech/blog/ai-lazyslop-and-personal-responsibility/"
source_title: "Daniel Sada Caraveo – AI Lazyslop, and Personal Responsibility – Software, Notes & Culture"
source_id: 46770675
excerpt: "AI生成コードの責任をPR・テストで明確化せずに放置するとレビュー地獄と障害を招く"
image: "https://danielsada.tech/images/DanielSadaLogo.png"
---

# AI Lazyslop and Personal Responsibility - AIの「手抜き生成」と個人の責任
AIが書いたコード、本当にレビューしましたか？—「AI Lazyslop」から学ぶ実務ルール

## 要約
AIで生成したコードをそのまま出すと、レビューの負担が増え品質リスクになる。「AI Lazyslop（作者が読んでいないAI生成）」を避け、使用の開示・自己検証・テストを必須にする実務的な提言。

## この記事を読むべき理由
日本の現場でもリリース圧や効率重視からAI生成コードの比率が増えています。品質・責任の線引きを明確にしないと、レビュー停滞や障害につながるため、エンジニアもマネジメントも必読です。

## 詳細解説
- 事例（要点）: 著者は同僚「Mike」から1600行のAI生成PRがテスト無しで出され、レビューを急がされる経験を紹介。要求されたテストに対して「動くから不要」と反発し、マネージャー圧でレビューが流される問題が発生した。
- 定義: AI Lazyslop = 作者が内容を読んでいない／検証していないAI生成コード。受け手（レビュー担当者）に過度な負担を強いる。
- 文化的変化: AI利用は恥ではなく不可避なツールへ。重要なのは「どう使ったか」をチームで合意すること（プロンプトや検証手順の共有）。
- 著者の提案（アンチ・Lazyslop宣言）:
  - コードとAI出力に対する責任を持つ
  - AI使用を明示する
  - 自分で全て読んでテストしたことを証明する
  - PRにプロンプトや修正方針を含める
  - AIで補助しても、最終的な設計・論理を説明できること
- 現実装: 完全な放置→半放置（レビューコメントをAIに投げて修正を得る）というパターンが出てきており、どちらが良いかは未だ議論中。

## 実践ポイント
- PRに次を必ず含める:
  - 「AIを使用しました／モデル名（例: Claude）」の明示
  - 使用したプロンプト/ワークフローの要約
  - 自分が検証・修正した箇所の一覧
- テストポリシー:
  - AIでテスト生成しても良いが、自分で動かして期待結果を確認する
  - 表層的なテスト（単なるgetter/setter確認）ではなく、振る舞いを保証するテストを書く
- レビュー運用:
  - 大きなAI生成PRは分割する（小さく、意味のある単位で）
  - CIで必須テストを通すゲートを設ける
  - チームで「AI使用のルール／テンプレート」を作る（PRテンプレにプロンプト欄を追加）
- 管理者への提案:
  - リリーススケジュールで「AI生成はレビュー時間を含める」を反映する
  - 透明性を評価指標に含める（開示・テスト実施の有無）

短く言うと：AIは強力だが「誰が最終責任を取るか」を明確にし、PRの透明性とテストを運用ルールとして組み込めば現場の品質を保てます。
