---
layout: post
title: "Same Prompt, Same Task — 2 of 3 AI coding assistant succeeded including OpenCode - 同じプロンプト、同じタスク — 3つのAIコーディングアシスタントのうち2つが成功（OpenCode含む）"
date: 2026-01-15T09:18:59.908Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://medium.com/@dqj1998/one-prompt-three-ai-coding-systems-what-survives-real-engineering-96b4f6473a61"
source_title: "Same Prompt, Same Task — 2 of 3 AI coding assistant succeeded including OpenCode"
source_id: 426400370
excerpt: "同一プロンプトで2/3のAIが実装成功も無自覚の回帰を生み、ツール選びとテストの必須性が明確に"
---

# Same Prompt, Same Task — 2 of 3 AI coding assistant succeeded including OpenCode - 同じプロンプト、同じタスク — 3つのAIコーディングアシスタントのうち2つが成功（OpenCode含む）
魅力的なタイトル: AIにコードを任せると何が壊れる？Chrome拡張で見つかった「見えない」回帰とツール選びの本質

## 要約
同じプロンプトで複数のAIコーディングシステムに実装を任せた実証で、2つは機能を追加できたが双方とも同じ「静かに壊れる」回帰を生んだ。第三者LLMのレビューは、ツールごとに「出荷重視」と「構造重視」という異なる最適化を示した。

## この記事を読むべき理由
AIが実装を自動生成する今、生成コードが「動いて見える」だけで安心してはいけない理由が分かる。日本のプロジェクトでは品質・ローカライズ・運用の要件が厳しいため、どのリスクを減らしたいかでAIツールの選び方が変わる点は非常に実用的。

## 詳細解説
- 実験の設定：作者は実際のChrome拡張（Prompt Editorを持つContextWizard）を用意し、同一のプロンプトを複数のAIに投げた。要求は「新しいブランチを作る」「置換ルール管理UIを追加（複数ルール、大小文字無視オプション、削除確認）」「既存UI/状態は壊さない」「単体テストを通す」など。  
- 結果：3つのアプローチのうち2つが機能追加を完了（OpenCode含む）。しかし両者とも、編集画面でテキスト選択→「Replace with」コンテキスト操作が無応答になる回帰を導入。エラーも警告もなく、マニュアルレビューで見逃しやすい典型的な出荷バグだった。  
- 第三者レビュー：別の大規模モデル（Gemini）に変更差分を評価させたところ、片方（copilot-Opus系）は国際化やUX、ドキュメント性に優れ「リリース向け」、もう片方（OpenCode系）は単体テストカバレッジや防御的実装で「構造的に堅牢」と評価された。結論は「無料＝脆弱」ではなく、ツールは『どのリスクを最小化するか』で選ぶべき、というもの。

## 実践ポイント
- 既存挙動の回帰テストを必須化する：UI操作（コンテキストメニューやショートカットなど）の自動化テストを用意してからAI生成コードをマージする。  
- 単体テストをゲートにする：AIに実装させたら、まずテストを追加・成功させる運用をルール化する。  
- 生成コードの非機能レビューを自動化する：国際化（i18n）、アクセスビリティ、ドキュメントの有無もチェックリスト化。  
- ツール選択は目的で決める：即時採用・UX重視なら出荷しやすいツール、長期保守や安全性重視ならテストを重視するツールを選ぶ。  
- 第三者LLMによる差分レビューを活用する：人的レビューの補助として、生成差分の要点（セキュリティ、保守性、機能的抜け）を模型に要約させると効率が上がる。

短い実験からはっきり分かるのは、「AIが作ったからOK」ではなく「どのリスクを受け入れるか」をチームで決め、テストと自動レビューを習慣化することが最も重要、ということです。
