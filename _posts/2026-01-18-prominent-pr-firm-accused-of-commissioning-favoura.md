---
layout: post
title: "Prominent PR firm accused of commissioning favourable changes to Wikipedia pages | Wikipedia - 著名なPR会社がウィキペディアを“有利に編集”依頼と告発"
date: 2026-01-18T01:18:41.054Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://www.theguardian.com/technology/2026/jan/16/pr-firm-portland-accused-of-commissioning-favourable-changes-to-wikipedia-pages"
source_title: "Prominent PR firm accused of commissioning favourable changes to Wikipedia pages | Wikipedia | The Guardian"
source_id: 424157391
excerpt: "大手PRが外注でウィキ改変、AIが拡散する虚偽情報の危険性を深刻化"
image: "https://i.guim.co.uk/img/media/bdffef94e4133bd0a7bdbfa9994208fe3b1be195/1_217_2188_1750/master/2188.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=201eb4e2c14dc1db8f4917acbb97d9f5"
---

# Prominent PR firm accused of commissioning favourable changes to Wikipedia pages | Wikipedia - 著名なPR会社がウィキペディアを“有利に編集”依頼と告発
PRは情報操作の“グレーゾーン”を超えたか？AI時代に震える百科事典の裏側

## 要約
英国の大手PR会社が外部委託でウィキペディアの編集を行わせ、クライアントに有利な表現や批判を目立たなくする「黒い編集（Wikilaundering）」を実行した疑いが報じられた。AIがWikipediaを参照する現状で、改ざんは情報流通の信頼性に直結する。

## この記事を読むべき理由
ウィキペディアは多くの検索エンジンやAIチャットボットの一次情報源になっており、編集操作は世論や自動化システムに大きな影響を与える。日本の企業・開発者・広報担当にとっても、透明性や検証の方法を知ることは今や必須だ。

## 詳細解説
- 何が起きたか：Tim Allanが創業したPR会社（Portland Communications）に関連して、外部請負業者を通じた一連の有利な編集が2016–2024年に行われたと調査機関が報告。対象には国家（カタール）などハイプロファイルなクライアントが含まれる。
- 手口の概要：編集ネットワーク（約26アカウントと報告）を使い、批判的な記述を下位に回す、批判記事の引用を差し替える、ネガティブな記述を抜くといった「微妙かつ効果的」な操作を行ったとされる。一部のアカウントは有志の編集者によりブロックされた。
- 過去の前例：同社は2012年にもビールメーカーの不要な呼称を削除する編集をした経緯があり、今回も「外注して目立たない形で継続した」との内部証言がある。
- 規約と倫理：ウィキメディア財団の規約では未開示の有償編集は禁じられている。PR業界のガイドライン（CIPRなど）も、匿名や欺瞞的な活動を倫理違反とする。
- 技術的影響：現在の検索エンジンやAI要約ツールはウィキデータやウィキペディアを参照してしまうため、不正編集が自動化された情報配信に乗って増幅されるリスクが高い。

## 実践ポイント
- 編集履歴を確認する：疑わしいページは「履歴（history）」で差分と編集コメント、編集者アカウントの挙動を追う。
- 自動検出ツールを活用する：WikimediaのORESスコアやBotometer的指標で編集の信頼度を機械的に評価する。
- APIで監視網を作る：Wikipedia APIやIRCフィードを使い、特定ページの変更をリアルタイム通知する仕組みを開発・導入する。
- ソース検証を徹底する：AIや検索結果に表示する前に、引用元の一次資料（ニュース原文、公式発表）をクロスチェックする。
- 企業側のガバナンス強化：広報・法務は有償編集の禁止・開示ルールを定め、外注時は第三者監査や透明性条項を契約に入れる。
- 市民側のリテラシー向上：エンジニアや編集者は「誰が」「いつ」「なぜ」編集したかを常に疑う文化を持つ。

短くまとめると、ウィキペディアは既に単なる百科事典ではなく、AI時代の情報基盤だ。企業もエンジニアも「編集される側／する側」の双方で透明性と検証の仕組みを整える必要がある。
