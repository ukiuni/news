---
layout: post
title: A Modern Recommender Model Architecture
date: 2025-12-28 09:15:58.420000+00:00
categories:
- tech
- world-news
tags:
- tech-news
- japan
source_url: https://cprimozic.net/blog/anime-recommender-model-architecture/
source_title: A Modern Recommender Model Architecture - Casey Primozic's Homepage
source_id: 1265212681
excerpt: 視聴確率と評価を同時予測しCPU運用に最適化した小型アニメ推薦モデル
---
# アニメ推薦を“実用”レベルに昇華させたモダンなレコメンダー設計 — 小さく速く、説明できるニューラルCF

## 要約
Denoising Autoencoderベースで「視聴有無（存在確率）」と「評価（レーティング）」を同時予測するマルチタスクモデル。小規模（約55Mパラメータ）、JAXで実装しCPU運用を意識した実用的な設計が特徴。

## この記事を読むべき理由
日本はアニメ視聴文化とレーティングデータが豊富で、実運用できるレコメンダーを作ればサービス差別化に直結します。この設計はデータ収集・損失設計・推論効率・説明性にまで踏み込んでおり、プロダクト化を目指すエンジニアに即役立つ手法が多く含まれます。

## 詳細解説
- アーキテクチャ概観  
  - 入力は固定コーパス（著者は6000作品）に対する「視聴フラグ（0/1）」と「ハイブリッド正規化評価」を連結したベクトル。  
  - Denoising Autoencoderとして一部エントリをホールドアウトし、欠損を復元する形で学習。ボトルネックで圧縮表現を学ぶことで協調フィルタリング的な相互関係を獲得する。  
  - 出力はボトルネックから分岐するマルチヘッドデコーダで、(1) 各作品がプロファイルに含まれる確率（存在）と、(2) 観た場合の評価を別々に予測する。これが品質と調整性を高める主要因。

- 重要な工夫（抜粋）  
  - 損失関数: 「Multinomial Negative Log-Likelihood」で存在確率を扱い、評価はHuber損失（外れ値耐性）で回帰。  
  - ハイブリッド正規化評価: 観ていないアイテムと観ているが評価があるアイテムを別表現にすることで情報豊富な入力に。  
  - マルチタスク重み付け: ホモスケダスティック（等分散）不確実性に基づく重みで複数目的をバランス。  
  - スワッシュ活性化、学習率自動調整、ボトルネックへのノイズ注入（ロバスト性向上）、未評価アイテムの損失マスキング（学習信号のノイズ低減）。  
  - 推論スコア: 存在確率と予測評価を統一的にスコアリングするアルゴリズムを設計し、ランキング生成を安定化。  
  - 説明性: ホールドアウト解析を用いて「なぜこの作品が推されたか」を分析可能にしている。

- 設計判断と実運用性  
  - モデルは約55Mパラメータと比較的小型で、CPUでの低遅延サービングを重視（実用上は重要）。  
  - 学習データはMyAnimeListから約150万プロファイルを収集し、最近の活動と最小エントリ数でフィルタリングして品質を確保。  
  - 試して上手く行かなかった手法：VAE+KL、単一ヘッドデコーダ、事前初期化された損失重み、過度に深いネットワーク——シンプルさの勝利。

- 実装メモ  
  - 実験はJAXで実施（高速な自動微分と効率的な並列化が利点）。ハイパーパラメータ感度は大きめで、学習率や損失重みの調整が性能に影響。

## 実践ポイント
- 小規模でまずは動かす：大規模化よりもシンプルでよく調整された小型モデルが実運用では強い。  
- マルチタスクに分ける：存在確率（推薦可能性）と評価予測を分けるとランキングの制御性が上がる。  
- 未評価データをきちんとマスクする：ノイズの多い未評価や未視聴を誤学習させない。  
- 損失選定は実用重視で：Huberや多項NLLなど頑健な損失を選ぶと外れ値や確率表現の扱いが改善。  
- ボトルネックにノイズを入れて堅牢化、かつ説明性のためにホールドアウト解析を組み込む。  
- データは最新かつ最低限の行動量でフィルタリング（例：過去5年以内、最低30エントリなど）し品質を担保。  
- JAXは実験開発で有力。CPUサービングを重視するならパラメータ規模と演算量を常に監視。

