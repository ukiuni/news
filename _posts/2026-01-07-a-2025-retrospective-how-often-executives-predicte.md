---
  layout: post
  title: "A 2025 Retrospective: How Often Executives Predicted the End of Software Engineering - 2025年回顧：経営層はどれほど頻繁にソフトウェア工学の終焉を予測したか"
  date: 2026-01-07T19:46:58.014Z
  categories: [tech, world-news]
  tags: [tech-news, japan]
  source_url: "https://www.techradar.com/pro/linux-godfather-linus-torvald-says-hes-fine-with-vibe-coding-just-dont-use-it-on-anything-important"
  source_title: "Veteran Linux creator embraces casual vibe coding for beginners while warning strict developers to keep experimental tools far from critical systems | TechRadar"
  source_id: 468581333
  excerpt: "リーナスがvibe codingを学習用で推奨、カーネルなど本番利用を厳しく警告"
  image: "https://cdn.mos.cms.futurecdn.net/p7asKHxYWoAoJXzcD2M8e7-2000-80.jpg"
---

# A 2025 Retrospective: How Often Executives Predicted the End of Software Engineering - 2025年回顧：経営層はどれほど頻繁にソフトウェア工学の終焉を予測したか
リーナスが「vibe coding」を容認。ただし重要系には絶対使うな、が本音 — 初心者を助ける利便性と現場の落とし穴

## 要約
Linuxの生みの親リーナス・トーバルズは、AI支援による「vibe coding」を学習や素早い試作には肯定的だが、カーネルなどミッションクリティカルな領域での利用は長期的な保守問題や誤報の原因になるとして強く警告している。

## この記事を読むべき理由
AIによるコード生成は日本の開発現場でも急速に広がっています。だが大事なシステム（組込み、産業機器、車載、サーバ基盤など）では安全性・メンテナンス性が命。リーナスの発言は「どこでAIを使うか」を判断するための実践的な指針になります。

## 詳細解説
- vibe codingとは？  
  ユーザーがAIや補助ツールを使って直感的にコードを書いたりタスクを完了する手法。入門者の学習やプロトタイピングに有効だが、出力は必ずしも正確・最適ではない。

- リーナスの立場（要点）  
  1) 学習や個人の作業補助としての利用は肯定的。昔の雑誌のプログラム丸写しと比べると、現代の学習手段は大きく進化したと指摘。  
  2) カーネルなどコアソフトウェアでの採用は反対。AI生成コードはメンテナンス性を損ない、将来の修正・解析を難しくする可能性がある。  
  3) 自動クローラーがkernel.org等のソースを無差別に収集し、AIが誤った脆弱性レポートを生成するなど、運用コスト（ノイズ対応）が増えていると批判。  
  4) AIはコンパイラがアセンブリを置き換えたような「道具」に過ぎず、開発者が消えるわけではない。今後は探究的ワークフローと厳格なプロダクションパイプラインに分かれていく可能性を示唆している。

- 技術的懸念の具体例  
  ・AIの出力はデターミニスティックでないため、再現性・トレーサビリティが低い。  
  ・ライセンスやコード由来の問題（学習データ由来の権利問題）や、hallucinationによる虚偽コード・虚偽レポート。  
  ・自動生成コードがテスト・ドキュメント不足で保守負荷を上げる。  

- 関係トピック：Rust導入や保守文化  
  リーナスはKernelへのRust導入やメンテナ不足なども話題にしており、新言語やツールの採用は技術的利点と運用コストのバランスで決めるべきと示唆している。

## 実践ポイント
- 学習・プロトタイプには活用して良いが、本番導入前に必ず厳密なレビューとテストを行う。  
- カーネルや車載、医療機器などミッションクリティカルなコードにはAI生成コードをそのまま持ち込まない。  
- CIテスト（ユニット・統合・静的解析・fuzz）を必須化し、モデル出力の差分や由来をログで残す。  
- AI出力は「ドラフト」と見なし、必ず人間がリファクタ／最適化するワークフローを定着させる。  
- 組織としてAI利用ポリシーを作り、ライセンス／セキュリティ／レビュー基準を明記する。  
- 公開リポジトリのスクレイピングや誤レポートに対しては、メンテナ向けのフィード制御や自動フィルタを導入してノイズを減らす。  
- 若手教育では「AIの長所と限界」を教え、ツール依存にならない基礎力（設計、テスト、デバッグ）を強化する。

リーナスのメッセージは単純で現実的です：AIは強力なアシスタントだが、使いどころと運用ルールを誤ると長期的な負債になる。日本の現場でも「どこでAIを使うか」を明確にして、安全と生産性を両立させましょう。
