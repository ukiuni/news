---
layout: post
title: "Patenting apps/code - アプリ・コードの特許"
date: 2026-02-17T20:58:16.641Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "http://vigilantproject.com"
source_title: "Vigilant | Pornography Detection App"
source_id: 439217020
excerpt: "AIで画面監視し疑わしい画像をぼかして通知、閲覧者特定で家族のプライバシーと法的懸念"
---

# Patenting apps/code - アプリ・コードの特許
魅惑と議論を呼ぶ「家族向けAIモニタリング」—あなたのスクリーンは誰に見られるべきか？

## 要約
Vigilantは画面のスクリーンショットをAIで解析し、ポルノ等の疑わしいコンテンツを検出すると、ぼかし画像と共に「アカウンタビリティパートナー」へ通知する画面監視アプリ。顔認識や検出後の操作記録などで行動変化を促す設計です。

## この記事を読むべき理由
プライバシー規制や顔認識技術の導入が進む日本で、家庭・教育現場・企業のデジタル健全化にどう向き合うかは喫緊の課題。技術的特徴とリスクを把握して、実装や利用判断に役立てられます。

## 詳細解説
- 検出フロー：定期的に画面をキャプチャ→画像をローカル／クラウドでAI解析→不適切判定ならぼかし画像を生成して通知。
- AI解析：ポルノグラフィ分類モデルを用いて「セクシー」等のラベルと信頼度（例: 72.5%）を返す。誤検知（false positives）や閾値設定が運用上の鍵。
- 顔認識：ウェブカメラ対応で閲覧者を特定し、検出直後の画面操作（約30秒）を記録。これにより「誰が見たか」を追跡可能。
- プライバシー処理：テキストのローカル編集・画像のぼかしを謳うが、通知手段はSMS/メールで第三者に情報送信される点に注意。
- UX/方針：遮断（blocking）よりも「非侵襲的なアカウンタビリティ」を重視。アプリ削除防止などの仕組みも提示。
- 倫理・法的懸念：本人同意、児童保護、個人情報保護法（APPI）や職場での監視規制との整合性、顔認識の精度と差別的誤判定リスク。

## 実践ポイント
- 利用前に同意と透明性を確保する（家族・従業員全員への説明と明示的同意）。
- 重要な設定：検出閾値の調整、ログ保持期間、画像/テキストの送信先制御を確認。
- プライバシー確保：可能ならローカル処理優先の設定を選ぶ、通知内容は最小限に。
- 法的チェック：学校や職場で使う場合は労務・個人情報の法務確認を行う。
- 代替策の検討：ブロッキング型フィルタ、ペアレンタルコントロール、カウンセリングや教育プログラムと組み合わせる。

（参照元：Vigilant — AI Screen Companion の公開情報を要約）
