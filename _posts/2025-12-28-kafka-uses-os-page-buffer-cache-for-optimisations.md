---
layout: "post"
title: "Kafka uses OS page buffer cache for optimisations instead of process caching - Kafkaはプロセスキャッシュの代わりにOSのページバッファキャッシュを最適化に使用する"
date: "2025-12-28 09:15:29.886000+00:00"
categories:
- tech
- world-news
tags:
- tech-news
- japan
source_url: "https://shbhmrzd.github.io/2025/11/21/what-helps-kafka-scale.html"
source_title: "What Helps Kafka Scale | Shubham Raizada’s Blog"
source_id: "436325463"
excerpt: "OSページキャッシュ＋ゼロコピーでKafkaがGC負荷と二重バッファを回避し高速化する理由"
---
# Kafka uses OS page buffer cache for optimisations instead of process caching - Kafkaはプロセスキャッシュの代わりにOSのページバッファキャッシュを最適化に使用する

## 要約
Kafkaはメッセージをアプリケーションヒープで保持せず、OSのファイルページキャッシュと「ゼロコピー」転送を活用して高スループットを実現している。これにより二重バッファやGC負荷、不要なメモリコピーを避けられる。

## この記事を読むべき理由
日本でも大量ログ・イベント処理やリアルタイム解析を扱うサービスが増えています。Kafkaの「OSファースト」な最適化を理解すれば、インフラ設計やチューニングで劇的に効率を上げられます。

## 詳細解説
Kafkaの設計は「スループット重視」で、APIや運用保証もそれに合わせてシンプル化されています。代表的な高速化手法は以下。

- 基本的な設計選択（おさらい）
  - バッチ処理：まとめて送受信してTCP往復回数を減らす
  - プルモデル：消費者が自分の取り込み速度を制御
  - パーティション当たり単一コンシューマ：同一パーティションに対する同時読みを避け、ロックや複雑な同期を排除
  - 連続I/O：ランダムシークを避け、ログへ追記中心のアクセス

- OSページキャッシュを使う（JVMヒープを迂回）
  - KafkaはメッセージをJavaオブジェクトとして長期的にヒープにキャッシュしない。代わりにファイルに書き、読み書きはOSのページキャッシュに任せる。
  - 利点：アプリ側での二重バッファリングがなくなり、GCによる遅延やメモリ管理コストを削減。プロセス再起動後もページキャッシュが「温かい」状態を維持できる（OSレベルのキャッシュが残るため）。
  - 動作条件：プロデューサとコンシューマが順次アクセスする特性（コンシューマは若干遅れる）により、OSの書き込みスルーやリードアヘッドが効果的に働く。

- ゼロコピー最適化（sendfile / FileChannel.transferTo）
  - 通常、ファイル→ソケット送信はユーザ空間とカーネル空間で複数回コピーが発生する（ディスク→ページキャッシュ→アプリバッファ→カーネル→ソケット）。
  - KafkaはLinuxのsendfile相当（JavaではFileChannel.transferTo）を使い、ユーザ空間コピーを省くことでCPU負荷とシステムコール数を減らす。
  - 注意点：OSやJVM実装に依存するため、環境ごとの検証が必要。

## 実践ポイント
- JVMアプリでメッセージを長時間ヒープに保持しない：バッファをアプリ側で抱え込むとKafkaの恩恵を受けられない。
- OSレベルのキャッシュを監視する：vmstat/iostat/htopでページキャッシュのヒット率やディスクI/Oパターンを確認する。
- ネットワークのゼロコピーを有効活用：JavaでFileChannel.transferToを使うか、Kafkaが使う設定やバージョンでゼロコピーが有効か確認する。
- カーネルとネットワークのチューニング：tcp_rmem/tcp_wmem、read-ahead、vm.swappinessなどをアプリに合わせて調整する。
- ストレージは「連続書き込み」に最適化：セグメント単位の追記性能が重要。SSDでもランダム書き込み特性を把握しておく。
- テストを忘れずに：LinuxカーネルバージョンやJVM実装で挙動が変わるため、実環境でパフォーマンス比較を行う。

