---
layout: post
title: Prompt Injection Isn’t a Prompting Problem, It’s an Authority Problem - プロンプトインジェクションはプロンプトの問題ではなく、権限の問題である
date: 2025-12-27 11:41:42.025000+00:00
categories:
- tech
- world-news
tags:
- tech-news
- japan
source_url: https://zenodo.org/records/18067959
source_title: 'Authority Separation in AI Systems: Structural Guarantees Across Security,
  Epistemics, Economics, and Safety'
source_id: 436977835
excerpt: プロンプト注入を防ぐ「実行権限分離」設計でAIの安全と運用コストを一挙に守る方法
---
# Prompt Injection Isn’t a Prompting Problem, It’s an Authority Problem - プロンプトインジェクションはプロンプトの問題ではなく、権限の問題である

## 要約
言語モデルは「提案者（generator）」に留め、実行の「認可（authority）」を分離する設計（Authority Separation）を提示。これにより、プロンプト注入・幻覚・コスト誤謬・不可逆的な学習などの失敗モードを構造的に軽減できると主張する。

## この記事を読むべき理由
大規模言語モデルを組み込む製品は日本でも急増中。金融、医療、製造や自治体システムでは、誤った自動実行やコスト暴発、規制違反が重大事故につながる。設計段階で「誰が何を実行できるか」を明確にするこの考え方は、実務での安全担保と監査対応に直結する。

## 詳細解説
- コアアイデア：モデルは「やるべきこと」を生成するが、それを実行する権限は別コンポーネントが持つ。すなわち「提案」と「認可」を分離するアーキテクチャ原則。
- 対応する脅威モデル：  
  - セキュリティ（prompt injection）: 悪意ある入力でモデルが危険な指示を生成しても、実行権限が切り離されていれば実害を防げる。  
  - 認識論（hallucination）: モデルの不確実な出力を、検証層（ファクトチェッカー、外部ソース照合）で弾くことで誤情報の流出を抑止。  
  - 経済（cost-correctness）: APIコールや外部アクションに対するコスト上限・見積もり検証を実行側で強制し、意図しない請求を防ぐ。  
  - 安全（irreversible constraint learning）: モデルの出力を直接システム状態に反映させないことで、不可逆な学習や状態変化を回避。
- 参照アーキテクチャ：論文は提案アーキテクチャとそれを評価する統一テストスイートを公開。設計要素としては、コマンドサニタイザ、認可エンジン、実行サンドボックス、監査ログ、コストガードなどを組み合わせる。
- エビデンス：理論的な「構造的保証」を示し、従来のプロンプト中心アプローチで残る失敗モードを排除する実験と評価指標を提示している（論文付随のリポジトリあり）。

## 実践ポイント
- アーキテクチャ設計
  - モデルは「提案（自然言語／構造化コマンド）」のみ生成、実行は別サービスがStrictに管理する。
- 認可と検証
  - 実行前にシグネチャ検証、ポリシーチェック、外部ファクト照合を必須化する。
- 最小権限・Capabilityトークン
  - 各実行ユニットに対し時間限定・用途限定の実行トークンを発行する。
- コスト制御
  - 実行層でコスト上限や見積り合意を強制し、想定外の課金を遮断。
- 監査と可観測性
  - 提案→検証→実行の全フローを不可変ログ（監査証跡）に残し、後追い検証を容易にする。
- 開発ワークフロー
  - テストスイートでprompt injectionや幻覚ケースを自動評価し、CIに組み込む。
- 導入順序（PoC提案）
  - 影響が小さい自動化タスクから実行分離を導入し、ログ・ポリシーを整備して段階的拡張を行う。

