---
layout: post
title: "Reading across books with Claude Code - Claude Codeで本を横断して読む"
date: 2026-01-16T21:05:50.182Z
categories: [tech, world-news]
tags: [tech-news, japan]
source_url: "https://pieterma.es/syntopic-reading-claude/"
source_title: "Reading across books with Claude Code | Pieter Maes"
source_id: 46650347
excerpt: "Claude Codeで100冊から抜粋を連鎖させ新発見を導く方法"
image: "https://pieterma.es/og/syntopic-reading-claude.png"
---

# Reading across books with Claude Code - Claude Codeで本を横断して読む
AIが100冊の知見を「つなげる」──Claude Codeで読書を再発明する方法

## 要約
Claude Codeを「エージェント」として運用し、100冊のノンフィクションから意味ある抜粋（trails）を自動で見つけ出す仕組みを作った話。検索だけでなく「つながり」を発見することで、より深い読書ができる点が肝。

## この記事を読むべき理由
- 単なる要約ではなく、複数の本にまたがるアイデアの連鎖を自動で発掘する手法は、アイデア探索やリサーチ、生産性向上に直結する。
- 日本のプロダクトチームやリサーチ室、個人の勉強会でも応用しやすい実装ノウハウが詰まっている。

## 詳細解説
- 目的と成果物
  - 目標は「本棚からテーマに沿った文章列（trail）を見つけ、抜粋を順序付けて並べる」こと。例としてスタートアップの欺瞞から大衆運動の心理へ自然につながる抜粋が生成されている。
- データ処理の基本設計
  - EPUBを高速パーサ（selectolax）で処理し、テキストを「チャンク」（目安500語、段落優先）に分割。500語はトークン節約と文脈保持のバランスを取った設定。
  - 文単位分割は wtpsplit を使用。チャンクはトピック抽出の単位となる。
- トピック抽出とインデックス
  - 各チャンクに対してLLM（著者は Gemini 2.5 Flash Lite を選定）で3–5個のトピックを抽出し、有益でないチャンク（索引、謝辞等）を除外。
  - 抽出トピックはおよそ10万件になり、これを階層化して約1,000のトップレベルにまとめる（グラフクラスタリング→再帰的パーティショニング）。
- 埋め込みと類似度
  - 埋め込みは google/embeddinggemma-300m を使い、再ランキングに BAAI/bge-reranker-v2-m3 を利用。類似トピックは統合（表記ゆれのマージ）して冗長性を減らす。
- トピック木と探索性
  - トピックをグラフ（類似度 + 共起のPMI）にしてLeidenでクラスタ化し木構造へ。これにより人が探索できるスケール感に集約する。
- エージェント（Claude）の役割
  - 単一の固定パイプラインではなく、Claudeをツール群（CLI）から呼び出す「エージェント」として動かす。探索→種出し→抜粋作成→並べ替え→ハイライト付与、という段階を自律的に進める。
  - エージェントに「何が必要か」を尋ねることで、実際に使いやすいコマンドを提案させ、ツール群を改善していくワークフローを採用。
- 新規性（novelty）重視
  - 面白さの指標に「埋め込み空間での近傍からの平均距離」を採用し、稀なトピックや本を優先的に表示するバイアスをかける。
- 実装スタックとコスト感
  - SQLite（sqlite-vecで埋め込み格納）、DSPyでLLM呼び出し、igraphでグラフ操作。重いモデルや埋め込みは別プロセスで常駐させることでCLI呼び出しを高速化。
  - 100冊の処理で約6,000万入力トークン、コストは概算で£10程度（著者の構成下での参考値）。

## 実践ポイント
- 小さく始める：まずは10冊程度でチャンク分割→トピック抽出→埋め込みまで流してみる。全体像が掴みやすい。
- チャンク長は調整可能：500語は基準。日本語では文の区切りやトークナイザーの違いで最適値が変わるので、Sudachi/MeCab等で試す。
- エージェントに「何が欲しいか」を聞く：単にプロンプト最適化するより、エージェントに足りないツールやコマンドを提案させると改善が速い。
- ノイズ除去は遅延処理で：全文前処理で無駄にトークンを使うより、表示する抜粋だけをクリーンアップするとコスト削減になる。
- 新規性指標を入れる：平凡な相関だけでなく、埋め込み空間での孤立度を重視すると意外な発見が出やすい。
- 日本語データの注意点：英語用の分割・モデルをそのまま使うと精度低下する可能性があるため、日本語対応の分割器・モデルに置き換えることを推奨。

Claude Codeのアプローチは、「LLMを単なる要約器にするな」という主張を実践している。ツール設計とエージェント的運用で、読書が「一覧→発見→編集→再発見」を繰り返せる作業に変わる。日本の現場でも、社内ナレッジの横断検索やリサーチ資料の相互参照など、応用範囲は広い。
